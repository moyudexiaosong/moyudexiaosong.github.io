

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/icon.jpg">
  <link rel="icon" href="/img/icon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="故障诊断基于卷积神经网络的轴承故障诊断算法研究本文主要研究基于卷积神经网络的轴承故障诊断，将卷积神经网络的特征识别直接作用在原始时域信号上，并对设计出的卷积神经网络进行改进，使改进后的网络在噪声环境和工作负载变化情况下，依然可以保持高识别率。主要结构分五部分： 一、卷积神经网络 本文中池化层采用的降采样操作为最大值池化。这样做的优点在于可以获得位置无关的特征，这一点对于周期性的时域信号很关键。">
<meta property="og:type" content="article">
<meta property="og:title" content="论文记录">
<meta property="og:url" content="http://example.com/2022/11/04/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/index.html">
<meta property="og:site_name" content="摸鱼之家">
<meta property="og:description" content="故障诊断基于卷积神经网络的轴承故障诊断算法研究本文主要研究基于卷积神经网络的轴承故障诊断，将卷积神经网络的特征识别直接作用在原始时域信号上，并对设计出的卷积神经网络进行改进，使改进后的网络在噪声环境和工作负载变化情况下，依然可以保持高识别率。主要结构分五部分： 一、卷积神经网络 本文中池化层采用的降采样操作为最大值池化。这样做的优点在于可以获得位置无关的特征，这一点对于周期性的时域信号很关键。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/photo37.jpeg">
<meta property="article:published_time" content="2022-11-03T17:25:02.536Z">
<meta property="article:modified_time" content="2022-11-07T17:59:08.843Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/photo37.jpeg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>论文记录 - 摸鱼之家</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":false},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"AwHBUAjSP1GvDVpiBgxfS2Pg-gzGzoHsz","app_key":"kMsGLN3hzkQJuLrmqQBgquFF","server_url":"https://awhbuajs.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>快乐老家</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                档案馆
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                目录
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/photo37.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="论文记录"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-11-04 01:25" pubdate>
          November 4, 2022 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.3k words
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">论文记录</h1>
            
              <p class="note note-info">
                
                  
                    Last updated on a few seconds ago
                  
                
              </p>
            
            <div class="markdown-body">
              
              <hr>
<h2 id="故障诊断"><a href="#故障诊断" class="headerlink" title="故障诊断"></a>故障诊断</h2><h3 id="基于卷积神经网络的轴承故障诊断算法研究"><a href="#基于卷积神经网络的轴承故障诊断算法研究" class="headerlink" title="基于卷积神经网络的轴承故障诊断算法研究"></a>基于卷积神经网络的轴承故障诊断算法研究</h3><p>本文主要研究基于卷积神经网络的轴承故障诊断，将卷积神经网络的特征识别直接作用在原始时域信号上，并对设计出的卷积神经网络进行改进，使改进后的网络在噪声环境和工作负载变化情况下，依然可以保持高识别率。主要结构分五部分：</p>
<p>一、卷积神经网络</p>
<p>本文中池化层采用的降采样操作为最大值池化。这样做的优点在于<strong>可以获得位置无关的特征</strong>，这一点对于周期性的时域信号很关键。</p>
<p>该卷网包含两个卷积层，两个池化层，一个全连接隐含层，以及一个Softmax层。</p>
<p>选用的目标函数为交叉熵函数，因为平方误差函数比较的是每一个类别的大小，故障诊断需要的是衡量两个概率分布的一致性。</p>
<p>用链式法则从后往前逐层计算目标函数关于W和b的偏导后，要对参数进行优化，因为参数及超参数多的缘故，选用可以自适应且具有鲁棒性的Adam算法。</p>
<p>数据集增强的方式是重叠采样。</p>
<p>最后，使用提出的卷积神经网络在CWRU滚动轴承数据集上进行训练，训练好的模型的识别率可以达到99%以上。</p>
<p>二、模型改进</p>
<p>为了提高网络性能，本章研究如何加深卷积神经网络的层数，并且减少网络参数个数。</p>
<p>堆叠式卷积核在一维振动信号领域表现的并不好，因此本文设计出一种WDCNN模型，第一层为大卷积核，目的是为了提取短时特征，快速筛去对诊断没有帮助的特征。</p>
<p>其余卷积层的卷积核大小均为3×1来增强网络的表达能力，3x1卷积核参数少，有利于加深网络，同时可以抑制过拟合。每层卷积操作之后均进行批量归一化处理BN，主要操作步骤是将卷积层或全连接层的输入先减去所在mini-batch的均值，再除以其标准差，类似于一种标准化操作，因此可以加速训练。但是这样会将输入值限制在一个较窄的区间，降低网络的表达能力。因此，将标准化后的值重新乘以一个缩放量并加上偏执系数，用于增强表达。</p>
<p>BN层的作用是加快收敛。</p>
<p><img src="/../img/image-20221104032816510.png" srcset="/img/loading.gif" lazyload alt="image-20221104032816510" style="zoom:50%;"></p>
<p>由于振动信号是周期性的，且每一个输入信号的相位值不一定相同。为了让WDCNN的滤波级学习到位移无关的特征，最后一个池化层的神经元在输入信号中的感受野大小，应当大于一个周期，由此结论推导出WDCNN每层网络训练步长的范围。</p>
<p>最终试验结果得到，WDCNN模型收敛速度快，在大数据训练下，对采样频率为12kHz的凯斯西储大学轴承数据库可以达到100%±0的识别率。</p>
<p><img src="/../img/image-20221104034028789.png" srcset="/img/loading.gif" lazyload alt="image-20221104034028789"></p>
<p>为了深入理解训练数据量对网络训练的影响，通过<strong>t-SNE降维技术</strong>，将测试集在最后一个隐含层的特征降成二维并可视化。上图分别是训练样本个数为90，300，3000以及19800时，测试集D特征可视化图。从图中可以看出，随着训练样本的增加，各类别之间的重叠部分逐渐减少，并且各类别之间的距离也越来越大，即特征的可分性也越来越强、表明WDCNN对测试样本的判别能力逐渐增强。</p>
<p>三、增加泛化性能</p>
<p>在实际的工业应用中，工业现场的噪声无法避免，机器工作负载也会随之改变，本章首次将故障诊断中的环境噪声与负载变化造成的信号改变，归结为机器学习中的领域自适应问题，即目标领域（测试样本）的分布与源领域（训练样本）的分布不一致的情况。</p>
<p>本章采用AdaBN（AdaptiveBatchNormalization）算法提高WDCNN模型的领域自适应能力，AdaBN认为BN层的均值和方差代表了不同域之间的特性，因此在我们用正常情况下的数据集训练出一个模型后，再将拥有噪声或不同工作负载的目标领域的数据输入模型。用目标领域样本在每一个 BN 层的均值和方差替换原来 BN 层所使用的由源领域样本计算出的均值和方差。这样就使源领域与目标领域调整到一个新的分布空间，在此空间内，两者近似一致，从而达到领域自适应的目的。</p>
<p><img src="/../img/image-20221104035239148.png" srcset="/img/loading.gif" lazyload alt="image-20221104035239148"></p>
<p>然后给测试样本添加噪声和在变载情况下测试网络性能，新模型都有很好的性能。得到的经验是，当噪声较大时应选取较大的卷积核，卷积核宽度建议不小于 3 倍步长。最后用tSNE降维表达了最后一个隐含层，可视化了模型的诊断性能。</p>
<p>四、训练干扰</p>
<p>上一章的模型虽然好但是需要目标领域样本的均值和方差，这在初期时很难满足的。因此，提出了基于训练干扰的卷积神经网络（TICNN）。</p>
<p>TICNN模型在WDCNN模型的训练过程中引入了卷积核Dropout和极小mini-batch，并采用集成学习。该模型在没有利用任何目标领域的信息情况下，依然具有很高的抗噪性与负载自适应性。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/77609689">Dropout</a>算法的原理是每次训练都随机让一定神经元停止参与运算，停止神经元的比例就是dropout rate，这样就得到了一堆新的模型（比方说四个）。</p>
<p>dropout太大就会把重要特征drop掉，会造成欠拟合，而适合的dropout会减轻过拟合，就是因为他drop掉了一些非本质的特征，比如说在人脸识别的时候，把衣服特征drop掉。</p>
<p>如果第四个模型overfitting了，前三个模型也参与了投票判断，第四个模型overfitting就被弱化了。</p>
<p><strong>所以，dropout的出现，使得模型稳定性和鲁棒性被大大提高了。</strong></p>
<p>但是模型在训练的时候会停止训练一些神经元，而测试的时候，整个模型是完整的，不会dropout 任何神经元。所以，在训练的时候，我们会对<strong>没有被dropout的神经元权值做一个rescale</strong>。</p>
<script type="math/tex; mode=display">
rescale rate = 1 / (1 - dropout rate)</script><p>没用dropout的神经网络前向传播计算公式：</p>
<p><img src="/../img/image-20221104041838983.png" srcset="/img/loading.gif" lazyload alt="image-20221104041838983" style="zoom:50%;"></p>
<p>用了dropout 的神经网络前向传播计算公式：</p>
<p><img src="/../img/image-20221104041912435.png" srcset="/img/loading.gif" lazyload alt="image-20221104041912435" style="zoom:50%;"></p>
<p>在使用第一层大卷积核进行卷积时，先对卷积核进行 Dropout 操作，这是 TICNN 模型的第一个训练干扰，目的是给 TICNN 训练时提供不完整的信号，从而强化 TICNN 在信号部分缺失时的诊断能力。</p>
<p>使用了极小的 mini-batch 来进行批量训练，增大 minibatch 的均值方差变化范围，增强模型对测试集的均值方差于训练集发生的偏移时容忍度。</p>
<p>为了模拟噪声的多样性与不确定性，TICNN采用变化的 Dropout 率，在每一次进行 mini-batch 训练时，Dropout 率服从 0.1 到 0.9 的均布分布。并且防止TICNN对噪声学习的太好，对正常样本的识别率会降低，五次里只会dropout一次。</p>
<h2 id="小样本学习"><a href="#小样本学习" class="headerlink" title="小样本学习"></a>小样本学习</h2><h3 id="大数据时代的小样本学习"><a href="#大数据时代的小样本学习" class="headerlink" title="大数据时代的小样本学习"></a>大数据时代的小样本学习</h3><p>不做结构，做方法。</p>
<p>本文提出目前的SSL技术主要可以分为两类：</p>
<ol>
<li><p>概念学习：类似迁移学习，通过已有的概念在对新概念进行少量观察后就可以掌握其分类或回归特点，其目的主要是模拟人类的识别、生成、想象、综合和分析等学习行为。</p>
</li>
<li><p>体验学习：通常与传统机器学习的大样本学习方式并存，该类别主要关注样本不足的学习，在一些文献中也可以称为小数据学习。</p>
</li>
</ol>
<p>总之，SSL模拟的是人类的学习能力，可以将场景解析为对象和关系，并将一些已经学习到的元素进行组合，用于识别其他的小样本学习任务。打个比方，比如看到一辆不认识的车，可以将它分解为一些已知概念，就比如车轮和转向杆。</p>
<p>因此，当前机器学习方法遇到的以下问题有望通过 SSL 技术的未来发展得到缓解：</p>
<ol>
<li>数据标签的成本高昂导致的弱监督学习或网络监督学习。</li>
<li>样本中若出现长尾现象，会让样本分布失衡，影响模型性能。</li>
<li>数据量太小，难以训练出接近真实的模型。</li>
</ol>
<p><img src="/../img/image-20221104145526582.png" srcset="/img/loading.gif" lazyload alt="image-20221104145526582" style="zoom:50%;"></p>
<p>与传统的LSL相比，经验学习通过增强数据集S和已有知识系统K提供的小样本数据集，试图将SSL转变为LSL。而概念学习用匹配规则R将概念系统C中的概念与输入的小样本S联系起来，来形成一个新的概念，或完成一个识别任务。</p>
<p>为了减少或满足 LSL方法对样本数量的要求，本研究主要包括两类方法，分别利用增强数据S——体验学习，和利用知识系统K——概念学习。</p>
<p><strong>增强数据：</strong></p>
<p>增强数据方法试图用与输入小样本高度相关的其他数据源来补偿输入数据，通常通过转换、合成、想象或其他方式产生。</p>
<h4 id="概念学习"><a href="#概念学习" class="headerlink" title="概念学习"></a>概念学习</h4><p><strong>知识系统来源：</strong></p>
<ol>
<li>来自其他领域：从不同领域转移同一目标的知识。例如，对一类对象进行图像识别时，在缺少该类图像样本时，可以通过对该类的语义描述来补偿。</li>
<li>训练模型：从其他相关数据集训练的模型可用于通过微调其参数来拟合小样本数据集，模型可以是神经网络、随机森林等。</li>
<li>概念的认知知识：此类知识包括常识知识、领域知识和如何通过小训练样本学习到概念的先验知识。例如，如果我们想要定位眼睛，可以利用眼睛的位置高于嘴的位置的认知知识。</li>
<li>元知识：一些超越数据的高级知识，有助于在样本不足的情况下补偿每个概念学习。</li>
</ol>
<p>概念系统包括内涵表示和外延表示：</p>
<ul>
<li>内涵表示命题或语义中的精确定义——形式上学习的概念，比如它的属性特征。</li>
<li>外延表示与学习相关的原型和概念。</li>
</ul>
<h2 id="Mixup"><a href="#Mixup" class="headerlink" title="Mixup"></a>Mixup</h2><p>一、大型神经网络的问题</p>
<p>大型的深度神经网络存在一些不好的行为，比如<strong>记忆性</strong>和<strong>对抗样本敏感</strong>问题。</p>
<p>首先需要从神经网络最基本的优化原理，也就是经验风险最小化（ERM原理）讲起。当前的神经网络其实都是基于这个基本思想进行学习或训练的。经过机器学习领域多年的发展，ERM优化原理逐渐暴露出了明显的问题：</p>
<p>一方面，即使在正则化约束的情况下，或者在标签随机分配的分类问题中，ERM仍允许大型神经网络<strong>记住</strong>训练数据（而不是从训练数据中泛化）。</p>
<p>另一方面，用ERM训练的神经网络在训练分布之外的示例（也称为对抗性示例）上进行评估时，其预测会发生巨大变化。 这些证据表明，ERM无法解释或提供与训练数据仅略有不同的测试分布的概括（其实就是泛化性问题可能是一个根本问题）。 但是，ERM的替代方法是什么？</p>
<p>二、数据增强方法</p>
<p>数据增强可以理解为扩充数据集和减少模型复杂度的综合手段，L2正则化、dropout等等也都是在控制模型复杂度。只不过它们没有考虑数据本身的分布，而数据增强属于更加机智的控制模型复杂度的方法。</p>
<p>数据增强方法本质就是选择与训练数据相似但不同的示例进行训练，也可以理解为近邻风险最小化规则的一种形式Vicinal Risk Minimization（VRM）。这种做法也可以理解为将训练数据进行人为的泛化，然后再让神经网络记住。</p>
<p>同时，数据增强的方法也需要结合具体的数据集，以及相应的专业知识，比如肿瘤分割的数据集就应该避免使用会破坏结构信息的数据增强方法。</p>
<p>另外，数据增强一个关键假设就是<strong>经过增强的近邻样本共享一个分类，而不会对这种近邻关系建模</strong>。说人话就是，先把数据增强，再构建神经网络。</p>
<p>mixup就是一种数据增强方法：</p>
<p><img src="/../img/image-20221108003455079.png" srcset="/img/loading.gif" lazyload alt="image-20221108003455079"></p>
<p><img src="/../img/image-20221108003848981.png" srcset="/img/loading.gif" lazyload alt="image-20221108003848981"></p>
<p>选出两组不同类别的训练样本及其标签，$λ∈[0,1]$，具体实现时λ 的值从beta(α,α)分布中采样，α越大越会导致欠拟合。因为label用的是one-hot vector编码，加权之后就变成了同时属于混合前的两个不同类。</p>
<p>这为不同的类提供了连续的数据样本，直观地扩展了给定训练集的分布，从而使网络在测试阶段更加稳健。</p>
<p>最后生成一个新的数据和标签，并输入到网络训练。</p>
<p>为什么会有用呢？</p>
<p>看了别人的解释，trainset可以看为高维空间中分布的一堆散点，通过mixup造出了一大批位于trainset 散点之间的新点出来，扩充数据的同时，使散点更密集，这样 model 在拟合 trainset 时不容易过拟合， 使model更准确。</p>
<p>三、带来的提升</p>
<p>（1）当从损坏的标签中学习时，提升了模型的鲁棒性</p>
<p>作者将CIFAR-10训练集的一部分（20%，50%，80%）的标签替换为随机噪声，测试集保持原状。Dropout是从损坏标签中学习的任务的SOTA方法，所以作者用了三种方法进行了对比实验——dropout方法；mixup方法；mixup + dropout。</p>
<p><img src="/../img/v2-1a8b3f51adab00d27420057e1306dac0_r.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>能够总结出的规律为，当使用比较大的dropout概率时，能够有效的减少过拟合，mixup使用大α值时效果优于dropout，而且当mixup和dropout一起使用时能够取得最好的效果，说明两种方法是兼容的。</p>
<p>（2）面对对抗样本时，mixup提高了神经网络的鲁棒性</p>
<p><img src="/../img/v2-92028372a38415d153f5193c3ae82944_r.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>（3）这种线性操作能够减少数据集中的不良振荡。</p>
<p><img src="/../img/v2-ee55654439687abe62bca696a37f614e_1440w.webp" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>上图说明了使用ERM和混合在CIFAR-10数据集上训练的两个神经网络模型的平均行为。 两种模型具有相同的架构，使用相同的程序进行训练，并在随机采样的训练数据之间的相同点进行评估。 可以看出在训练样本之间的模型预测和梯度规范方面，使用混合训练的模型更稳定。</p>
<p>（4）提供更平滑的不确定性估计</p>
<p><img src="/../img/v2-a8b48f9c4457450a434ca8ac30ea25f0_1440w.jpeg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>上图显示，mixup导致决策边界在类之间线性过渡，从而提供了更平滑的不确定性估计。</p>
<p>四、超参设置经验</p>
<ol>
<li>mixup更适合较小的 weight decay (10−4) ，ERM更适合较大的 weight decay (5 × 10−4)</li>
<li>线性插值不能对相同label做，要对不同label进行混合。</li>
<li>λ 的值从beta(α,α)分布中采样，α越大越会导致欠拟合</li>
<li>imagenet数据集上，α∈[0.1,0.4] 效果更好</li>
</ol>
<p>五、其它一些知识点</p>
<p>（1）pre-training 预训练</p>
<p>打个比方，我们需要搭建一个神经网络来完成一个特定的图像识别任务，在随机初始化参数后，当我们把模型训练的差不多的时候，就可以把这时候的模型参数保存下来。等到下次还执行这种图像任务的时候，就可以拿来直接初始化，可以获得一个较好的结果。</p>
<p>在CNN领域中，很少有人从头训练，因为足够规模的数据集还是比较少见的。</p>
<p>（2）fine-tuning 微调</p>
<p>继续打比方，假设有一个神经网络Y=W*X，我们希望在输入为2的时候，可以得到输出为1的回归结果，首先要对W进行初始化，初始化的值服从N(0,1)，假设取到的是0.1，得到0.2，和目标值差0.8，经过反向传播去更新W，这次更新到0.2，得到0.4，和目标值差0.6，经过这么十次八次吧，终于得到我们想要的0.5了。</p>
<p>但如果在一开始就有人告诉你，W的值就在0.47附近，那么和目标值一开始就只差0.06，可能只用一两步，就达到了我们想要的目标值0.5，这个告诉我们的人就相当于是预训练模型，调的这一两次就是fine-tuning。</p>
<p>一般我们会选择在数据集相似，但数据集数量很少，或者计算资源很少的情况下使用fine- tuning。</p>
<p><img src="/../img/v2-309bcf3d287cab31aabdeeccaf71b4d0_r.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>（3）剪枝中train from scratch的解释</p>
<p>训练一个大模型 -&gt; 在大模型中剪枝 -&gt; 微调/从头训练</p>
<p>对于剪枝后的模型如何恢复精度目前有好几种方案：</p>
<ol>
<li>从头训练(Trrain From Scratch)：指只保留剪枝后的模型的结构，而不使用其剪枝后的权重。并随机初始化权重，再进行训练（通常使用和训练大模型时相同的学习率计划）。</li>
<li>微调(Finetune)：剪枝后的模型使用小学习率继续训练。</li>
</ol>
<p>总结：</p>
<p>mixup的思想出发点主要在于以下几个方面：</p>
<ol>
<li>提出一种新的生成数据集的近邻分布的方法（新的数据增强的方法）</li>
<li>传统数据增强没有对标签进行近邻关系建模</li>
<li>可以在减少过拟合的同时达到更小的训练误差。</li>
<li>可以用在GAN的实验里，本质上是鉴别器的Regularizer，在生成对抗网络求解超参数的过程中，增加了结构的鲁棒性。</li>
</ol>
<p>同时，这种将随机选择的两个类的数据和标签进行凸组合之后再进行训练的方法，是否也是在给网络提供更多潜在的信息呢。作者认为增加模型容量将使训练误差对大α的敏感性降低，从而使mixup具有更大的优势，有可能是mixup的方法提供了更多的信息，因此才需要增加模型容量来存储这些信息。</p>
<p>一、经验风险最小化和邻近风险最小化</p>
<blockquote>
<p>风险函数：度量平均意义下的模型预测好坏，损失函数的值越小， 模型就越好。</p>
</blockquote>
<p>损失函数的期望就是反映真实世界误差的期望风险，理论上是模型 $f(x,θ)$ 关于联合分布 $P(X,Y) $的平均意义下的代价损失，表达为如下公式：</p>
<p><img src="/../img/image-20221107221254065.png" srcset="/img/loading.gif" lazyload alt="image-20221107221254065"></p>
<p>模型的训练就是一个去拟合数据真实分布的过程，但现实里，只有神知道真实的概率分布，因此我们只能得到所谓的“经验分布”，mixup论文里写成：</p>
<p><img src="/../img/image-20221108001013275.png" srcset="/img/loading.gif" lazyload alt="image-20221108001013275"></p>
<p>理论上认为，训练过程，既然追求收敛，也就是说，训练误差越小越好，可以看作是追逐一种“经验风险最小化”：</p>
<p>经验风险最小化原则一致性条件认为，如果期望风险和经验风险都收敛于某个极小值，则学习过程是一致的。</p>
<p><img src="/../img/image-20221108001125178.png" srcset="/img/loading.gif" lazyload alt="image-20221108001125178"></p>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AE%BA%E6%96%87/">#论文</a>
      
    </div>
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/10/10/%E5%91%A8%E5%BF%97%E5%8D%8E%E9%87%8D%E5%88%B7%E2%80%9C/" title="西瓜书重刷">
                        <span class="hidden-mobile">西瓜书重刷</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="vcomment" class="comment"></div> 
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
  <script>
    var notify = '' == true ? true : false;
    var verify = '' == true ? true : false;
      window.onload = function() {
          new Valine({
              el: '#vcomment',
              app_id: "AwHBUAjSP1GvDVpiBgxfS2Pg-gzGzoHsz",
              app_key: "kMsGLN3hzkQJuLrmqQBgquFF",
              placeholder: "说点什么",
              avatar:"retro",
              visitor: true       

          });
      }
  </script>

 
  <noscript>Please enable JavaScript to view the comments</noscript>



  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  




  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  
    
  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>

  <script defer src="/js/leancloud.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/yinghua.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/xiantiao.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/xiaoxingxing.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/caidai.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
