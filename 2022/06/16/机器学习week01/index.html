

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/icon.jpg">
  <link rel="icon" href="/img/icon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="第一章 绪论1.1 什么是机器学习类似人类通过对经验的利用对新情况做出有效的决策，计算机通过计算的手段，利用经验来改善系统自身的性能。 在计算机系统中，”经验”通常以”数据”形式存在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生”模型”(model)的算法，即”学习算法”(learningalgorithm).有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习第一周">
<meta property="og:url" content="http://example.com/2022/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0week01/index.html">
<meta property="og:site_name" content="摸鱼之家">
<meta property="og:description" content="第一章 绪论1.1 什么是机器学习类似人类通过对经验的利用对新情况做出有效的决策，计算机通过计算的手段，利用经验来改善系统自身的性能。 在计算机系统中，”经验”通常以”数据”形式存在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生”模型”(model)的算法，即”学习算法”(learningalgorithm).有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/photo13.jpeg">
<meta property="article:published_time" content="2022-06-16T11:27:38.737Z">
<meta property="article:modified_time" content="2022-06-25T11:38:00.757Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="机器学习基础理论">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/photo13.jpeg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>机器学习第一周 - 摸鱼之家</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":false},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"AwHBUAjSP1GvDVpiBgxfS2Pg-gzGzoHsz","app_key":"kMsGLN3hzkQJuLrmqQBgquFF","server_url":"https://awhbuajs.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>快乐老家</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                档案馆
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                目录
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/photo11.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="机器学习第一周"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-06-16 19:27" pubdate>
          June 16, 2022 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          26k words
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">机器学习第一周</h1>
            
              <p class="note note-info">
                
                  
                    Last updated on 5 days ago
                  
                
              </p>
            
            <div class="markdown-body">
              
              <h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h1><h3 id="1-1-什么是机器学习"><a href="#1-1-什么是机器学习" class="headerlink" title="1.1 什么是机器学习"></a>1.1 什么是机器学习</h3><p>类似人类通过对经验的利用对新情况做出有效的决策，计算机通过计算的手段，利用经验来改善系统自身的性能。</p>
<p>在计算机系统中，”经验”通常以”数据”形式存在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生”<strong>模型”(model)</strong>的算法，即”学习算法”(learningalgorithm).有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时(例如看到一个没剖开的西瓜)，模型会给我们提供相应的判断(例如好瓜).</p>
<p>如果说计算机科学是研究关于”算法”的学问，那么类似的，可以说机器学习是研究关于”学习算法”的学问.</p>
<h3 id="1-2-基本术语"><a href="#1-2-基本术语" class="headerlink" title="1.2 基本术语"></a>1.2 基本术语</h3><p>假定我们收集了一批关于西瓜的数据，例如(色泽=青绿；根蒂=蜷缩；敲声=浊响)，(色泽=乌黑；根蒂:稍蜷；敲声=沉闷)，(色泽=浅自；根蒂硬挺；敲声=清脆)…</p>
<p>每对括号内是一条<strong>记录</strong>，=的意思是”取值为”。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617192915496.png" srcset="/img/loading.gif" lazyload alt="image-20220617192915496"></p>
<p>从数据中学得模型的过程称为<u><strong>“学习”(learning)或”训练”(training)</strong></u>,这个过程通过执行某个学习算法来完成学得模型对应了关于数据的某种潜在的规律，因此亦称<strong><u>“假设”</u></strong>(hypothesis)；这种潜在规律自身，则称为<u><strong>“真相”或”真实”(ground-truth)</strong></u>，学习过程就是为了找出或逼近真相.本书有时将模型称为<u><strong>“学习器”(learner)</strong></u>，可看作学习算法在给定数据和参数空间上的实例化.</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617200149951-5467313-5467314-5467315.png" srcset="/img/loading.gif" lazyload alt="image-20220617200149951"></p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617200824722-5467707.png" srcset="/img/loading.gif" lazyload alt="image-20220617200824722"></p>
<p>学得模型后，使用其进预测的过程称为<u><strong>“测试”(testing)</strong></u>，被预测的样本称为<u><strong>“测试样本”(testingsample)</strong></u>.例如在学得$f$后，对测试例，可得到其预测标记$ν=f(x)$.</p>
<p><u><strong>“聚类”(clustering)</strong></u>，即将训练集中的西瓜分成若干组，每组称为一个”<u><strong>簇</strong></u>“(cluster)；这些自动形成的簇可能对应一些潜在的概念划分，例如”浅色瓜””深色瓜”，这些概念事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息.</p>
<p>根据<u>训练数据是否拥有标记信息</u>，学习任务可大致划分为两大类”监督学习”(supervisedlearning)和”<strong>无监督学习</strong>“(unsupervisedlearning)，分类和回归是前者的代表，而聚类则是后者的代表.</p>
<p><u>学得模型适用于新样本的能力</u>，称为”<strong><u>泛化</u></strong>“(generalization)能力.具有强泛化能力的模型能很好地适用于整个样本空间.通常假设样本空间的样本均服从独立同分布，一般而言，训练样本越多，我们得到的关于分布的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型.</p>
<h3 id="1-3-假设空间"><a href="#1-3-假设空间" class="headerlink" title="1.3 假设空间"></a>1.3 假设空间</h3><p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618134035759.png" srcset="/img/loading.gif" lazyload alt="image-20220618134035759" style="zoom: 50%;" /></p>
<p>归纳学习有<strong>狭义</strong>与<strong>广义</strong>之分：</p>
<p>广义的归纳学习大体相当于<u>从样例中学习</u>。</p>
<p>狭义的归纳学习则要求<u>从训练数据中学得概念(concept)</u>，因此亦称为<u><strong>“概念学习”或”概念形成”</strong></u>。</p>
<p>举一个西瓜数据集的例子：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">硬挺</td>
<td style="text-align:center">清脆</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
</div>
<p>这里要学习的目标是”好瓜”，表1.1第一行虽然是好瓜，但这是一个已经见过的瓜，不属于“泛化”的范畴，因此引入一个概念——<u><strong>假设空间</strong></u>，里面包含所有假设。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618104530154.png" srcset="/img/loading.gif" lazyload alt="image-20220618104530154"></p>
<p>搜索过程中可以不断删除<u><strong>与正例不一致</strong></u>的假设、和(或)<u><strong>与反例一致</strong></u>的假设，最终获得与训练集一致(即<u>对所有训练样本能够进行正确判断</u>)的假设，这就是我们学得的结果.</p>
<p>与训练集一致的”假设集合”称之为”版本空间”(versionspace).例如，在西瓜问题中，与表1.1训练集所对应的版本空间如图1.2所示.<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_18433441/article/details/55682732">详细过程</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618110202690.png" srcset="/img/loading.gif" lazyload alt="image-20220618110202690"></p>
<h3 id="1-4-归纳偏好"><a href="#1-4-归纳偏好" class="headerlink" title="1.4 归纳偏好"></a>1.4 归纳偏好</h3><p>通过学习得到的模型对应了假设空间中的一个假设，但很可能存在有多个与训练集一致的假设，但与它们对应的模型在面临新样本的时候，却会产生不同的输出.</p>
<p>机器学习算法在学习过程中对某种类型假设的偏好，称为”<strong><u>归纳偏好</u></strong>“(inductivebias),或简称为”偏好”。<u>任何一个有效的机器学习算法必有其归纳偏好</u>。</p>
<p>“奥卡姆剃刀”(Occam’srazor)原则：”若有多个假设与观察一致，则选最简单的那个。</p>
<p>在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能.脱离具体问题，空泛地谈论”什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好.</p>
<h3 id="1-5-习题"><a href="#1-5-习题" class="headerlink" title="1.5 习题"></a>1.5 习题</h3><h4 id="1-5-1"><a href="#1-5-1" class="headerlink" title="1.5.1"></a>1.5.1</h4><p><em>表1. 1 中若只包含编号为 1 和 4 的两个样例，试给出相应的版本空间.</em></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
</div>
<p>表1.1的训练数据集对应的假设空间应该如下：</p>
<p>搜索过程中可以不断删除与正例不一致的假设、和（或）与反例一致的假设。最终将会获得与训练集一致（即对所有训练样本能够进行正确判断）的假设，这就是我们学得的结果。</p>
<p>按照上述过程进行学习：</p>
<p>编号1可以删除：3，5，6，8，9，11-15，17-21，23-30，32-49</p>
<p>编号4可以删除：3，6，15，21，30，48，即剩余假设空间中无可删除的假设</p>
<p>学习过后剩余的假设为：</p>
<p>1，2，4，7，10。</p>
<p>这就是最后的“假设集合”，也就是<strong>“版本空间”</strong>。</p>
<p>1 色泽＝＊，根蒂＝＊，敲声＝＊<br>2 色泽＝青绿，根蒂＝＊，敲声＝＊<br>3 色泽＝乌黑，根蒂＝＊，敲声＝＊<br>4 色泽＝＊，根蒂＝蜷缩，敲声＝＊<br>5 色泽＝＊，根蒂＝硬挺，敲声＝＊<br>6 色泽＝＊，根蒂＝稍蜷，敲声＝＊<br>7 色泽＝＊，根蒂＝＊，敲声＝浊响<br>8 色泽＝＊，根蒂＝＊，敲声＝清脆<br>9 色泽＝＊，根蒂＝＊，敲声＝沉闷<br>10 色泽＝青绿，根蒂＝蜷缩，敲声＝＊<br>11 色泽＝青绿，根蒂＝硬挺，敲声＝＊<br>12 色泽＝青绿，根蒂＝稍蜷，敲声＝＊<br>13 色泽＝乌黑，根蒂＝蜷缩，敲声＝＊<br>14 色泽＝乌黑，根蒂＝硬挺，敲声＝＊<br>15 色泽＝乌黑，根蒂＝稍蜷，敲声＝＊<br>16 色泽＝青绿，根蒂＝＊，敲声＝浊响<br>17 色泽＝青绿，根蒂＝＊，敲声＝清脆<br>18 色泽＝青绿，根蒂＝＊，敲声＝沉闷<br>19 色泽＝乌黑，根蒂＝＊，敲声＝浊响<br>20 色泽＝乌黑，根蒂＝＊，敲声＝清脆<br>21 色泽＝乌黑，根蒂＝＊，敲声＝沉闷<br>22 色泽＝＊，根蒂＝蜷缩，敲声＝浊响<br>23 色泽＝＊，根蒂＝蜷缩，敲声＝清脆<br>24 色泽＝＊，根蒂＝蜷缩，敲声＝沉闷<br>25 色泽＝＊，根蒂＝硬挺，敲声＝浊响<br>26 色泽＝＊，根蒂＝硬挺，敲声＝清脆<br>27 色泽＝＊，根蒂＝硬挺，敲声＝沉闷<br>28 色泽＝＊，根蒂＝稍蜷，敲声＝浊响<br>29 色泽＝＊，根蒂＝稍蜷，敲声＝清脆<br>30 色泽＝＊，根蒂＝稍蜷，敲声＝沉闷<br>31 色泽＝青绿，根蒂＝蜷缩，敲声＝浊响<br>32 色泽＝青绿，根蒂＝蜷缩，敲声＝清脆<br>33 色泽＝青绿，根蒂＝蜷缩，敲声＝沉闷<br>34 色泽＝青绿，根蒂＝硬挺，敲声＝浊响<br>35 色泽＝青绿，根蒂＝硬挺，敲声＝清脆<br>36 色泽＝青绿，根蒂＝硬挺，敲声＝沉闷<br>37 色泽＝青绿，根蒂＝稍蜷，敲声＝浊响<br>38 色泽＝青绿，根蒂＝稍蜷，敲声＝清脆<br>39 色泽＝青绿，根蒂＝稍蜷，敲声＝沉闷<br>40 色泽＝乌黑，根蒂＝蜷缩，敲声＝浊响<br>41 色泽＝乌黑，根蒂＝蜷缩，敲声＝清脆<br>42 色泽＝乌黑，根蒂＝蜷缩，敲声＝沉闷<br>43 色泽＝乌黑，根蒂＝硬挺，敲声＝浊响<br>44 色泽＝乌黑，根蒂＝硬挺，敲声＝清脆<br>45 色泽＝乌黑，根蒂＝硬挺，敲声＝沉闷<br>46 色泽＝乌黑，根蒂＝稍蜷，敲声＝浊响<br>47 色泽＝乌黑，根蒂＝稍蜷，敲声＝清脆<br>48 色泽＝乌黑，根蒂＝稍蜷，敲声＝沉闷<br>49 Ø</p>
<h4 id="1-5-2"><a href="#1-5-2" class="headerlink" title="1.5.2"></a>1.5.2</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_26371477/article/details/102292685?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5-102292685-blog-103812745.pc_relevant_antiscanv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5-102292685-blog-103812745.pc_relevant_antiscanv3&amp;utm_relevant_index=10">代码实现</a></p>
<p><em>与使用单个合取式来进行假设表示相比，使用”析合范式”将使得假设空间具有更强的表示能力.例如</em></p>
<p><em>好瓜$\leftrightarrow$((色泽=all)$\cap$(根蒂=蜷缩) $\cap$(敲声=all )) $\cup$ ((色泽=乌黑) $\cap$ (根蒂= all)$\cap$(敲声=沉闷)),</em></p>
<p>会把”(色泽=青绿)$\cap$(根蒂=蜷缩) $\cap$(敲声=清脆 <em>)”以及”(色泽=乌黑)$\cap$(根蒂=硬挺) $\cap$(敲声=沉闷 </em>)”都分类为”好瓜”。若使用最 多包含 $k$个合取式的析合范式来表达表1. 1 西瓜分类问题的假设空 间 ,试估算共有多少种可能的假设.*</p>
<blockquote>
<p>知识储备</p>
<p>合取式：是用合取真值联结词“∧”将两个或两个以上的命题联结起来而形成的命题形式。</p>
<p>析取式：用析取真值连接词“∨”将两个或两个以上的命题联结而成的一种命题形式</p>
<p>合取：相当于交集但不是交集</p>
<p>析取：相当于并集但不是并集</p>
<p>合取范式（合析范式）：有限个简单析取式构成的合取式</p>
<p>析取范式（析合范式）：由有限个简单合取式构成的析取式称为析取范式。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">编号</th>
<th style="text-align:center">色泽</th>
<th style="text-align:center">根蒂</th>
<th style="text-align:center">敲声</th>
<th style="text-align:center">好瓜</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">蜷缩</td>
<td style="text-align:center">浊响</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">青绿</td>
<td style="text-align:center">硬挺</td>
<td style="text-align:center">清脆</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">乌黑</td>
<td style="text-align:center">稍缩</td>
<td style="text-align:center">沉闷</td>
<td style="text-align:center">否</td>
</tr>
</tbody>
</table>
</div>
<p>表中4个样例，3种属性，属性个数分别为2，3，3，假若考虑没有泛化属性和空集的情况下，剔除含通配符和相同的项，得到无冗余的假设空间共有2$\times$3$\times$3=18种假设，这18种假设的自由组合成的析合范式能够唯一的表示所有的假设。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">色泽=青绿</td>
<td style="text-align:center">色泽=乌黑</td>
<td style="text-align:center">——</td>
</tr>
<tr>
<td style="text-align:center">b</td>
<td style="text-align:center">根蒂=蜷缩</td>
<td style="text-align:center">根蒂=稍蜷</td>
<td style="text-align:center">根蒂=硬挺</td>
</tr>
<tr>
<td style="text-align:center">c</td>
<td style="text-align:center">敲声=浊响</td>
<td style="text-align:center">敲声=清脆</td>
<td style="text-align:center">敲声=沉闷</td>
</tr>
</tbody>
</table>
</div>
<p>可列集合为（$a_1<script type="math/tex">b_1</script>c_1$, $a_1b_1c_2$ ,……, $a_2b_3c_3$)，将其简化为（$1,2,3,……,18$),</p>
<p>$k=1$时，所有的析合范式为：$(1,2,3,……18)$。</p>
<p>$k=2$时，所有的析合范式为：$((1,2),(1,3),(1,4),(1,5),……(16,17),(16,18),(17,18))$。</p>
<p>有可能的析合范式的个数为：$17+16+……+3+2+1$=153。</p>
<p>$k=3$时，析合范式的个数为816,代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">result=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">17</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((i+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((j+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>            <span class="hljs-built_in">print</span>((i,j,k))<br>            result=result+<span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>$k=4$时，析合范式的个数为3060,代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">result=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> a1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">16</span>):<span class="hljs-comment">#这里16和循环次数相加就等于20</span><br>    <span class="hljs-keyword">for</span> a2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((a1+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>        <span class="hljs-keyword">for</span> a3 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((a2+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>            <span class="hljs-keyword">for</span> a4  <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((a3  + <span class="hljs-number">1</span>), <span class="hljs-number">19</span>):<br>                <span class="hljs-built_in">print</span>((a1 ,a2 ,a3 ,a4 ))<br>                result=result+<span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<h4 id="1-5-3"><a href="#1-5-3" class="headerlink" title="*1.5.3"></a>*1.5.3</h4><p>若数据包含噪声，则假设空间中有可能不存在与所有训练样本都一致 的假设，在此情形下，试设计一种归纳偏好用于假设选择.</p>
<p><u>不会</u></p>
<p>数据包含噪声，其含义就是，存在训练集本身的部分数据，其<u>属性取值对应的标记值是错误的</u>。对于噪声，最理想的情况是去除所有噪声，即将这部分“错误”的数据剔除出训练集。但事实上，单从数据集本身来剔除噪声并无通用的办法，甚至无法直接判断哪些数据属于噪声。</p>
<p>通俗来讲，我们可以先认为所有不矛盾的数据是正确的，只有哪些属性值相同但标记值不同的数据，“相互矛盾”的情况下，才剔除一部分数据使矛盾消除，此时剔除的方法可以归纳为一种偏好。 </p>
<p>例如，属性值相同的两个数据，其标记值分别为正例和反例，可以设计归纳偏好为：<u>始终保留正例的数据，或始终保留反例的数据。</u><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/MaxQuYY/article/details/120287245">原文链接</a></p>
<h4 id="1-5-4"><a href="#1-5-4" class="headerlink" title="*1.5.4"></a>*1.5.4</h4><p>换用其它性能度量，试证明没有免费的午餐定理成立。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48493722">公式推导</a></p>
<h4 id="1-5-5"><a href="#1-5-5" class="headerlink" title="1.5.5"></a>1.5.5</h4><p>试述机器学习能在互联网搜索的哪些环节起什么作用.</p>
<ol>
<li>在向搜索引擎提交信息阶段，能够从提交文本中进行信息提取，进行语义分析。</li>
<li>在搜索引擎进行信息匹配阶段，能够提高问题与各个信息的匹配程度。</li>
<li>在向用户展示搜索结果的阶段，能够根据用户对结果感兴趣的程度进行排序。 </li>
</ol>
<h1 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h1><h3 id="章节主要内容"><a href="#章节主要内容" class="headerlink" title="章节主要内容"></a>章节主要内容</h3><p>在第一章绪论中，我们知道要根据具体的问题选择具体的算法和归纳偏好。那么要怎么判定我们的选择是正确的呢？这就需要拥有一套规范的模型评估与选择方法论了。</p>
<p>具体的章节思路可参考如下图解。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//5328356-6afc770c7199ac3d.jpeg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8e369f73a0cc">参考链接</a></p>
<h3 id="2-1-经验误差与过拟合"><a href="#2-1-经验误差与过拟合" class="headerlink" title="2.1 经验误差与过拟合"></a><strong>2.1 </strong>经验误差与过拟合</h3><p>——机器学习为什么需要一套模型评估与选择方法论？</p>
<p>在前一章的学习中，我们知道<u>机器学习是对数据集的泛化过程，即从输入的数据中归纳出一套能适用于所有潜在样本的“普遍规律”</u>。可因为训练数据不够充分，机器学习出来的模型并没办法涵盖所有的情况，这就会导致学习器的实际预测输出与样本的真实输出之间存在“误差”。</p>
<p>学习器在训练集上的误差称为“经验误差”，在新样本上的误差称为“泛化误差”。很明显，要使得分类器尽可能的有用，我们应该要让泛化误差仅可能的小。可惜在现实环境中，我们很难知道新样本是什么样的，所以我们实际能做的只有努力使经验误差最小化。</p>
<p>但如果将算法设计的尽可能百分百的满足所有训练样本，就忘了学习器真正要达到的是泛化误差尽可能小，而不是目前的折中方案降低经验误差。而在降低经验误差的道路上，有着机器学习领域最大的难题之一：<u><strong>“过拟合”</strong></u>。</p>
<p>“过拟合”是指学习器对训练样本学的太好了，导致泛化程度不够（机器学习本身就是一个泛化过程），没法适应新的数据样本。与之相反的还有一个“欠拟合”的概念，就是对训练样本中的一般规律都没学习好。举个例子，你通过姚明这个训练样本来学习一个人类判断器，如果你将身高两米二十以上作为判断是否是人的依据，那就是过拟合了；而如果你没有“直立行走”这样的特征都没有找出来作为判断是否是人的标准，那就是欠拟合了。</p>
<p>所以，为什么需要一套模型评估与选择的方法论呢？<u><strong>因为我们的训练数据没法真正代表真实的样本空间，而泛化误差无法直接获得，经验误差又因为过拟合的存在而不适合作为标准，所以我们才需要一套模型评估与选择的方法论。</strong></u></p>
<h4 id="2-1-1-相关概念"><a href="#2-1-1-相关概念" class="headerlink" title="2.1.1 相关概念"></a>2.1.1 相关概念</h4><p>误差分为训练误差、经验误差和泛化误差，前两种为在学习集上的误差，最后一种是在新样本上的误差。</p>
<p>错误率$E$=分类错误的样本数$a$/总样本数$m$</p>
<p>精度=$1 - $ 错误率=$1-\frac{a}{m}$</p>
<p>误差=学习器的实际预测输出-真实输出</p>
<p><strong>欠拟合与过拟合的例子</strong>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618142530466.png" srcset="/img/loading.gif" lazyload alt="image-20220618142530466"></p>
<h3 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2  评估方法"></a><strong>2.2 </strong> 评估方法</h3><p>——在已经知道为什么要对模型进行评估后，在不知道泛化误差的情况下，我们该如何进行评估呢？</p>
<p>一个合理的思路是：<u>既然我们没法拿到新样本来进行泛化误差计算，那么我们可以从训练样本中取出一部分来，假装它是一组新样本，并用这些样本计算出来的误差作为泛化误差的近似。</u>这组选出来的样本被称为“测试集”，测试集上的误差被称为测试误差。我们学习本书的一个主要目的是学会机器学习领域的脉络和背后逻辑，这种评估思路是科学研究领域的一个常用思路。领悟这种思路有助于我们解决其它领域上的问题）</p>
<p>不过我们需要注意一点，那就是测试集应该尽量不与训练集重合，否则测试集计算出的误差将没法准确代表该学习器的泛化能力。</p>
<p>基于这个考虑，书中列出了以下几种把包含$m$个样例的数据集$D$划分为训练集$S$和测试集$T$的办法。</p>
<h4 id="［1］留出法（hold-out）"><a href="#［1］留出法（hold-out）" class="headerlink" title="［1］留出法（hold-out）"></a><strong>［1］留出法（hold-out）</strong></h4><p>直接将$D$划分为互斥的两部分$S和T$，在$S$上训练出模型后，用$T$来评估测试误差，即 $D=S\cup T$，$S\cap T=\empty$。</p>
<p>需要注意的是训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。</p>
<blockquote>
<p>“分层采样” (stratified sampling)：一种保留类别比例的采样方式. 例如通过对 D 进行分层采样而获得含 70% 样本的训练集 S 和含 30% 样本的测试集 T， 若 D 包含 500 个正例、 500 个反例，则分层采样得到的 S 应包含 350 个正例、 350 个反例?而 T 则包含 150 个正例和 150 个反例；若 S、 T 中样本类别比例差别很大，则误差估计将由于训练/测试数据分布的差异 而产生偏差.</p>
</blockquote>
<p>在样本数量上的划分上，为了平衡模型的准确性与测试结果的保真性，常见做法是将大约 2/3～ 4/5 的样本用于训练，剩余样本用于测试（一般而言，测试集至少应含 30 个样例）。</p>
<h4 id="［2］交叉验证法（cross-validation）"><a href="#［2］交叉验证法（cross-validation）" class="headerlink" title="［2］交叉验证法（cross validation）"></a><strong>［2］交叉验证法（cross validation）</strong></h4><p>将数据集 $D $划 分为 $k $个互斥子集，即$D=D_1\cup D_2\cup ……\cup D_k$，$D_i\cap D_j=\empty $，每次用$k-1 $个子集的并集作为训练集，余下的那个子集作为测试集；对获得的 $k$组训练/测试集进行 $k$ 次训练和测试，得到这 $k$ 个测试结果的均值。</p>
<p>显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 $k $的取值，为强调这一点，通常把交叉验证法称为 “$ k $折交叉验证” (k-fold cross validation). $k $最常用的取值是 10，此时称为 10 折交叉验 证；其他常用的$k$值有 5、 20 等.</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618155420458.png" srcset="/img/loading.gif" lazyload alt="image-20220618155420458"></p>
<p>交叉验证法的一 个特例:留一法(Leave-One-Out，简称 LOO) . 假定数据集 $D$ 中包含 $m$ 个样本，令 $k=m$ ，即子集数量设定为样本数量。</p>
<blockquote>
<p>10次10 折交叉验证法与100 次留出法都是进行了 100 次训练/测试</p>
</blockquote>
<h4 id="［3］自助法（bootstrapping）"><a href="#［3］自助法（bootstrapping）" class="headerlink" title="［3］自助法（bootstrapping）"></a><strong>［3］自助法（bootstrapping）</strong></h4><p>每次从$D$中随机复制一个样本到$D1$中，重复$m$次，会得到一个拥有$m$个数据样本的$D1$数据集。显然，$D$中的一部分数据会多次出现在$D1$中，而另一部分样本不出现。根据平均分布概率计算，大约有36.8%的数据不会被复制到$D1$中。</p>
<p>可以做一个简单的估计，样本在 $m$ 次采样中始终不被采到的概率是 $(1-\frac{1}{m})^m$， 取极限得到$\lim_{m\to \infin}(1-\frac{1}{m})^m \to \frac{1}{e} \approx. 0.368$</p>
<p>于是我们可将$ D’ $用作训练集， $D/D’ $用作测试集；这样实际评估的模型与期望评估的模型都使用 $m $个训练样本，而我们仍有数据总量约 $1/3$ 的，没在训练集中出现的样本用于测试。这样的测试结果，亦称”包外估计” (out-of-bag estimate).</p>
<h4 id="［4］注意点"><a href="#［4］注意点" class="headerlink" title="［4］注意点"></a><strong>［4］注意点</strong></h4><p>训练/测试集的划分要尽可能保持数据分布一致性。</p>
<p>单次划分往往不够稳定可靠，一般要采用若干次随机划分、重复进行实验评估后取平均值作为评估结果。</p>
<p>训练/测试集的划分比例没有完美答案，训练样本多会使得模型更接近$D$，测试样本多会使得评估结果更可靠，这其中的取舍因人/场景而异。常见的训练/测试划分比例是2:1～4:1。</p>
<h4 id="［5］调参"><a href="#［5］调参" class="headerlink" title="［5］调参"></a><strong>［5］调参</strong></h4><p>不同的参数其实就代表着不同的模型了。一般参数分两种：一类是算法的参数，亦称“超参数”，如聚类要分的簇数量$k$；一类是模型的参数，如神经网络中每个节点的权重。前者多为人工选择一组候选，后者是让机器自己学习。</p>
<p>常用的做法是对每个参数选定一个范围和变化步长，<u>例如在 [0， 0.2] 范围内以 0.05 为步长，则实际要评估的候选参数值有 5 个，最终是从这 5 个候选值中产生选定值。简单估算一下：假定算法有 3 个参数，每个参数仅考虑 5 个候选 值，这样对每一组训练/测试集就有 53 = 125 个模型需考察；</u>很多强大的学习算 法有大量参数需设定，这将导致极大的调参工程量，例如大型”深度学习模型甚至有上百亿个参数。</p>
<p>调参是机器学习的重点，也是决定模型性能的关键。一般调参过程中，会将训练数据再次划分为训练集和验证集（validation set）。具体包含关系如下：<img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619171542448.png" srcset="/img/loading.gif" lazyload alt="image-20220619171542448"></p>
<h4 id="［6］适用性"><a href="#［6］适用性" class="headerlink" title="［6］适用性"></a><strong>［6］适用性</strong></h4><p>自助法在数据集较小、难以有效划分训练/测试集时很有用</p>
<p>自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。</p>
<p>留出法和交叉验证法由于都把数据集中的一部分用来测试，没有参与训练，因此必然会引入一些因训练样本规模不同而导致的估计偏差，留一法受影响较小，但计算复杂度又太高了。</p>
<h3 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3  性能度量"></a><strong>2.3 </strong> 性能度量</h3><p>——在了解了有效可行实验评估方法后，接下来我们需要了解一下具体的衡量模型泛化能力的评价标准，即性能度量（performance measure）</p>
<p>性能度量反映了任务需求，使用不同的性能度量会导致对模型的评判结果不同。这意味着模型的“好坏”是相对的，什么样的模型是好的，不仅取决于算法和数据，还决定于任务需求。</p>
<p>在预测任务中，给定样例集 $D = {(x1 , y1) , (x2 ， y2)， . . . , (xm, ym)} $， 其中 $yi$ 是示例 $xi$ 的真实标记。要评估学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$  与真实标记  $y$ 进行比较。</p>
<p>回归任务<strong>最常用的性能度量</strong>是”<strong>均方误差</strong>“ (mean squared error)：</p>
<script type="math/tex; mode=display">
E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(xi)-yi)^2</script><p>更一般的，对于数据分布 $Ð$ 和概率密度函数 $p(.) $， 均方误差可描述为</p>
<script type="math/tex; mode=display">
E(f;Ð)=\int_{x～Ð}(f(x)-y)^2p(x)dx</script><h4 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h4><p>对样例集 $D$，分类错误率定义为：</p>
<script type="math/tex; mode=display">
E(f;D)=\frac{1}{m}\sum_{i=1}^{m}I(f(xi)\ne yi)</script><p>精度则定义为：</p>
<script type="math/tex; mode=display">
acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}I(f(xi)= yi)=1-E(f;D)</script><p>更一般的，对于数据分布 $Ð$ 和概率密度函数 $p(.)$ ，错误率与精度可分别描述为</p>
<script type="math/tex; mode=display">
E(f;Ð)=\int_{x～Ð}(f(x)\ne y)p(x)dx</script><script type="math/tex; mode=display">
acc(f;Ð)=\int_{x～Ð}(f(x)= y)p(x)dx=1-E(f;Ð)</script><h4 id="2-3-2-查准率、查全率与-F1"><a href="#2-3-2-查准率、查全率与-F1" class="headerlink" title="2.3.2 查准率、查全率与$F1$"></a>2.3.2 查准率、查全率与$F1$</h4><p>查准率和查全率可以理解为”挑出的西瓜中有多少比例是好瓜”，或者”所有好瓜中有多少比例被挑了出来”，或者”检索出的信息中有多少比例是用户感兴趣的” 和”用户感兴趣的信息中有多少被检索出来了”。</p>
<p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例 (true positive) 、假正例 (false positive) 、真反例 (true negative) 、 假反例 (false negative) 四种情形，令 $TP、 FP、 TN、 FN$ 分别表示其对应的样例数，则显然有 $TP+FP+TN+FN=样例总数$。分类结果的误差矩阵或者精度矩阵称为”混淆矩阵” (confusion matrix)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618175331853.png" srcset="/img/loading.gif" lazyload alt="image-20220618175331853"></p>
<p>查准率 $P $ 与查全率 $R$ 分别定义为：</p>
<p>$P=\frac{TP}{TP+FP}$  =  真正例 / 预测出的正例</p>
<p>$R=\frac{TP}{TP+FN}$ =。真正例 / 实际上的正例</p>
<p>二者通常呈反比。</p>
<p>举个例子：假设有10个西瓜，6个好瓜，4个坏瓜。我们将这十个瓜按照预测结果排序，最可能是好瓜的排在前头，最不可能的排在最后，然后控制学习器的分类阀值来依次逐个把样本作为好瓜来进行预测，则可以计算出不同的阀值时的$P$和$R$如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>指标</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody>
<tr>
<td>TP</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>6</td>
<td>6</td>
<td>6</td>
<td>6</td>
</tr>
<tr>
<td>FN</td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>FP</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>TN</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>P</td>
<td>X</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>6/7</td>
<td>6/8</td>
<td>6/9</td>
<td>6/10</td>
</tr>
<tr>
<td>R</td>
<td>0</td>
<td>1/6</td>
<td>2/6</td>
<td>3/6</td>
<td>4/6</td>
<td>5/6</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p>由上边例子可以看到，P和R的值也基本满足了一方升高，另一方下降的状况，通常只有在一些简单的任务（比如我举的这个）中，才可能使查全率和查准率都很高。以查准率为纵轴、查全率为横轴作图，就得到了查准率－查全率曲线，简称“P-R曲线”。</p>
<p>再举个例子：</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//20160721114615857-20220619182907525.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>Inst#是样本序号，图中有20个样本。Class是ground truth 标签，p是positive样本（正例），n当然就是negative（负例） score是分类器对于该样本属于正例的可能性的打分。因为一般模型输出的不是0,1的标注，而是小数，相当于置信度。</p>
<p>然后设置一个从高到低的阈值y，大于等于阈值y的被正式标注为正例，小于阈值y的被我正式标注为负例。</p>
<p>显然，设置n个阈值，就能得到n种标注结果，评判模型好不好使。</p>
<p>比如阈值0.9，只有第一个样本被判断为正例，那么我的查准率precision就是100%，但是查全率recall就是10%。阈值0.1，所有样本都被我判断为正例，查全率是100%，查准率就是50%</p>
<p>最后我能得到若干对precision，recall值(P,R) :  (1, 0.1),… ,(0.5,1),将这若干对画在图上，再连接起来就是这个pr曲线了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//20160721111312507.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者。当曲线有相交时，很难断言两者的优劣。真要判别时，“平衡点”（Break-Even Point）是一个不错的度量方法。下图是一个具体的示意图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618181148275.png" srcset="/img/loading.gif" lazyload alt="image-20220618181148275"></p>
<p>平衡点(Break-Event Point，简称 BEP)，它是” 查准率=查全率”时的取值，例如上图中基于 BEP的比较，可认为学习器 A 优于 B。</p>
<p>但 BEP 还是过于简化了些，更常用的是 F1 度量：</p>
<script type="math/tex; mode=display">
F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}</script><p>$F1$ 是基于查准率与查 全率的调和平均 (harinonic mean)定义的:</p>
<script type="math/tex; mode=display">
\frac{1}{F1}=\frac{1}{2}.(\frac{1}{P}+\frac{1}{R})</script><p>在不同的条件下，对查准率和查全率的重视程度有所不同。比如在大数据推送时，为了少打扰用户，更希望能推荐用户感兴趣的广告，此时查准率要比查全率更重要；在追捕逃犯时，为了不漏掉逃犯，此时查全率比查准率更重要。为了表达出对查准率/查全率的不同偏好，定义了$F1 $度量的一般形式</p>
<script type="math/tex; mode=display">
F_\beta=\frac{(1+\beta^2)\times P \times R}{(\beta^2 \times P)+R}</script><p>$ß&gt; 1$ 时查全率有更大影响 ; $ß &lt; 1$ 时查准率有更大影响。</p>
<p>很多时候我们有多个二分类混淆矩阵，例如进行多次训练/测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练/测试，希望估计算法的”全局” 性能；甚或是执行多分类任务，每两两类别的组合都对应一个混淆矩阵，总之，我们希望在 $n$ 个二分类混淆矩阵上综合考察查准率和查全率。</p>
<p>一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，记为 $(P_1， R_1 ) ， (P_2 ， R_2) ，…… ， (Pn ， Rn)$ ，再计算平均值，这样就得到”宏查准率” ($macro-P$) 、”宏查全率” ($macro-R$) ，以及相应的”宏 $F1$” ($macro-F1$):</p>
<script type="math/tex; mode=display">
macro-P=\frac{1}{n}\sum^n_{i=1}P_i</script><script type="math/tex; mode=display">
macro-R=\frac{1}{n}\sum^n_{i=1}R_i</script><script type="math/tex; mode=display">
macro-F1=\frac{2\times macro-P \times macro-R}{macro-P+macro-R}</script><p>还可先将各混 淆矩阵的对应元素进行平均，得到 $TP 、FP 、 TN 、FN$ 的平均值，分别记为 $\overline{TP}、 \overline{FP}、 \overline{TN}、 \overline{FN}$，再基于这些平均值计算出”微查准率 “(micro-P) 、 “微查全率” (micro-R)和”微F1” (micro-F1):</p>
<script type="math/tex; mode=display">
micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}</script><script type="math/tex; mode=display">
micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}</script><script type="math/tex; mode=display">
micro-F1=\frac{2\times micro-P\times micro-R}{micro-P+micro-R}</script><h4 id="2-3-3-ROC-与-AUC"><a href="#2-3-3-ROC-与-AUC" class="headerlink" title="2.3.3 ROC 与 AUC"></a>2.3.3 ROC 与 AUC</h4><p>ROC：“受试者工作特征”（receiver operating characteristic）曲线，与P-R 曲线类似，只不过取用“真正利率”（TPR ）作为纵轴，“假正例率”（FPR）作为横轴 ，两者分别定义为</p>
<script type="math/tex; mode=display">
TPR=\frac{TP}{TP+FN},FPR=\frac{FP}{TN+FP}</script><p>显示 ROC 曲线的图称为 “ROC 图”，显然，对角线对应于 “随机猜测” 模型，而点 ($0，1)$ 则对应于将所有正例排在所有反例之前的”理想模型”。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619155415423.png" srcset="/img/loading.gif" lazyload alt="image-20220619155415423"></p>
<p>现实任务中测试样例有限 ，无法产生图 a 中的光滑 ROC 曲线，只能绘制出如图 b 所示的近似 ROC 曲线。绘图过程很简单：给定 $m^+ $个正例和$m^-$ 个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为 0， 在坐标$ (0， 0)$ 处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为 $(x， y) $， 当前若为真正例，则对应标记点的坐标为 $(x， y + \frac{1}{m^+})$ ;当前若为假正例，则对应标记点的坐标为 ($( x + \frac{1}{m^-},y)$ ，然后用线段连接相邻点即得。</p>
<p>​        进行学习器的比较时，与 P-R 图相似， 若一个学习器的 ROC 曲线被另 一个学习器的曲线完全”包住”， 则可断言后者的性能优于前者；若两个学习 器 的 ROC 曲线发生交叉，则难以一般性地断言两者孰优孰劣。此时如果一定要进行比较，则较为合理的判据是比较 ROC 曲线下的面积，即 AUC (Area Under ROC Curve) 。</p>
<p>​        从定义可知， AUC 可通过对 ROC 曲 线下各部分的面积求和而得,估算为</p>
<script type="math/tex; mode=display">
AUC=\frac{1}{2}\sum^{m-1}_{i=1}(x_{i+1}-x_i).(y_i+y_{i+1})</script><h4 id="2-3-4-代价敏感错误率与代价曲线"><a href="#2-3-4-代价敏感错误率与代价曲线" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线"></a>2.3.4 代价敏感错误率与代价曲线</h4><p>代价敏感错误率代表数据的平均总体代价。</p>
<p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可为错误赋予”非均等代价” (unequa1 cost)。以二分类任务为例，我们可根据任务的领域知识设定一个”代价矩阵” (cost matrix) ，其中 $cost_{ij} $表示将第$ i $类样本预测为第 $j $类样本的代价。一般来说， $cost_{ii} = 0$；若将第 0 类判别为第 1 类所造成的损失更大，则 $cost_{01} &gt; cost_{10}$; 损失程度相差越大， $cost_{01} 与 cost_{10}$ 值的差别越大。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">真实</th>
<th style="text-align:center">预测</th>
<th style="text-align:center">类别</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">类别</td>
<td style="text-align:center">第0类</td>
<td style="text-align:center">第1类</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">第0类</td>
<td style="text-align:center">0</td>
<td style="text-align:center">$cost_{01{}}$</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">第1类</td>
<td style="text-align:center">$cost_{10}$</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
</div>
<p>上面的例子中都隐式地假设了均等代价，所定义的错误率是直接计算错误次数。而在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化”总体代价” (total cost). 若将表中的第 0 类作为正类、第 1 类作为反类，令 $D^+$ 与 $D^-$分别代表样例集 D 的正例子集和反例子集，则”代价敏感” (cost-sensitive)错误率为</p>
<script type="math/tex; mode=display">
E(f;D;cost)=\frac{1}{m}(\sum_{x_i\in D^+}I(f(x_i)\ne y_i)\times cost_{01}+\sum_{x_i\in D^-}I(f(x_i)\ne y_i)\times cost_{10})</script><p>在非均等代价下， ROC 曲线不能直接反映出学习器的期望总体代价，而”代价曲线” (cost curve) 则可达到该目的.代价曲线图的横轴是取值为 [0,1]的正例概率代价</p>
<script type="math/tex; mode=display">
P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}</script><p>其中 $p$ 是样例为正例的概率；纵轴是取值为 [0,1] 的归一化代价。</p>
<script type="math/tex; mode=display">
P(+)cost=\frac{FNP\times p\times cost_{01}+FNP\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}</script><p>其中 $FPR$ 是假正例率， $FNR = 1 - TPR$ 是假反例率。</p>
<p>代价曲线的绘制很简单：ROC 曲线上每一点对应了代价平面上的一条线段 ， 设 ROC 曲线上点的坐标为 $(TPR， FPR)$ ，则可相应计算出 $FNR$，然后在代价平面上绘制 一条从 $(0， FPR)$ 到 $(1 ，FNR)$ 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将 ROC 曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619191716330.png" srcset="/img/loading.gif" lazyload alt="image-20220619191716330"></p>
<h3 id="2-4-比较检验"><a href="#2-4-比较检验" class="headerlink" title="2.4  比较检验"></a><strong>2.4 </strong> 比较检验</h3><p>——有了实验评估方法和性能度量，就要研究如何应用方法和度量指标去对学习器的性能进行评估比较了</p>
<p>研究怎么来做“比较”是很有必要的，因为第一，我们要的是<strong>泛化性能</strong>，但是能用的只是测试性能；第二，测试性能和测试集的选择对测试结果有很大影响；第三，有的机器学习算法本身也有随机性，对同一测试集的多次测试结果也可能会不同。</p>
<p>为了解决这些问题，统计假设检验（hypothesis test）为我们提供了重要的依据。</p>
<h4 id="2-4-1-假设检验"><a href="#2-4-1-假设检验" class="headerlink" title="2.4.1 假设检验"></a>2.4.1 假设检验</h4><blockquote>
<p>西瓜书介绍的是假设检验方法，个人认为更好的方式应该是求泛化性能的置信区间，而不是进行假设检验。置信区间不仅可以得到泛化性能的一个区间，同时它也可以进行假设检验。所以，置信区间完全可以替换掉假设检验。</p>
<p>泛化性能的估计值 u=k/n，它是泛化性能p的一个无偏估计，E(u)=p，u的方差为 u<em>(1-u)/n，基于中心极限定理知道 u 渐进符合正态分布 N[p,u</em>(1-u)/n]。知道了u的抽样分布，u的置信区间就可以计算出来。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/259232881">如何计算置信区间</a></p>
</blockquote>
<p>假设检验中的“假设”是对学习器泛化错误率分布的某种猜想或判断，现实任务中学习器的泛化错误率不可知，只能获知其测试错误率，尽管二者未必相同，但肯定相似，因此， 可根据测试错误率估推出泛化错误率的分布。</p>
<p>然后通过假设的验证结果来对不同的学习器或模型的性能进行判断。比如假设“学习器A和B性能相同”，当该假设被拒绝时，说明学习器A和B具有显著差异，这时候错误率较低的学习器性能较优。</p>
<p>假设检验的具体逻辑和使用方法是这样的：</p>
<p>［1］设定一个假设，比如“一个机器学习真正的泛化错误率不大于0.3”</p>
<p>［2］设定一个置信概率“显著度a”，a的一般取值为0.05、0.1；a代表的意思是当我们的假设成立的概率在（1-a，1］的范围内时，我们认为是成立的。</p>
<p>［3］计算使假设在置信范围内成立的最大值是多少，比如根据上边［1］中的假设，要使泛化错误率不大于0.3成立，即泛化错误率小于0.3的概率大于（1-a）。要计算这个，我们要算出要使错误率大于0.3的概率之和小于a时的最大泛化错误率是多少。</p>
<p>［4］比较计算出的满足假设的最大值和我们实际计算出的值，如果我们实际计算出来的错误率已经大于最大可能的错误率了，说明假设不成立。</p>
<p>［5］在这里的假设中，假设不成立说明我们的学习器错误率要大于0.3啊，这是个很烂的学习器，我们还需要继续调优。</p>
<p>在实际实验时，我们会多次使用留出法或交叉验证法进行多次训练/测试，那么我们实际上会得到多个测试错误率（这里假设为$k$个）。我们可以通过求这些错误率的平均和方差来将假设检验转换为自由度为$k-1$的$ t $分布。通过查询 $t$ 检验常用临界表可以很方便的计算出假设是否成立。</p>
<p>书中提到的交叉验证 $t $检验、Friedman检验与Nemenyi后续检验都是基于一样的假设检验流程的稍微变化。其中交叉验证 $t$ 检验是针对两种学习器之间性能的比较，Friedman检验与Nemenyi后续检验是针对多个学习器之间性能的比较。在这里就不一一介绍了。</p>
<h3 id="2-5-偏差与方差"><a href="#2-5-偏差与方差" class="headerlink" title="2.5 偏差与方差"></a><strong>2.5 </strong>偏差与方差</h3><p>——对学习算法除了通过实验估计其泛化性能，我们还需要理解“为什么”具有这样的性能，“偏差与方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。</p>
<p>省略具体的算法和公式推导过程，偏差与方差分解是对学习算法的期望泛化错误率的分解，分解结果是下边这个重要的公式</p>
<p>$E(f;D)=bias^2(x)+var(x)+\varepsilon^2$</p>
<p>也就是说，泛化误差可分解为偏差、方差与噪声之和。</p>
<p>其中，偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法的拟合能力；方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所带来的影响；噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<p>偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p>
<p>一般来说，偏差与方差是有冲突的。要使偏差小则需要算法对数据充分拟合，这就有可能会导致过拟合，这样对新样本的适应性差，就会导致方差变高。反之亦然，拟合过低，偏差较大，但是方差会相对较低。</p>
<blockquote>
<p>很多学习算法都可控制训练程度，例如决策树可控制层数，神经网络可控制训练轮数，集成学习方法可控制基学习器个数。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619224405067.png" srcset="/img/loading.gif" lazyload alt="image-20220619224405067"></p>
<h3 id="2-6-总结"><a href="#2-6-总结" class="headerlink" title="2.6 总结"></a>2.6 总结</h3><p>泛化误差无法获得，经验误差因为过拟合的存在而不适合作为标准，导致我们需要专门的模型评估方法来测量学习器的效果。</p>
<p>专门的模型评估方法是通过从数据集中选取一部分数据作为测试集来对训练出的模型进行验证，以测试误差来近似泛化误差实现的。</p>
<p>测试误差体现在具体的性能度量指标上，我们要根据具体情况选择对应的指标。</p>
<p>假设检验是我们对学习器性能进行比较的有效方法。</p>
<p>泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p>
<p>通常来讲，更多的数据胜过更好的算法：对一批数据使用高明的算法，比不上用普通算法但是引入一部分外部数据源的效果要好。</p>
<p><a target="_blank" rel="noopener" href="http://anand.typepad.com/datawocky/2008/03/more-data-usual.html">额外阅读</a></p>
<h3 id="2-7-习题"><a href="#2-7-习题" class="headerlink" title="2.7 习题"></a>2.7 习题</h3><h4 id="2-7-1"><a href="#2-7-1" class="headerlink" title="2.7.1"></a>2.7.1</h4><p><em>数据集包含 1000 个样本，其中 500 个正例、 500 个反例，将其划分为包含 70% 样本的训练集和 30% 样本的测试集用于留出法评估，试估算共有多少种划分方式。</em></p>
<p>500个正例和500个反例，根据分层抽样的原则，30%的测试样本共300个，其中必须包含150个正例和150个反例。若不考虑样本其他的分布情况，则选取方式为：从500个正例中随机抽取150个，再从500个反例中随机抽取150个，两个过程相互独立，则共有$(C_{500}^{150})^2$种方式。</p>
<h4 id="2-7-2"><a href="#2-7-2" class="headerlink" title="2.7.2"></a>2.7.2</h4><p><em>数据集包含 100 个样本，其中正、反例各一半，假定学习算法所产生的模型是将新样本预测为训练样本数较多的类别(训练样本数相同时进行随机猜测)，试给出用 10 折交叉验证法和留一法分别对错误率进行评估所得的结果。</em></p>
<p>10 折交叉验证法：将样本集划分为10个同分布不相交的子集，将其中9个作为训练集，1个作为测试集，每个划分可得到10次不同的训练和验证。对于题目所述的模型，总是将新样本预测为训练样本较多的类别，但每一次验证时，训练集的正例和反例一样多，将会进行随机猜测。每次都进行随即猜测，其错误率的期望是50%。</p>
<p>留一法：$k$折交叉验证中$k$等于样本个数的特例。在题目所述的情况下，即将100个样本每次取出1个样本用于测试，99个用于训练。当1个测试样本为正例时，99个训练样本为50个反例和49个正例，新样本将被预测为出现较多的反例，而测试样本的ground truth是正例，必然会预测错误。当测试样本为反例时同理必然会预测错误，此时错误率的期望为100%。</p>
<h4 id="2-7-3"><a href="#2-7-3" class="headerlink" title="2.7.3"></a>2.7.3</h4><p><em>若学习器 A 的 F1 值比学习器 B 高，试析 A 的 BEP 值是否也比 B 高。</em></p>
<p>F1：查准率P和查全率R的调和平均；</p>
<p>BEP：Beak-Even Point，P-R曲线上P = R时二者的取值。</p>
<p>F1和BEP有概念上的巨大差异，二者没有必然联系。P-R曲线的定义是：学习器将所有样本按“可能是正例”的概率从前向后排序，然后依次将前若干个样本按正例进行预测，所得出的预测结论。注意此时<u>BEP曲线只是衡量了学习器进行“排序”的性能，并不包含最终预测的结果。</u>也就是说，给定了P-R曲线的情况下，根据不同的预测策略，会产生不同的P和R。<u>而F1是一个确定的概念，是在P和R都确定的情况下计算出的二者的调和平均。</u>因此在同一P-R曲线上，F1在不同的位置有不同的取值。</p>
<p>因此对于题目所述的假设，我们很容易给出反例：对于R-P曲线完全相同的两个学习器，二者的P-R曲线上存在两个不同位置，使得对应的F1值不同。不妨设F1值较大的位置所对应的预测策略为学习器A，另一个为B，此时学习器A的F1值比学习器B高，但二者P-R曲线完全相同，也有相同的BEP值。</p>
<h4 id="2-7-4"><a href="#2-7-4" class="headerlink" title="2.7.4"></a>2.7.4</h4><p><em>试述真正例率(TPR) 、假正例率 (FPR)与查准率(P) 、查全率(R)之间的联系。</em></p>
<p>查全率: 真实正例被预测为正例的比例。<br>真正例率: 真实正例被预测为正例的比例。<br>显然查全率与真正例率是相等的。</p>
<p>查准率:预测为正例的实例中真实正例的比例。<br>假正例率: 真实反例被预测为正例的比例。<br>两者并没有直接的数值关系。</p>
<h4 id="2-7-5"><a href="#2-7-5" class="headerlink" title="*2.7.5"></a>*2.7.5</h4><p><em>试证明式(2.22).</em></p>
<p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/pumpkin-book/#/chapter2/chapter2?id=_221">南瓜书中有证明，但同时，根据南瓜书的建议</a></p>
<blockquote>
<p>对于初学机器学习的小白，西瓜书第1章和第2章的公式<strong>强烈不建议深究</strong>，简单过一下即可，等你学得有点飘的时候再回来啃都来得及。</p>
</blockquote>
<h4 id="2-7-6"><a href="#2-7-6" class="headerlink" title="2.7.6"></a>2.7.6</h4><p><em>试述错误率与 ROC 曲线的联系。</em></p>
<p>ROC曲线本质上只反映学习器的“排序能力”，而具体的预测策略则取决于在ROC曲线上的哪一点作截断。当确定了一种预测策略时，才会对应一个确定的错误率。因此可以说，ROC曲线上的每一点，对应了学习器一种情况下的错误率。</p>
<h4 id="2-7-7"><a href="#2-7-7" class="headerlink" title="2.7.7"></a>2.7.7</h4><p><em>试证明任意一条 ROC 曲线都有一条代价曲线与之对应，反之亦然.</em></p>
<p>代价曲线、ROC曲线、P-R曲线都是为了描述某一学习器的“排序能力”而引入的概念。ROC曲线下方的面积仅能在“错误代价均等”的条件下反应学习器的排序质量，而在错误代价并不均等的情况下，引入代价矩阵后，应当使用代价曲线来反应考虑代价的排序质量。但不论使用哪一种曲线，衡量哪一种面积，一旦学习器给定，其排序质量是一定的，则三种曲线都是确定的。从这一角度来看，任意一条ROC曲线都对应了一个确定的学习器，而该学习器有唯一确定的代价曲线，反之亦然。</p>
<p>若要严格证明该结论，西瓜书给出了ROC曲线和代价曲线的转换方法：ROC曲线上每一点对应了代价平面上的一条线段，设ROC曲线上点的坐标为(FPR, TPR)，则可计算相应的FNR，然后再代价平面上绘制一条从(0, FPR)到(1, FNR)的线段，如此求出ROC曲线上所有点对应的线段，其下界围成的曲线即代价曲线。同理，在代价曲线上寻找一个连续的分段，将其线段计算出相应的FPR与FNR，再计算出TPR，即得到ROC曲线上的一个点，连接所有如此的到的点即得ROC曲线。</p>
<h4 id="2-7-8"><a href="#2-7-8" class="headerlink" title="2.7.8"></a>2.7.8</h4><p><em>Min-Max规范化与z-score规范化如下所示。试析二者的优缺点</em></p>
<p>Min−max规范化方法简单，而且保证规范化后所有元素都是正的，每当有新的元素进来，只有在该元素大于最大值或者小于最小值时才要重新计算全部元素。但是若存在一个极大(小)的元素，会导致其他元素变的非常小(大)。</p>
<p>z−score标准化对个别极端元素不敏感，且把所有元素分布在0的周围，一般情况下元素越多，0周围区间会分布大部分的元素，每当有新的元素进来，都要重新计算方差与均值。</p>
<h4 id="2-7-9"><a href="#2-7-9" class="headerlink" title="2.7.9"></a>2.7.9</h4><p><em>试述 χ2 检验过程.</em></p>
<p><a target="_blank" rel="noopener" href="http://guoze.me/2015/09/07/chi-square/">参考链接</a></p>
<h4 id="2-7-10"><a href="#2-7-10" class="headerlink" title="2.7.10*"></a>2.7.10*</h4><p><em>试述在Friedman 检验中使用式 (2.34) 与 (2.35) 的区别.</em></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/daigz1224/p/7163342.html">参考链接</a></p>
<h1 id="第三章-线性模型"><a href="#第三章-线性模型" class="headerlink" title="第三章 线性模型"></a>第三章 线性模型</h1><h3 id="章节主要内容-1"><a href="#章节主要内容-1" class="headerlink" title="章节主要内容"></a>章节主要内容</h3><p>线性模型形式简单、易于建模，许多功能更为强大的非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得（神经网络就是一个例子，后边学习神经网络时会发现其实神经网络的每个神经元就是一个广义的线性模型）</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/04786709258b">思维导图</a></p>
<p>基本知识：</p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/af0a4f71c05a">最小二乘法</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/bcfc11c216a3">极大似然法</a></p>
<h3 id="3-1-基本形式"><a href="#3-1-基本形式" class="headerlink" title="3.1 基本形式"></a>3.1 基本形式</h3><p>——线性模型的背后逻辑以及变型思路</p>
<p>线性模型的本质是通过训练数据学习出一个通过样本数据的属性的线性组合来进行预测的函数。</p>
<p>线性模型具体是什么，简单来说和我们学过的线性函数是一样的，我们学过的线性函数形式一般为：$y = ax + b$，在这里$a，b$代表系数，也就是我们模型要学习的东西，代表的是属性，也就是我们的特征。</p>
<p>给定由 $d$ 个属性描述的示例$x=(x_1;x_2;……;x_d)$ ， 其中$x_i$是 $x$ 在第 $i$ 个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即$f(x)=w_1x_1+w_2x_2+……+w_dx_d+b$ ，一般用向量形式写成$f(x)=w^Tx+b$ ，其中$w=(w_1;w_2;…;w_d)$ ，$w$ 和 $b$ 学得之后，模型就得以确定。</p>
<p>举一个例子，在西瓜样例中，</p>
<script type="math/tex; mode=display">
f_{好瓜}(x)=0.2\times x_{色泽}+0.5\times x_{根蒂}+0.3\times x_{敲声}+1</script><p>其中0.2,0.5,0.3还有1 都是属于线性模型通过训练数据学到的系数，而其中的色泽，根蒂，敲声属于一个样本的各个特征，我们在本章中先从回归讲起，然后讨论二分类再讨论多分类问题。 </p>
<p>二分类：新闻可以分为体育、非体育等两个类别，这就是一个典型的二分类任务，1可以代表正类，0代表负类。</p>
<p>多分类：新闻可以分为体育、财经、其它等三个类别，这就是一个典型的多分类任务。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/270458779">二分类、多分类、多标签分类的基础、原理、算法和工具</a></p>
<h3 id="3-2-线性回归"><a href="#3-2-线性回归" class="headerlink" title="3.2 线性回归"></a>3.2 线性回归</h3><p>——<strong>线性模型最基础的算法</strong></p>
<p>首先我们考虑最简单的问题，也就是只有一个输入属性的情况。</p>
<p>对离散属性，若属性值间存在”序” (order)关系，可通过连续化将其转化为连续值，例如二值属性”身高”的取值——“高” “矮”可转化为 {1.0,0.0}，三值属性”高度” 的取值”高” “中” “低”可转化为 {1.0, 0.5, 0.0}；若属性值间不存在序关 系，假定有 $k$ 个属性值，则通常转化为 $k$ 维向量，例如属性”瓜类”的取值”西瓜”、”南瓜”、”黄瓜”可转化为(0,0,1),(0,1,0),(1,0,0)。</p>
<p>线性回归试图学得$f(x_i)=wx_i+b$ ，使得$f(x_i)\approx y_i$ ，</p>
<p><u><em>如何确定 $ω$ 和 $b$ 呢？显然，关键在于如何衡量$ f(x) $与 $y$ 之间的差别。</em></u></p>
<p>这时候需要用到均方误差了，也就是我们常说的”欧式距离“，我们可以通过让均方误差最小化来求解需要的$w,b$。即</p>
<script type="math/tex; mode=display">
(w^*,b^*)=arg\min_{(w,b)}\sum^m_{i=1}(f(x_i)-y_i)^2=arg\min_{(w,b)}\sum^m_{i=1}(y_i-wx_i-b)^2</script><p>求解$w$和$b$使所有样本到一条直线上的欧氏距离之和最小，称为线性回归模型的最小二乘”参数估计” (parameter estimation).。我们可将上式对 $ω $和 $b$ 分别求导，得到</p>
<script type="math/tex; mode=display">
\frac{\partial{E_{w,b}}}{\partial w}=2(w\sum^m_{i=1}x_i^2-\sum^m_{i=1}x_i(y_i-b))</script><script type="math/tex; mode=display">
\frac{\partial{E_{w,b}}}{\partial b}=2(mb-\sum^m_{i=1}(y_i-wx_i))</script><p>令导数等于0可得到$w$和$b$最优解的闭式解：</p>
<script type="math/tex; mode=display">
w=\frac{\sum^m_{i=1}y_i(x_i-\overline{x})}{\sum^m_{i=1}x_i^2-\frac{1}{m}(\sum^m_{i=1}x_i)^2}</script><script type="math/tex; mode=display">
b=\frac{1}{m}\sum^m_{i=1}(y_i-wx_i)</script><p>其中$\overline{x}=\frac{1}{m}\sum^m_{i=1}x_i$为 $x$ 的均值。</p>
<p><strong>整理一下思路：线性回归要得到式子①，那么①里面的未知数怎么求，利用②式子最小二乘法求，通过对②求偏导等于0，来得到解，即式子③和式子④</strong></p>
<p>当我们的问题中存在的不止一个特征，我们称之为多元线性回归，形式与上述过程类似。<br>把$w,b$吸入向量模式，表示形式为$\hat{w}=(w;b)$，然后把数据集$D$表示为一个$m*(d+1)$的大小矩阵，前$d$行对应$d$个属性，最后一行元素置为$1$，即</p>
<script type="math/tex; mode=display">
X=\left|
    \begin{matrix}
    x_{11} & x_{12} & \cdots & x_{1d} & 1\\
    x_{21} & x_{22} & \cdots & x_{2d} & 1\\
    \vdots & \vdots & \ddots & \vdots & \vdots\\
    x_{m1} & x_{m2} & \cdots & x_{md} & 1 \\
    \end{matrix}
    \right|=\left|
    \begin{matrix}
    x_1^T &1\\
    x_2^T &1\\
    \vdots & \vdots\\
    x_m^T &1\\
    \end{matrix}
    \right|</script><p>再把标记也写成向量形式$y=(y_1;y_2;…;y_m)$，则类似于单变量线性回归模型，有</p>
<script type="math/tex; mode=display">
\hat{w}^*=argmin_{\hat{w}}(y-X\hat{w})^T{}(y-X\hat{w})</script><p>令$E_\hat{w}=(y-X\hat{w})^T{}(y-X\hat{w})$，对$\hat{w}$求导得到：</p>
<script type="math/tex; mode=display">
\frac{\partial E_{\hat{w}}}{ \partial\hat w}=2X^T(X\hat w-y)</script><p>令上式为零可得 $\hat w$ 最优解的闭式解。假设当为满秩矩阵或正定矩阵时<script type="math/tex">\hat{w^*}=(X^TX)^{-1}X^Ty</script>，回归模型为<script type="math/tex">f(\hat{x_i})=\hat{x_i}(X^TX)^{-1}X^Ty</script>。<br> <strong>【注】现实任务往往<script type="math/tex">X^TX</script>不满秩，所以会有多个$\hat{w}$，此时结果由算法的学习偏好决定。</strong></p>
<p>下面说一下线性模型的变种，有时候我们的$y$和$x$之间不是线性变化，比如说y是跟随$x$呈现指数变化，这就导致了一个问题，$y=w<em>x+b$不能再表示他们之间的关系，那么这时候应该通过一个“<em>*联系函数</em></em>”，如上面我们举出来的例子，如果$y$和$wx+b$之间不再是线性而是指数变换，这是我们可以对$y$进行取对数操作</p>
<script type="math/tex; mode=display">
ln y=w^Tx+b</script><p>这个取对的操作就相当于在原先的等式之间又加上了一个函数，这个函数我们就叫作联系函数，而我们把上面的式子叫做对数线性回归。<br> 我们再回味一下为什么这么做呢？因为$y$和$x$之间不再具有某种线性关系，取而代之的是一种指数关系，那我们怎么将这种指数关系表示出来呢？将$y$进行取对操作，这样$lny$又一次和$wx+b$呈现一种线性关系，这实际上是一种空间映射。这就是”对数线性回归” (log-linear regression) ，它实际上是在试图让 $e^{w^Tx+ b} $ 逼近 $y$。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220620162127816.png" srcset="/img/loading.gif" lazyload alt="image-20220620162127816"></p>
<p>如上图所示，这里的对数函数起到了<u>将线性回归模型的预测值与真实标记联系起来的作用</u>。</p>
<p>更一般地，考虑单调可微函数$ g(.) $， 令</p>
<script type="math/tex; mode=display">
y=g^{-1}(w^Tx+b)</script><p>$g(.) $连续且充分光滑，这样得到的模型称为”广义线性模型” (generalized linear model) ，其中函数$g(.)$ 称为”联系函数” (link function).。显然?，对数线性回归是广义线性模型在$g(.) = ln(.) $时的特例.</p>
<h3 id="3-3-对数几率回归"><a href="#3-3-对数几率回归" class="headerlink" title="3.3 对数几率回归"></a>3.3 对数几率回归</h3><p>——<strong>线性回归函数的变型</strong></p>
<p>这里的对数几率回归是我们经常见到的一种算法：logistic回归，虽然它叫做回归算法，但实际上它是一种分类算法。</p>
<p>上一节说的是如何使用线性模型进行回归学习，但是如何利用线性模型进行分类算法呢？这时候就需要我们的联系函数，只要能找到一个函数可以将预测值与真实标签联系起来就可以。</p>
<p>考虑二分类任务，其输出标记$y$是[0，1]之中的一个，但是线性模型$w*x+b$预测出来是一个实际的值，我们应该把值转换成$0/1$，最理想的是”单位阶跃函数”</p>
<script type="math/tex; mode=display">
y=
\left\{
\begin{array}{c}
    0,z<0\\
    0.5,z=0\\
    1,z>0
\end{array}
\right.</script><p>即若预测值 $ z$ 大于零就判为正例，小于零则判为反例，预测值为临界值零则可任意判别，如图所示为单位阶跃函数与对数几率函数。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220620163011834.png" srcset="/img/loading.gif" lazyload alt="image-20220620163011834"></p>
<p>从图中可看出单位阶跃函数并不连续，因此不能直接用作广义线性模型中的联系函数$g^-(.)$，于是我们用对数几率函数这种近似单位阶跃函数且单调可微的函数来作为其替代函数。</p>
<script type="math/tex; mode=display">
y=\frac{1}{1+e^{-z}}</script><p>对数几率函数与对数函数是不同的，它是一种”Sigmod”函数，几率是什么意思呢？假设为正例的概率是$y$那么$y/1-y$就表示几率。</p>
<p>我们要时刻记住这个函数为什么出现在这里，他是为了<strong>将我们的输出转换成别的函数，这个对数几率函数将作为我们的联系函数</strong>。</p>
<p>我们将上一节讲的线性函数代入到对数几率函数中得到如下所示</p>
<script type="math/tex; mode=display">
y=\frac{1}{1+e^{-(w^Tx+b)}}</script><p>进行变换之后我们将含$w$以及$b$的放在等式的一边，其余的放在另一边，如下所示</p>
<script type="math/tex; mode=display">
ln\frac{y}{1-y}=w^Tx+b</script><p>由此可以看出，我们是在用线性回归模型的预测结果去逼近真实标记的对数几率(即几率的对数)，其中对数几率表示的是$x$做为正例的可能性。</p>
<p>那么如何求得<script type="math/tex">w,b</script>，这里用了<strong>极大似然法</strong>(推导就不列出来)。最后得到一个关于β的高阶可导连续凸函数</p>
<script type="math/tex; mode=display">
l(β)=\sum_{i=1}^m(-y_iβ^T\hat{x_i}+\ln(1+e^{β^T\hat{x_i}}))</script><p>通过梯度下降法、牛顿法等都可求得这个函数的最优解<script type="math/tex">β^*=argmin_βl(β)</script>。</p>
<h3 id="3-4线性判别分析"><a href="#3-4线性判别分析" class="headerlink" title="3.4线性判别分析"></a>3.4线性判别分析</h3><p>——<strong>线性模型在多分类场景下的应用</strong></p>
<p><strong>线性判别分析（LDA）：设法将样例投到一条线上，同类样例尽可能接近，不同样例间尽可能远离，将新样例投到线上通过其位置来分类。</strong>简单点就是正例尽量投在一起，反例投一起，正反例尽可能远离，拿到新样例投上去看更接近哪。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220620171630343.png" srcset="/img/loading.gif" lazyload alt="image-20220620171630343"></p>
<p>LDA 的二维示意图”+”、 “ “分别代表正例和反例，椭圆表示数据簇的外轮廓，虚线表示投影， 红色实心园和实心三角形分别表示两类样本投影后的中心点。</p>
<p>LDA常常用于二分类问题以及多分类的降维处理，我们先讲解关于二分类的问题。由于两类数据过于繁多，导致无法直接对数据属于哪一类进行判断，LDA的基本思想是对于两类数据，想办法将两类数据映射到一条合适的直线上，此时只需要找到直线上一个可以将两类数据分开到两边的点，就可以直观且简便地判断某个样本数据属于哪一类了。</p>
<p>但并不是所有直线都可以找到这个分界点，如下图所示，紫色与红色分别代表两类数据，左侧将两类数据的一部分映射到一起了显然增加了判断难度，右侧可以找到一个蓝色的点将两类数据区分开来,相对于左侧图像而言，右侧映射到直线的数据，具有类内尽可能聚集，不同类数据尽可能分散的特点，如何利用数学公式去描述这种特点，就是Linear Discriminant Analysis(LDA)的任务了。<br><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxODc2MjEz,size_16,color_FFFFFF,t_70.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h4 id="二分类线性判别分析"><a href="#二分类线性判别分析" class="headerlink" title="二分类线性判别分析"></a><strong>二分类线性判别分析</strong></h4><p>首先需要理解映射的概念，具体内容在<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41876213/article/details/107695663">PCA降维的投影</a>部分中讲解过，简单来说，若单位向量$θ $是直线$l $上的单位向量，那么样本数据$x_i $在直线$l$上的投影距离为$\theta^Tx_i$。类别$k$的样本平均向量为</p>
<script type="math/tex; mode=display">
u^k=\frac{1}{m^k}\sum^{m^k}_{i=1}x_i,k\in c</script><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41876213/article/details/108140335">详细推导过程及代码实现见链接</a></p>
<p>数据集<script type="math/tex">D=\{(x_i,y_i)\}_{i=1}^m,y_i\in\{0,1\}</script>，令<script type="math/tex">X_i、u_i、\sum{i}</script>分别表示<script type="math/tex">i\in\{0,1\}</script>类示例的集合、均值向量、协方差矩阵，$w$表示直线。<br> 线性判别分析有两个目标:①同类样例投影点尽可能接近，即同类投影点协方差<script type="math/tex">（w^T\sum{0w}+w^T\sum{1w}</script>  尽可能小，②异类尽可能远离，即类中心点之间的距离<script type="math/tex">||w^Tu_0-w^Tu_1||^2_2</script>尽可能大。所以同时还要考虑二者，则可以得到最大化目标</p>
<script type="math/tex; mode=display">
J={\frac{||w^Tu_0-w^Tu_1||^2_2}{w^T\sum_0{w}+w^T\sum_{1}{w}}}={\frac{w^T{(u_0-u_1)}(u_0-u_1)^Tw}{w^T(\sum_0+\sum_1)w}})①</script><p> 定义“类内散度矩阵”</p>
<script type="math/tex; mode=display">
S_w=\sum_0+\sum_1=\sum_{x∈X_0}(x-u_0)(x-u_0)^T+\sum_{x∈X_1}(x-u_1)(x-u_1)^T</script><p>定义“类间散度矩阵”</p>
<script type="math/tex; mode=display">
S_b=(u_0-u_1)(u_0-u_1)^T</script><p> 将式子①重写为</p>
<script type="math/tex; mode=display">
J=\frac{w^TS_bw}{w^TS_ww}</script><p>这就是LDA要求的最大化目标，即<script type="math/tex">S_b与S_w</script>的“广义瑞利商”。那么$w$怎么求呢？因为上式分子分母都有$w$二次项所以解$w$长度无关只和方向有关。由拉格朗日乘子式得</p>
<script type="math/tex; mode=display">
S_bw={\lambda}S_ww</script><p>λ是拉格朗日乘子。</p>
<p>又因为$S_bw$方向衡为$u_0-u_1$，所以令<script type="math/tex">S_bw={\lambda}(u_0-u_1)</script>代入上式最终得$w=S_w^{-1}(u_0-u_1)$。</p>
<h4 id="多分类线性判别分析"><a href="#多分类线性判别分析" class="headerlink" title="多分类线性判别分析"></a>多分类线性判别分析</h4><p>假设存在$N$个类，且第$i$类示例数为$m_i$；</p>
<p>定义“全局散度矩阵”</p>
<script type="math/tex; mode=display">
S_t=S_b+S_w=\sum_{i=1}^m(x_i-u)(x_i-u)^T①</script><p><strong>【注】$u$是所有示例的均值向量</strong><br>定义“每个类别的散度矩阵之和”</p>
<script type="math/tex; mode=display">
S_w=\sum_{i=1}^NS_{w_i}②</script><p>**【注】<script type="math/tex">S_{w_i}=\sum_{x∈X_i}(x-u_i)(x-u_i)^T</script><br>由上式①和②得</p>
<script type="math/tex; mode=display">
S_b=S_t-S_w=\sum_{i=1}^Nm_i(u_i-u)(u_i-u)^T</script><p>所以多分类LDA有多种实现方法，使用<script type="math/tex">S_b,S_t,S_w</script>任何两个就可以了。</p>
<h3 id="3-5-多分类学习"><a href="#3-5-多分类学习" class="headerlink" title="3.5 多分类学习"></a>3.5 多分类学习</h3><p>——<strong>线性模型在多分类场景下的应用</strong></p>
<p>多分类学习有两个思路。一种是将二分类学习方法推广到多分类，比如上一节讲到的LDA。另一种则是利用二分类的学习器来解决多分类问题。下面讨论第二种。</p>
<p>多分类学习的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。</p>
<p><strong>拆解法步骤：</strong></p>
<p>1.通过拆分策略对问题进行【<strong>拆分】</strong>；</p>
<p>2.为拆分出的每个二分类任务【<strong>训练】</strong>一个分类器；</p>
<p>3.对各个分类器的结果进行【<strong>集成】</strong>，以获得多分类结果。</p>
<p>最经典的拆分策略有以下三种：</p>
<p>多分类学习有N个类别$C_1,C_2,…,C_N$，给定数据集$D={(x_1,y_1),…,(x_m,y_m)},y_i\in {C_1,…,C_n}$。</p>
<p><strong>［1］“一对一”（One vs One，简称OvO）</strong></p>
<p>将 N 个分类分别两两配对，从而【<strong>拆分】</strong>成 $N(N-1)/2$ 个二分类任务；【<strong>训练</strong>】时为了区分 $C_i$和 $C_j$ 这两个分类，这 $N(N-1)/2$ 个分类器中的一个将 $C_i$ 作为正例， $C_j $作为反例；测试时候将新样本同时提交给所有分类器，将得到 $N(N-1)/2$ 个分类结果，【<strong>集成】</strong>的方法是通过投票在这些结果中选出最终结果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//v2-437db32129fdc1d411ac560bfa0f8842_1440w.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><strong>［2］“一对其余”（One vs Rest，简称OvR）</strong></p>
<p>将N个分类中的一个类拿出来作为一个分类器的正例，其余均设置为反例，从而【拆分】成N个分类任务；【训练】得到N个分类结果；【集成】的方法是考虑各被判为正例的分类器的置信度，选择置信度大的类别标记作为分类的结果。（如果只有一个，直接选择）</p>
<p>我们看到OvO和OvR相比，前者要训练的分类器要多得多，因此存储和测试开销要相对多些。但是在训练时，因为前者每个分类器只使用部分数据，而后者要用全量数据，所以类别多时，OvO的训练开销要更小一些。</p>
<p>至于预测性能，则取决于数据分布，在多数情况下两者差不多。</p>
<p><strong>［3］“多对多”（Many vs Many，简称MvM）</strong></p>
<p>每次将若干个类别作为正类，若干个其它类作为反类。显然，OvO和OvR是MvM的特例。但其正反类的划分必须有特殊的设计，不能随意选取。一种最常用的MvM技术是：“纠错输出码”（Error Correcting Output Codes，简称ECOC）</p>
<p>ECOC过程主要分两步：</p>
<ul>
<li><p>编码：对N个类进行M次划分，产生M个分类器。</p>
</li>
<li><p>解码：M个分类器对测试样本进行预测，得到M个预测标记，将其组成编码；这个编码与N个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测的结果。</p>
</li>
</ul>
<p>编码形式又分为二元码和三元码，前者指定“正类”、“反类”，后者又多一个“停用类”。</p>
<p>以二元ECOC码为例：如下图，首先，将<script type="math/tex">N(N=4)</script>个类通过设计构造成<script type="math/tex">M(M=5)</script>个分类器$(f_1,f_2,f_3,f_4,f_5)$，每个分类器为每个类分配了一个标记结果(-1/+1)，这样一来，每个类$C_i,i\in{1,N}$都获得了一个$M$位的编码，这个编码就是【各类所对应的编码】。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//v2-2c27bcec29d2a98b0a4725775cb8b2c4_1440w.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>当有一个测试例$A$时，先将 A 依照次序放入 $M$ 个分类器中，得到了$ M$ 个分类标记结果$(-1，-1，+1，-1，+1)$；再将这 $M$ 个标记结果编成一个纠错输出码$（-1-1+1-1+1）$；最后去和【各类所对应的编码】进行比较海明距离或欧式距离，距离最短的对应编码对应的分类就是结果。（图中结果为 $C_3$）</p>
<p>海明距离：每个分类器对样本的分类结果如果和$C_1$类不一致，则计数加1，否则不加，结果为：0+1+1+1+0 = 3</p>
<p>欧式距离：每个分类器对样本的分类结果减去$C_1$类的分类划分，差值的平方和的开方，结果为：$\sqrt{( 0+4+4+4+0)}$ = $\sqrt12$ ＝<script type="math/tex">2\sqrt3</script></p>
<p>纠错输出码还有一个功能是为分类器的错误进行修正。比如正确的分类结果是$（-1，-1，+1，-1，+1）$，但如果分类器 $f_2$ 出了错误，得到的结果就是$（-1，+1，+1，-1，+1)$。但通过这一套编码，可以让最终的结果仍为$C_3$ 。</p>
<p>分类器越多，ECOC编码越长，纠错能力越强，但开销越大；而且，如果分类有限，那么可组合的数目也有限，码长超过一定程度，也没有意义了。</p>
<p>同等长度的编码，【各类所对应的编码】之间计算出的距离越远，编码的纠错能力越强，但当码长到达一定程度时，无法得出最优解。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/lafengxiaoyu/article/details/107886065">ECOC编码详解</a></p>
<h3 id="3-6-类别不平衡问题"><a href="#3-6-类别不平衡问题" class="headerlink" title="3.6 类别不平衡问题"></a>3.6 类别不平衡问题</h3><p>——<strong>类别不平衡时的调优方案</strong></p>
<p>类别不平衡（class-imbalance），就是指分类任务中不同类别的训练样例数目差别很大的情况。例如有 998 个反例，但正例只有 2 个，那么学 习方法只需返回一个永远将新样本预测为反例的学习器，就能达到 99.8% 的精度；然而这样的学习器往往没有价值，因为它不能预测出任何正例。</p>
<p>目前类别不平衡性学习的一个基本策略是“再缩放”（rescaling），现有技术大体上有以下三种做法：</p>
<p><strong>［1］欠采样（undersampling）</strong></p>
<p>去除样例过多的类别中的一部分样例，使得正、反例数目接近。代表性算法EasyEnsemble，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息。</p>
<p><strong>［2］过采样（oversampling）</strong></p>
<p>对样例少的类别增加数据，使得正、反例数目接近。过采样法不能简单地对初始正例样本进行重复采样，否则会招致严重的过拟合。代表性算法SMOTE是通过对训练集里的正例进行插值来产生额外的正例。</p>
<p><strong>［3］阈值移动（threshold-moving）</strong></p>
<p>一般我们对二分类法的正负值的判定阈值是基于中间值0.5来判断的，这是基于分类器认为真实正、反例可能性相同的认知下的判断，即分类器决策规则为：</p>
<p>若$ y / ( 1 - y ) &gt; 1$，则预测为正例②</p>
<p>然而，当训练集中正、反例不同时，令$m^+$表示正例数，$m^-$表示反例数，则观察几率为：$m^+/m^-$，这时我们应该改变分类器决策规则为：</p>
<p>若$ y / ( 1 - y ) &gt; m^+/m-$，则预测为正例③</p>
<p>将③代入②中，我们可以得到新的决策规则：</p>
<p>若</p>
<script type="math/tex; mode=display">
\frac{ y'} { (1 - y') }= \frac{y} {(1 - y)} \times \frac{m^-}{m^+} > 1</script><p>则预测为正例</p>
<p>这种在用训练好的分类器进行预测时，将决策规则根据数据分布来进行移动的方法就是阈值移动。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>［1］线性模型是一个形式简单、易于建模的机器学习模型，因为$w$直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性</p>
<p>［2］线性回归背后的逻辑是用模型的预测值去逼近真实标记$y$，并通过计算训练样本在向量空间上距离模型线的欧式距离之和的最小值来确定参数$w和b$</p>
<p>［3］线性回归可写成广义线性模型形式：$g(y) = wx + b$，通过选择不同的联系函数$g(.)$会构成不同的线性回归模型</p>
<p>［4］在遇到多分类学习任务时，基本的解决思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解</p>
<p>［5］当不同类别的样例数不同时，会造成类别不平衡问题，解决该问题的基本策略是对数据进行“再缩放”</p>
<h3 id="3-7-习题"><a href="#3-7-习题" class="headerlink" title="3.7 习题"></a>3.7 习题</h3><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/49ef509ef874">习题答案</a></p>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/">#机器学习基础理论</a>
      
    </div>
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/06/21/mac%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="Mac环境配置java工具">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Mac环境配置java工具</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/06/16/MarkDown%E6%95%99%E7%A8%8B/" title="MarDown使用教程">
                        <span class="hidden-mobile">MarDown使用教程</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="vcomment" class="comment"></div> 
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
  <script>
    var notify = '' == true ? true : false;
    var verify = '' == true ? true : false;
      window.onload = function() {
          new Valine({
              el: '#vcomment',
              app_id: "AwHBUAjSP1GvDVpiBgxfS2Pg-gzGzoHsz",
              app_key: "kMsGLN3hzkQJuLrmqQBgquFF",
              placeholder: "说点什么",
              avatar:"retro",
              visitor: true       

          });
      }
  </script>

 
  <noscript>Please enable JavaScript to view the comments</noscript>



  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  




  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  
    
  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>

  <script defer src="/js/leancloud.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/yinghua.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/xiantiao.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/xiaoxingxing.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/caidai.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
