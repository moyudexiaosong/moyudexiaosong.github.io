

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="第一章 绪论1.1 什么是机器学习类似人类通过对经验的利用对新情况做出有效的决策，计算机通过计算的手段，利用经验来改善系统自身的性能。 在计算机系统中，”经验”通常以”数据”形式存在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生”**模型”(model)**的算法，即”学习算法”(learningalgorithm).有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；">
<meta property="og:type" content="article">
<meta property="og:title" content="week01">
<meta property="og:url" content="http://example.com/2022/06/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0week01/index.html">
<meta property="og:site_name" content="摸鱼之家">
<meta property="og:description" content="第一章 绪论1.1 什么是机器学习类似人类通过对经验的利用对新情况做出有效的决策，计算机通过计算的手段，利用经验来改善系统自身的性能。 在计算机系统中，”经验”通常以”数据”形式存在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生”**模型”(model)**的算法，即”学习算法”(learningalgorithm).有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617192915496.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617200149951-5467313-5467314-5467315.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617200824722-5467707.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618134035759.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618104530154.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618110202690.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//5328356-6afc770c7199ac3d.jpeg">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618142530466.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618155420458.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619171542448.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618175331853.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//20160721114615857-20220619182907525.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//20160721111312507.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618181148275.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619155415423.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619191716330.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619224405067.png">
<meta property="article:published_time" content="2022-06-16T11:27:38.737Z">
<meta property="article:modified_time" content="2022-06-20T07:55:25.263Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="机器学习基础理论">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617192915496.png">
  
  
  
  <title>week01 - 摸鱼之家</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>加油</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/photo6.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="week01"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-06-16 19:27" pubdate>
          June 16, 2022 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          20k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          168 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">week01</h1>
            
            <div class="markdown-body">
              
              <h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h1><h3 id="1-1-什么是机器学习"><a href="#1-1-什么是机器学习" class="headerlink" title="1.1 什么是机器学习"></a>1.1 什么是机器学习</h3><p>类似人类通过对经验的利用对新情况做出有效的决策，计算机通过计算的手段，利用经验来改善系统自身的性能。</p>
<p>在计算机系统中，”经验”通常以”数据”形式存在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生”**模型”(model)**的算法，即”学习算法”(learningalgorithm).有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时(例如看到一个没剖开的西瓜)，模型会给我们提供相应的判断(例如好瓜).</p>
<p>如果说计算机科学是研究关于”算法”的学问，那么类似的，可以说机器学习是研究关于”学习算法”的学问.</p>
<h3 id="1-2-基本术语"><a href="#1-2-基本术语" class="headerlink" title="1.2 基本术语"></a>1.2 基本术语</h3><p>假定我们收集了一批关于西瓜的数据，例如(色泽=青绿；根蒂=蜷缩；敲声=浊响)，(色泽=乌黑；根蒂:稍蜷；敲声=沉闷)，(色泽=浅自；根蒂硬挺；敲声=清脆)…</p>
<p>每对括号内是一条<strong>记录</strong>，=的意思是”取值为”。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617192915496.png" srcset="/img/loading.gif" lazyload alt="image-20220617192915496"></p>
<p>从数据中学得模型的过程称为<u><strong>“学习”(learning)或”训练”(training)</strong></u>,这个过程通过执行某个学习算法来完成学得模型对应了关于数据的某种潜在的规律，因此亦称**<u>“假设”</u><strong>(hypothesis)；这种潜在规律自身，则称为<u></strong>“真相”或”真实”(ground-truth)<strong></u>，学习过程就是为了找出或逼近真相.本书有时将模型称为<u></strong>“学习器”(learner)**</u>，可看作学习算法在给定数据和参数空间上的实例化.</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617200149951-5467313-5467314-5467315.png" srcset="/img/loading.gif" lazyload alt="image-20220617200149951"></p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220617200824722-5467707.png" srcset="/img/loading.gif" lazyload alt="image-20220617200824722"></p>
<p>学得模型后，使用其进预测的过程称为<u><strong>“测试”(testing)</strong></u>，被预测的样本称为<u><strong>“测试样本”(testingsample)</strong></u>.例如在学得$f$后，对测试例，可得到其预测标记$ν=f(x)$.</p>
<p><u><strong>“聚类”(clustering)</strong></u>，即将训练集中的西瓜分成若干组，每组称为一个”<u><strong>簇</strong></u>“(cluster)；这些自动形成的簇可能对应一些潜在的概念划分，例如”浅色瓜””深色瓜”，这些概念事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息.</p>
<p>根据<u>训练数据是否拥有标记信息</u>，学习任务可大致划分为两大类”监督学习”(supervisedlearning)和”<strong>无监督学习</strong>“(unsupervisedlearning)，分类和回归是前者的代表，而聚类则是后者的代表.</p>
<p><u>学得模型适用于新样本的能力</u>，称为”<strong><u>泛化</u></strong>“(generalization)能力.具有强泛化能力的模型能很好地适用于整个样本空间.通常假设样本空间的样本均服从独立同分布，一般而言，训练样本越多，我们得到的关于分布的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型.</p>
<h3 id="1-3-假设空间"><a href="#1-3-假设空间" class="headerlink" title="1.3 假设空间"></a>1.3 假设空间</h3><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618134035759.png" srcset="/img/loading.gif" lazyload alt="image-20220618134035759" style="zoom: 50%;" />

<p>归纳学习有<strong>狭义</strong>与<strong>广义</strong>之分：</p>
<p>广义的归纳学习大体相当于<u>从样例中学习</u>。</p>
<p>狭义的归纳学习则要求<u>从训练数据中学得概念(concept)</u>，因此亦称为<u><strong>“概念学习”或”概念形成”</strong></u>。</p>
<p>举一个西瓜数据集的例子：</p>
<table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">色泽</th>
<th align="center">根蒂</th>
<th align="center">敲声</th>
<th align="center">好瓜</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">青绿</td>
<td align="center">蜷缩</td>
<td align="center">浊响</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">乌黑</td>
<td align="center">蜷缩</td>
<td align="center">浊响</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">青绿</td>
<td align="center">硬挺</td>
<td align="center">清脆</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">乌黑</td>
<td align="center">稍缩</td>
<td align="center">沉闷</td>
<td align="center">否</td>
</tr>
</tbody></table>
<p>这里要学习的目标是”好瓜”，表1.1第一行虽然是好瓜，但这是一个已经见过的瓜，不属于“泛化”的范畴，因此引入一个概念——<u><strong>假设空间</strong></u>，里面包含所有假设。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618104530154.png" srcset="/img/loading.gif" lazyload alt="image-20220618104530154"></p>
<p>搜索过程中可以不断删除<u><strong>与正例不一致</strong></u>的假设、和(或)<u><strong>与反例一致</strong></u>的假设，最终获得与训练集一致(即<u>对所有训练样本能够进行正确判断</u>)的假设，这就是我们学得的结果.</p>
<p>与训练集一致的”假设集合”称之为”版本空间”(versionspace).例如，在西瓜问题中，与表1.1训练集所对应的版本空间如图1.2所示.<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_18433441/article/details/55682732">详细过程</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618110202690.png" srcset="/img/loading.gif" lazyload alt="image-20220618110202690"></p>
<h3 id="1-4-归纳偏好"><a href="#1-4-归纳偏好" class="headerlink" title="1.4 归纳偏好"></a>1.4 归纳偏好</h3><p>通过学习得到的模型对应了假设空间中的一个假设，但很可能存在有多个与训练集一致的假设，但与它们对应的模型在面临新样本的时候，却会产生不同的输出.</p>
<p>机器学习算法在学习过程中对某种类型假设的偏好，称为”<strong><u>归纳偏好</u></strong>“(inductivebias),或简称为”偏好”。<u>任何一个有效的机器学习算法必有其归纳偏好</u>。</p>
<p>“奥卡姆剃刀”(Occam’srazor)原则：”若有多个假设与观察一致，则选最简单的那个。</p>
<p>在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能.脱离具体问题，空泛地谈论”什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好.</p>
<h3 id="1-5-习题"><a href="#1-5-习题" class="headerlink" title="1.5 习题"></a>1.5 习题</h3><h4 id="1-5-1"><a href="#1-5-1" class="headerlink" title="1.5.1"></a>1.5.1</h4><p><em>表1. 1 中若只包含编号为 1 和 4 的两个样例，试给出相应的版本空间.</em></p>
<table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">色泽</th>
<th align="center">根蒂</th>
<th align="center">敲声</th>
<th align="center">好瓜</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">青绿</td>
<td align="center">蜷缩</td>
<td align="center">浊响</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">乌黑</td>
<td align="center">稍缩</td>
<td align="center">沉闷</td>
<td align="center">否</td>
</tr>
</tbody></table>
<p>表1.1的训练数据集对应的假设空间应该如下：</p>
<p>搜索过程中可以不断删除与正例不一致的假设、和（或）与反例一致的假设。最终将会获得与训练集一致（即对所有训练样本能够进行正确判断）的假设，这就是我们学得的结果。</p>
<p>按照上述过程进行学习：</p>
<p>编号1可以删除：3，5，6，8，9，11-15，17-21，23-30，32-49</p>
<p>编号4可以删除：3，6，15，21，30，48，即剩余假设空间中无可删除的假设</p>
<p>学习过后剩余的假设为：</p>
<p>1，2，4，7，10。</p>
<p>这就是最后的“假设集合”，也就是<strong>“版本空间”</strong>。</p>
<p>1 色泽＝＊，根蒂＝＊，敲声＝＊<br>2 色泽＝青绿，根蒂＝＊，敲声＝＊<br>3 色泽＝乌黑，根蒂＝＊，敲声＝＊<br>4 色泽＝＊，根蒂＝蜷缩，敲声＝＊<br>5 色泽＝＊，根蒂＝硬挺，敲声＝＊<br>6 色泽＝＊，根蒂＝稍蜷，敲声＝＊<br>7 色泽＝＊，根蒂＝＊，敲声＝浊响<br>8 色泽＝＊，根蒂＝＊，敲声＝清脆<br>9 色泽＝＊，根蒂＝＊，敲声＝沉闷<br>10 色泽＝青绿，根蒂＝蜷缩，敲声＝＊<br>11 色泽＝青绿，根蒂＝硬挺，敲声＝＊<br>12 色泽＝青绿，根蒂＝稍蜷，敲声＝＊<br>13 色泽＝乌黑，根蒂＝蜷缩，敲声＝＊<br>14 色泽＝乌黑，根蒂＝硬挺，敲声＝＊<br>15 色泽＝乌黑，根蒂＝稍蜷，敲声＝＊<br>16 色泽＝青绿，根蒂＝＊，敲声＝浊响<br>17 色泽＝青绿，根蒂＝＊，敲声＝清脆<br>18 色泽＝青绿，根蒂＝＊，敲声＝沉闷<br>19 色泽＝乌黑，根蒂＝＊，敲声＝浊响<br>20 色泽＝乌黑，根蒂＝＊，敲声＝清脆<br>21 色泽＝乌黑，根蒂＝＊，敲声＝沉闷<br>22 色泽＝＊，根蒂＝蜷缩，敲声＝浊响<br>23 色泽＝＊，根蒂＝蜷缩，敲声＝清脆<br>24 色泽＝＊，根蒂＝蜷缩，敲声＝沉闷<br>25 色泽＝＊，根蒂＝硬挺，敲声＝浊响<br>26 色泽＝＊，根蒂＝硬挺，敲声＝清脆<br>27 色泽＝＊，根蒂＝硬挺，敲声＝沉闷<br>28 色泽＝＊，根蒂＝稍蜷，敲声＝浊响<br>29 色泽＝＊，根蒂＝稍蜷，敲声＝清脆<br>30 色泽＝＊，根蒂＝稍蜷，敲声＝沉闷<br>31 色泽＝青绿，根蒂＝蜷缩，敲声＝浊响<br>32 色泽＝青绿，根蒂＝蜷缩，敲声＝清脆<br>33 色泽＝青绿，根蒂＝蜷缩，敲声＝沉闷<br>34 色泽＝青绿，根蒂＝硬挺，敲声＝浊响<br>35 色泽＝青绿，根蒂＝硬挺，敲声＝清脆<br>36 色泽＝青绿，根蒂＝硬挺，敲声＝沉闷<br>37 色泽＝青绿，根蒂＝稍蜷，敲声＝浊响<br>38 色泽＝青绿，根蒂＝稍蜷，敲声＝清脆<br>39 色泽＝青绿，根蒂＝稍蜷，敲声＝沉闷<br>40 色泽＝乌黑，根蒂＝蜷缩，敲声＝浊响<br>41 色泽＝乌黑，根蒂＝蜷缩，敲声＝清脆<br>42 色泽＝乌黑，根蒂＝蜷缩，敲声＝沉闷<br>43 色泽＝乌黑，根蒂＝硬挺，敲声＝浊响<br>44 色泽＝乌黑，根蒂＝硬挺，敲声＝清脆<br>45 色泽＝乌黑，根蒂＝硬挺，敲声＝沉闷<br>46 色泽＝乌黑，根蒂＝稍蜷，敲声＝浊响<br>47 色泽＝乌黑，根蒂＝稍蜷，敲声＝清脆<br>48 色泽＝乌黑，根蒂＝稍蜷，敲声＝沉闷<br>49 Ø</p>
<h4 id="1-5-2"><a href="#1-5-2" class="headerlink" title="1.5.2"></a>1.5.2</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_26371477/article/details/102292685?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-5-102292685-blog-103812745.pc_relevant_antiscanv3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-5-102292685-blog-103812745.pc_relevant_antiscanv3&utm_relevant_index=10">代码实现</a></p>
<p><em>与使用单个合取式来进行假设表示相比，使用”析合范式”将使得假设空间具有更强的表示能力.例如</em></p>
<p><em>好瓜$\leftrightarrow$((色泽=all)$\cap$(根蒂=蜷缩) $\cap$(敲声=all )) $\cup$ ((色泽=乌黑) $\cap$ (根蒂= all)$\cap$(敲声=沉闷)),</em></p>
<p>会把”(色泽=青绿)$\cap$(根蒂=蜷缩) $\cap$(敲声=清脆 *)”以及”(色泽=乌黑)$\cap$(根蒂=硬挺) $\cap$(敲声=沉闷 <em>)”都分类为”好瓜”。若使用最 多包含 $k$个合取式的析合范式来表达表1. 1 西瓜分类问题的假设空 间 ,试估算共有多少种可能的假设.</em></p>
<blockquote>
<p>知识储备</p>
<p>合取式：是用合取真值联结词“∧”将两个或两个以上的命题联结起来而形成的命题形式。</p>
<p>析取式：用析取真值连接词“∨”将两个或两个以上的命题联结而成的一种命题形式</p>
<p>合取：相当于交集但不是交集</p>
<p>析取：相当于并集但不是并集</p>
<p>合取范式（合析范式）：有限个简单析取式构成的合取式</p>
<p>析取范式（析合范式）：由有限个简单合取式构成的析取式称为析取范式。</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">色泽</th>
<th align="center">根蒂</th>
<th align="center">敲声</th>
<th align="center">好瓜</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">青绿</td>
<td align="center">蜷缩</td>
<td align="center">浊响</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">乌黑</td>
<td align="center">蜷缩</td>
<td align="center">浊响</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">青绿</td>
<td align="center">硬挺</td>
<td align="center">清脆</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">乌黑</td>
<td align="center">稍缩</td>
<td align="center">沉闷</td>
<td align="center">否</td>
</tr>
</tbody></table>
<p>表中4个样例，3种属性，属性个数分别为2，3，3，假若考虑没有泛化属性和空集的情况下，剔除含通配符和相同的项，得到无冗余的假设空间共有2$\times$3$\times$3=18种假设，这18种假设的自由组合成的析合范式能够唯一的表示所有的假设。</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
</tr>
</thead>
<tbody><tr>
<td align="center">a</td>
<td align="center">色泽=青绿</td>
<td align="center">色泽=乌黑</td>
<td align="center">—-</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">根蒂=蜷缩</td>
<td align="center">根蒂=稍蜷</td>
<td align="center">根蒂=硬挺</td>
</tr>
<tr>
<td align="center">c</td>
<td align="center">敲声=浊响</td>
<td align="center">敲声=清脆</td>
<td align="center">敲声=沉闷</td>
</tr>
</tbody></table>
<p>可列集合为（$a_1$$b_1$$c_1$, $a_1b_1c_2$ ,……, $a_2b_3c_3$)，将其简化为（$1,2,3,……,18$),</p>
<p>$k=1$时，所有的析合范式为：$(1,2,3,……18)$。</p>
<p>$k=2$时，所有的析合范式为：$((1,2),(1,3),(1,4),(1,5),……(16,17),(16,18),(17,18))$。</p>
<p>有可能的析合范式的个数为：$17+16+……+3+2+1$=153。</p>
<p>$k=3$时，析合范式的个数为816,代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">result=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">17</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((i+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((j+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>            <span class="hljs-built_in">print</span>((i,j,k))<br>            result=result+<span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>

<p>$k=4$时，析合范式的个数为3060,代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">result=<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> a1 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">16</span>):<span class="hljs-comment">#这里16和循环次数相加就等于20</span><br>    <span class="hljs-keyword">for</span> a2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((a1+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>        <span class="hljs-keyword">for</span> a3 <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((a2+<span class="hljs-number">1</span>),<span class="hljs-number">19</span>):<br>            <span class="hljs-keyword">for</span> a4  <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((a3  + <span class="hljs-number">1</span>), <span class="hljs-number">19</span>):<br>                <span class="hljs-built_in">print</span>((a1 ,a2 ,a3 ,a4 ))<br>                result=result+<span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>

<h4 id="1-5-3"><a href="#1-5-3" class="headerlink" title="*1.5.3"></a>*1.5.3</h4><p>若数据包含噪声，则假设空间中有可能不存在与所有训练样本都一致 的假设，在此情形下，试设计一种归纳偏好用于假设选择.</p>
<p><u>不会</u></p>
<p>数据包含噪声，其含义就是，存在训练集本身的部分数据，其<u>属性取值对应的标记值是错误的</u>。对于噪声，最理想的情况是去除所有噪声，即将这部分“错误”的数据剔除出训练集。但事实上，单从数据集本身来剔除噪声并无通用的办法，甚至无法直接判断哪些数据属于噪声。</p>
<p>通俗来讲，我们可以先认为所有不矛盾的数据是正确的，只有哪些属性值相同但标记值不同的数据，“相互矛盾”的情况下，才剔除一部分数据使矛盾消除，此时剔除的方法可以归纳为一种偏好。 </p>
<p>例如，属性值相同的两个数据，其标记值分别为正例和反例，可以设计归纳偏好为：<u>始终保留正例的数据，或始终保留反例的数据。</u><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/MaxQuYY/article/details/120287245">原文链接</a></p>
<h4 id="1-5-4"><a href="#1-5-4" class="headerlink" title="*1.5.4"></a>*1.5.4</h4><p>换用其它性能度量，试证明没有免费的午餐定理成立。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48493722">公式推导</a></p>
<h4 id="1-5-5"><a href="#1-5-5" class="headerlink" title="1.5.5"></a>1.5.5</h4><p>试述机器学习能在互联网搜索的哪些环节起什么作用.</p>
<ol>
<li>在向搜索引擎提交信息阶段，能够从提交文本中进行信息提取，进行语义分析。</li>
<li>在搜索引擎进行信息匹配阶段，能够提高问题与各个信息的匹配程度。</li>
<li>在向用户展示搜索结果的阶段，能够根据用户对结果感兴趣的程度进行排序。 </li>
</ol>
<h1 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h1><h3 id="章节主要内容"><a href="#章节主要内容" class="headerlink" title="章节主要内容"></a>章节主要内容</h3><p>在第一章绪论中，我们知道要根据具体的问题选择具体的算法和归纳偏好。那么要怎么判定我们的选择是正确的呢？这就需要拥有一套规范的模型评估与选择方法论了。</p>
<p>具体的章节思路可参考如下图解。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//5328356-6afc770c7199ac3d.jpeg" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8e369f73a0cc">参考链接</a></p>
<h3 id="2-1-机器学习为什么需要一套模型评估与选择方法论？"><a href="#2-1-机器学习为什么需要一套模型评估与选择方法论？" class="headerlink" title="2.1 机器学习为什么需要一套模型评估与选择方法论？"></a><strong>2.1 机器学习为什么需要一套模型评估与选择方法论？</strong></h3><p>在前一章的学习中，我们知道<u>机器学习是对数据集的泛化过程，即从输入的数据中归纳出一套能适用于所有潜在样本的“普遍规律”</u>。可因为训练数据不够充分，机器学习出来的模型并没办法涵盖所有的情况，这就会导致学习器的实际预测输出与样本的真实输出之间存在“误差”。</p>
<p>学习器在训练集上的误差称为“经验误差”，在新样本上的误差称为“泛化误差”。很明显，要使得分类器尽可能的有用，我们应该要让泛化误差仅可能的小。可惜在现实环境中，我们很难知道新样本是什么样的，所以我们实际能做的只有努力使经验误差最小化。</p>
<p>但如果将算法设计的尽可能百分百的满足所有训练样本，就忘了学习器真正要达到的是泛化误差尽可能小，而不是目前的折中方案降低经验误差。而在降低经验误差的道路上，有着机器学习领域最大的难题之一：<u><strong>“过拟合”</strong></u>。</p>
<p>“过拟合”是指学习器对训练样本学的太好了，导致泛化程度不够（机器学习本身就是一个泛化过程），没法适应新的数据样本。与之相反的还有一个“欠拟合”的概念，就是对训练样本中的一般规律都没学习好。举个例子，你通过姚明这个训练样本来学习一个人类判断器，如果你将身高两米二十以上作为判断是否是人的依据，那就是过拟合了；而如果你没有“直立行走”这样的特征都没有找出来作为判断是否是人的标准，那就是欠拟合了。</p>
<p>所以，为什么需要一套模型评估与选择的方法论呢？<u><strong>因为我们的训练数据没法真正代表真实的样本空间，而泛化误差无法直接获得，经验误差又因为过拟合的存在而不适合作为标准，所以我们才需要一套模型评估与选择的方法论。</strong></u></p>
<h4 id="2-1-1-经验误差与过拟合的相关概念"><a href="#2-1-1-经验误差与过拟合的相关概念" class="headerlink" title="2.1.1 经验误差与过拟合的相关概念"></a>2.1.1 经验误差与过拟合的相关概念</h4><p>误差分为训练误差、经验误差和泛化误差，前两种为在学习集上的误差，最后一种是在新样本上的误差。</p>
<p>错误率$E$=分类错误的样本数$a$/总样本数$m$</p>
<p>精度=$1 - $ 错误率=$1-\frac{a}{m}$</p>
<p>误差=学习器的实际预测输出-真实输出</p>
<p><strong>欠拟合与过拟合的例子</strong>：</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618142530466.png" srcset="/img/loading.gif" lazyload alt="image-20220618142530466"></p>
<h3 id="2-2-在已经知道为什么要对模型进行评估后，在不知道泛化误差的情况下，我们该如何进行评估呢？"><a href="#2-2-在已经知道为什么要对模型进行评估后，在不知道泛化误差的情况下，我们该如何进行评估呢？" class="headerlink" title="2.2 在已经知道为什么要对模型进行评估后，在不知道泛化误差的情况下，我们该如何进行评估呢？"></a><strong>2.2 在已经知道为什么要对模型进行评估后，在不知道泛化误差的情况下，我们该如何进行评估呢？</strong></h3><p>一个合理的思路是：<u>既然我们没法拿到新样本来进行泛化误差计算，那么我们可以从训练样本中取出一部分来，假装它是一组新样本，并用这些样本计算出来的误差作为泛化误差的近似。</u>这组选出来的样本被称为“测试集”，测试集上的误差被称为测试误差。我们学习本书的一个主要目的是学会机器学习领域的脉络和背后逻辑，这种评估思路是科学研究领域的一个常用思路。领悟这种思路有助于我们解决其它领域上的问题）</p>
<p>不过我们需要注意一点，那就是测试集应该尽量不与训练集重合，否则测试集计算出的误差将没法准确代表该学习器的泛化能力。</p>
<p>基于这个考虑，书中列出了以下几种把包含$m$个样例的数据集$D$划分为训练集$S$和测试集$T$的办法。</p>
<h4 id="［1］留出法（hold-out）"><a href="#［1］留出法（hold-out）" class="headerlink" title="［1］留出法（hold-out）"></a><strong>［1］留出法（hold-out）</strong></h4><p>直接将$D$划分为互斥的两部分$S和T$，在$S$上训练出模型后，用$T$来评估测试误差，即 $D=S\cup T$，$S\cap T=\empty$。</p>
<p>需要注意的是训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。</p>
<blockquote>
<p>“分层采样” (stratified sampling)：一种保留类别比例的采样方式. 例如通过对 D 进行分层采样而获得含 70% 样本的训练集 S 和含 30% 样本的测试集 T， 若 D 包含 500 个正例、 500 个反例，则分层采样得到的 S 应包含 350 个正例、 350 个反例?而 T 则包含 150 个正例和 150 个反例；若 S、 T 中样本类别比例差别很大，则误差估计将由于训练/测试数据分布的差异 而产生偏差.</p>
</blockquote>
<p>在样本数量上的划分上，为了平衡模型的准确性与测试结果的保真性，常见做法是将大约 2/3～ 4/5 的样本用于训练，剩余样本用于测试（一般而言，测试集至少应含 30 个样例）。</p>
<h4 id="［2］交叉验证法（cross-validation）"><a href="#［2］交叉验证法（cross-validation）" class="headerlink" title="［2］交叉验证法（cross validation）"></a><strong>［2］交叉验证法（cross validation）</strong></h4><p>将数据集 $D $划 分为 $k $个互斥子集，即$D=D_1\cup D_2\cup ……\cup D_k$，$D_i\cap D_j=\empty $，每次用$k-1 $个子集的并集作为训练集，余下的那个子集作为测试集；对获得的 $k$组训练/测试集进行 $k$ 次训练和测试，得到这 $k$ 个测试结果的均值。</p>
<p>显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 $k $的取值，为强调这一点，通常把交叉验证法称为 “$ k $折交叉验证” (k-fold cross validation). $k $最常用的取值是 10，此时称为 10 折交叉验 证；其他常用的$k$值有 5、 20 等.</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618155420458.png" srcset="/img/loading.gif" lazyload alt="image-20220618155420458"></p>
<p>交叉验证法的一 个特例:留一法(Leave-One-Out，简称 LOO) . 假定数据集 $D$ 中包含 $m$ 个样本，令 $k=m$ ，即子集数量设定为样本数量。</p>
<blockquote>
<p>10次10 折交叉验证法与100 次留出法都是进行了 100 次训练/测试</p>
</blockquote>
<h4 id="［3］自助法（bootstrapping）"><a href="#［3］自助法（bootstrapping）" class="headerlink" title="［3］自助法（bootstrapping）"></a><strong>［3］自助法（bootstrapping）</strong></h4><p>每次从$D$中随机复制一个样本到$D1$中，重复$m$次，会得到一个拥有$m$个数据样本的$D1$数据集。显然，$D$中的一部分数据会多次出现在$D1$中，而另一部分样本不出现。根据平均分布概率计算，大约有36.8%的数据不会被复制到$D1$中。</p>
<p>可以做一个简单的估计，样本在 $m$ 次采样中始终不被采到的概率是 $(1-\frac{1}{m})^m$， 取极限得到$\lim_{m\to \infin}(1-\frac{1}{m})^m \to \frac{1}{e} \approx. 0.368$</p>
<p>于是我们可将$ D’ $用作训练集， $D/D’ $用作测试集；这样实际评估的模型与期望评估的模型都使用 $m $个训练样本，而我们仍有数据总量约 $1/3$ 的，没在训练集中出现的样本用于测试。这样的测试结果，亦称”包外估计” (out-of-bag estimate).</p>
<h4 id="［4］注意点"><a href="#［4］注意点" class="headerlink" title="［4］注意点"></a><strong>［4］注意点</strong></h4><p>训练/测试集的划分要尽可能保持数据分布一致性。</p>
<p>单次划分往往不够稳定可靠，一般要采用若干次随机划分、重复进行实验评估后取平均值作为评估结果。</p>
<p>训练/测试集的划分比例没有完美答案，训练样本多会使得模型更接近$D$，测试样本多会使得评估结果更可靠，这其中的取舍因人/场景而异。常见的训练/测试划分比例是2:1～4:1。</p>
<h4 id="［5］调参"><a href="#［5］调参" class="headerlink" title="［5］调参"></a><strong>［5］调参</strong></h4><p>不同的参数其实就代表着不同的模型了。一般参数分两种：一类是算法的参数，亦称“超参数”，如聚类要分的簇数量$k$；一类是模型的参数，如神经网络中每个节点的权重。前者多为人工选择一组候选，后者是让机器自己学习。</p>
<p>常用的做法是对每个参数选定一个范围和变化步长，<u>例如在 [0， 0.2] 范围内以 0.05 为步长，则实际要评估的候选参数值有 5 个，最终是从这 5 个候选值中产生选定值。简单估算一下：假定算法有 3 个参数，每个参数仅考虑 5 个候选 值，这样对每一组训练/测试集就有 53 = 125 个模型需考察；</u>很多强大的学习算 法有大量参数需设定，这将导致极大的调参工程量，例如大型”深度学习模型甚至有上百亿个参数。</p>
<p>调参是机器学习的重点，也是决定模型性能的关键。一般调参过程中，会将训练数据再次划分为训练集和验证集（validation set）。具体包含关系如下：<img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619171542448.png" srcset="/img/loading.gif" lazyload alt="image-20220619171542448"></p>
<h4 id="［6］适用性"><a href="#［6］适用性" class="headerlink" title="［6］适用性"></a><strong>［6］适用性</strong></h4><p>自助法在数据集较小、难以有效划分训练/测试集时很有用</p>
<p>自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。</p>
<p>留出法和交叉验证法由于都把数据集中的一部分用来测试，没有参与训练，因此必然会引入一些因训练样本规模不同而导致的估计偏差，留一法受影响较小，但计算复杂度又太高了。</p>
<h3 id="2-3-在了解了有效可行实验评估方法后，接下来我们需要了解一下具体的衡量模型泛化能力的评价标准，即性能度量（performance-measure）"><a href="#2-3-在了解了有效可行实验评估方法后，接下来我们需要了解一下具体的衡量模型泛化能力的评价标准，即性能度量（performance-measure）" class="headerlink" title="2.3 在了解了有效可行实验评估方法后，接下来我们需要了解一下具体的衡量模型泛化能力的评价标准，即性能度量（performance measure）"></a><strong>2.3 在了解了有效可行实验评估方法后，接下来我们需要了解一下具体的衡量模型泛化能力的评价标准，即性能度量（performance measure）</strong></h3><p>性能度量反映了任务需求，使用不同的性能度量会导致对模型的评判结果不同。这意味着模型的“好坏”是相对的，什么样的模型是好的，不仅取决于算法和数据，还决定于任务需求。</p>
<p>在预测任务中，给定样例集 $D = {(x1 , y1) , (x2 ， y2)， . . . , (xm, ym)} $， 其中 $yi$ 是示例 $xi$ 的真实标记。要评估学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$  与真实标记  $y$ 进行比较。</p>
<p>回归任务<strong>最常用的性能度量</strong>是”<strong>均方误差</strong>“ (mean squared error)：</p>
<p>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(xi)-yi)^2<br>$$<br>更一般的，对于数据分布 $Ð$ 和概率密度函数 $p(.) $， 均方误差可描述为</p>
<p>$$<br>E(f;Ð)=\int_{x～Ð}(f(x)-y)^2p(x)dx<br>$$</p>
<h4 id="2-3-1-错误率与精度"><a href="#2-3-1-错误率与精度" class="headerlink" title="2.3.1 错误率与精度"></a>2.3.1 错误率与精度</h4><p>对样例集 $D$，分类错误率定义为：</p>
<p>$$<br>E(f;D)=\frac{1}{m}\sum_{i=1}^{m}I(f(xi)\ne yi)<br>$$<br>精度则定义为：</p>
<p>$$<br>acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}I(f(xi)= yi)=1-E(f;D)<br>$$<br>更一般的，对于数据分布 $Ð$ 和概率密度函数 $p(.)$ ，错误率与精度可分别描述为</p>
<p>$$<br>E(f;Ð)=\int_{x～Ð}(f(x)\ne y)p(x)dx<br>$$</p>
<p>$$<br>acc(f;Ð)=\int_{x～Ð}(f(x)= y)p(x)dx=1-E(f;Ð)<br>$$</p>
<h4 id="2-3-2-查准率、查全率与-F1"><a href="#2-3-2-查准率、查全率与-F1" class="headerlink" title="2.3.2 查准率、查全率与$F1$"></a>2.3.2 查准率、查全率与$F1$</h4><p>查准率和查全率可以理解为”挑出的西瓜中有多少比例是好瓜”，或者”所有好瓜中有多少比例被挑了出来”，或者”检索出的信息中有多少比例是用户感兴趣的” 和”用户感兴趣的信息中有多少被检索出来了”。</p>
<p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例 (true positive) 、假正例 (false positive) 、真反例 (true negative) 、 假反例 (false negative) 四种情形，令 $TP、 FP、 TN、 FN$ 分别表示其对应的样例数，则显然有 $TP+FP+TN+FN=样例总数$。分类结果的误差矩阵或者精度矩阵称为”混淆矩阵” (confusion matrix)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618175331853.png" srcset="/img/loading.gif" lazyload alt="image-20220618175331853"></p>
<p>查准率 $P $ 与查全率 $R$ 分别定义为：</p>
<p>$P=\frac{TP}{TP+FP}$  =  真正例 / 预测出的正例</p>
<p>$R=\frac{TP}{TP+FN}$ =。真正例 / 实际上的正例</p>
<p>二者通常呈反比。</p>
<p>举个例子：假设有10个西瓜，6个好瓜，4个坏瓜。我们将这十个瓜按照预测结果排序，最可能是好瓜的排在前头，最不可能的排在最后，然后控制学习器的分类阀值来依次逐个把样本作为好瓜来进行预测，则可以计算出不同的阀值时的$P$和$R$如下表所示：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody><tr>
<td>TP</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>6</td>
<td>6</td>
<td>6</td>
<td>6</td>
</tr>
<tr>
<td>FN</td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>FP</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>TN</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>P</td>
<td>X</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>6/7</td>
<td>6/8</td>
<td>6/9</td>
<td>6/10</td>
</tr>
<tr>
<td>R</td>
<td>0</td>
<td>1/6</td>
<td>2/6</td>
<td>3/6</td>
<td>4/6</td>
<td>5/6</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<p>由上边例子可以看到，P和R的值也基本满足了一方升高，另一方下降的状况，通常只有在一些简单的任务（比如我举的这个）中，才可能使查全率和查准率都很高。以查准率为纵轴、查全率为横轴作图，就得到了查准率－查全率曲线，简称“P-R曲线”。</p>
<p>再举个例子：</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//20160721114615857-20220619182907525.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>Inst#是样本序号，图中有20个样本。Class是ground truth 标签，p是positive样本（正例），n当然就是negative（负例） score是分类器对于该样本属于正例的可能性的打分。因为一般模型输出的不是0,1的标注，而是小数，相当于置信度。</p>
<p>然后设置一个从高到低的阈值y，大于等于阈值y的被正式标注为正例，小于阈值y的被我正式标注为负例。</p>
<p>显然，设置n个阈值，就能得到n种标注结果，评判模型好不好使。</p>
<p>比如阈值0.9，只有第一个样本被判断为正例，那么我的查准率precision就是100%，但是查全率recall就是10%。阈值0.1，所有样本都被我判断为正例，查全率是100%，查准率就是50%</p>
<p>最后我能得到若干对precision，recall值(P,R) :  (1, 0.1),… ,(0.5,1),将这若干对画在图上，再连接起来就是这个pr曲线了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//20160721111312507.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>在进行比较时，若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者。当曲线有相交时，很难断言两者的优劣。真要判别时，“平衡点”（Break-Even Point）是一个不错的度量方法。下图是一个具体的示意图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220618181148275.png" srcset="/img/loading.gif" lazyload alt="image-20220618181148275"></p>
<p>平衡点(Break-Event Point，简称 BEP)，它是” 查准率=查全率”时的取值，例如上图中基于 BEP的比较，可认为学习器 A 优于 B。</p>
<p>但 BEP 还是过于简化了些，更常用的是 F1 度量：</p>
<p>$$<br>F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}<br>$$<br>$F1$ 是基于查准率与查 全率的调和平均 (harinonic mean)定义的:</p>
<p>$$<br>\frac{1}{F1}=\frac{1}{2}.(\frac{1}{P}+\frac{1}{R})<br>$$<br>在不同的条件下，对查准率和查全率的重视程度有所不同。比如在大数据推送时，为了少打扰用户，更希望能推荐用户感兴趣的广告，此时查准率要比查全率更重要；在追捕逃犯时，为了不漏掉逃犯，此时查全率比查准率更重要。为了表达出对查准率/查全率的不同偏好，定义了$F1 $度量的一般形式<br>$$<br>F_\beta=\frac{(1+\beta^2)\times P \times R}{(\beta^2 \times P)+R}<br>$$<br>$ß&gt; 1$ 时查全率有更大影响 ; $ß &lt; 1$ 时查准率有更大影响。</p>
<p>很多时候我们有多个二分类混淆矩阵，例如进行多次训练/测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练/测试，希望估计算法的”全局” 性能；甚或是执行多分类任务，每两两类别的组合都对应一个混淆矩阵，总之，我们希望在 $n$ 个二分类混淆矩阵上综合考察查准率和查全率。</p>
<p>一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率，记为 $(P_1， R_1 ) ， (P_2 ， R_2) ，…… ， (Pn ， Rn)$ ，再计算平均值，这样就得到”宏查准率” ($macro-P$) 、”宏查全率” ($macro-R$) ，以及相应的”宏 $F1$” ($macro-F1$):</p>
<p>$$<br>macro-P=\frac{1}{n}\sum^n_{i=1}P_i<br>$$</p>
<p>$$<br>macro-R=\frac{1}{n}\sum^n_{i=1}R_i<br>$$</p>
<p>$$<br>macro-F1=\frac{2\times macro-P \times macro-R}{macro-P+macro-R}<br>$$</p>
<p>还可先将各混 淆矩阵的对应元素进行平均，得到 $TP 、FP 、 TN 、FN$ 的平均值，分别记为 $\overline{TP}、 \overline{FP}、 \overline{TN}、 \overline{FN}$，再基于这些平均值计算出”微查准率 “(micro-P) 、 “微查全率” (micro-R)和”微F1” (micro-F1):</p>
<p>$$<br>micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}<br>$$</p>
<p>$$<br>micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}<br>$$</p>
<p>$$<br>micro-F1=\frac{2\times micro-P\times micro-R}{micro-P+micro-R}<br>$$</p>
<h4 id="2-3-3-ROC-与-AUC"><a href="#2-3-3-ROC-与-AUC" class="headerlink" title="2.3.3 ROC 与 AUC"></a>2.3.3 ROC 与 AUC</h4><p>ROC：“受试者工作特征”（receiver operating characteristic）曲线，与P-R 曲线类似，只不过取用“真正利率”（TPR ）作为纵轴，“假正例率”（FPR）作为横轴 ，两者分别定义为</p>
<p>$$<br>TPR=\frac{TP}{TP+FN},FPR=\frac{FP}{TN+FP}<br>$$<br>显示 ROC 曲线的图称为 “ROC 图”，显然，对角线对应于 “随机猜测” 模型，而点 ($0，1)$ 则对应于将所有正例排在所有反例之前的”理想模型”。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619155415423.png" srcset="/img/loading.gif" lazyload alt="image-20220619155415423"></p>
<p>现实任务中测试样例有限 ，无法产生图 a 中的光滑 ROC 曲线，只能绘制出如图 b 所示的近似 ROC 曲线。绘图过程很简单：给定 $m^+ $个正例和$m^-$ 个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为 0， 在坐标$ (0， 0)$ 处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为 $(x， y) $， 当前若为真正例，则对应标记点的坐标为 $(x， y + \frac{1}{m^+})$ ;当前若为假正例，则对应标记点的坐标为 ($( x + \frac{1}{m^-},y)$ ，然后用线段连接相邻点即得。</p>
<p>​        进行学习器的比较时，与 P-R 图相似， 若一个学习器的 ROC 曲线被另 一个学习器的曲线完全”包住”， 则可断言后者的性能优于前者；若两个学习 器 的 ROC 曲线发生交叉，则难以一般性地断言两者孰优孰劣。此时如果一定要进行比较，则较为合理的判据是比较 ROC 曲线下的面积，即 AUC (Area Under ROC Curve) 。</p>
<p>​        从定义可知， AUC 可通过对 ROC 曲 线下各部分的面积求和而得,估算为</p>
<p>$$<br>AUC=\frac{1}{2}\sum^{m-1}<em>{i=1}(x</em>{i+1}-x_i).(y_i+y_{i+1})<br>$$</p>
<h4 id="2-3-4-代价敏感错误率与代价曲线"><a href="#2-3-4-代价敏感错误率与代价曲线" class="headerlink" title="2.3.4 代价敏感错误率与代价曲线"></a>2.3.4 代价敏感错误率与代价曲线</h4><p>代价敏感错误率代表数据的平均总体代价。</p>
<p>不同类型的错误所造成的后果不同，为权衡不同类型错误所造成的不同损失，可为错误赋予”非均等代价” (unequa1 cost)。以二分类任务为例，我们可根据任务的领域知识设定一个”代价矩阵” (cost matrix) ，其中 $cost_{ij} $表示将第$ i $类样本预测为第 $j $类样本的代价。一般来说， $cost_{ii} = 0$；若将第 0 类判别为第 1 类所造成的损失更大，则 $cost_{01} &gt; cost_{10}$; 损失程度相差越大， $cost_{01} 与 cost_{10}$ 值的差别越大。</p>
<table>
<thead>
<tr>
<th align="center">真实</th>
<th align="center">预测</th>
<th align="center">类别</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td align="center">类别</td>
<td align="center">第0类</td>
<td align="center">第1类</td>
<td></td>
</tr>
<tr>
<td align="center">第0类</td>
<td align="center">0</td>
<td align="center">$cost_{01{}}$</td>
<td></td>
</tr>
<tr>
<td align="center">第1类</td>
<td align="center">$cost_{10}$</td>
<td align="center">0</td>
<td></td>
</tr>
</tbody></table>
<p>上面的例子中都隐式地假设了均等代价，所定义的错误率是直接计算错误次数。而在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化”总体代价” (total cost). 若将表中的第 0 类作为正类、第 1 类作为反类，令 $D^+$ 与 $D^-$分别代表样例集 D 的正例子集和反例子集，则”代价敏感” (cost-sensitive)错误率为</p>
<p>$$<br>E(f;D;cost)=\frac{1}{m}(\sum_{x_i\in D^+}I(f(x_i)\ne y_i)\times cost_{01}+\sum_{x_i\in D^-}I(f(x_i)\ne y_i)\times cost_{10})<br>$$<br>在非均等代价下， ROC 曲线不能直接反映出学习器的期望总体代价，而”代价曲线” (cost curve) 则可达到该目的.代价曲线图的横轴是取值为 [0,1]的正例概率代价</p>
<p>$$<br>P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}<br>$$<br>其中 $p$ 是样例为正例的概率；纵轴是取值为 [0,1] 的归一化代价。<br>$$<br>P(+)cost=\frac{FNP\times p\times cost_{01}+FNP\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}<br>$$<br>其中 $FPR$ 是假正例率， $FNR = 1 - TPR$ 是假反例率。</p>
<p>代价曲线的绘制很简单：ROC 曲线上每一点对应了代价平面上的一条线段 ， 设 ROC 曲线上点的坐标为 $(TPR， FPR)$ ，则可相应计算出 $FNR$，然后在代价平面上绘制 一条从 $(0， FPR)$ 到 $(1 ，FNR)$ 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将 ROC 曲线上的每个点转化为代价平面上的一条线段，然后取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价。</p>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619191716330.png" srcset="/img/loading.gif" lazyload alt="image-20220619191716330"></p>
<h3 id="2-4-有了实验评估方法和性能度量，就要研究如何应用方法和度量指标去对学习器的性能进行评估比较了"><a href="#2-4-有了实验评估方法和性能度量，就要研究如何应用方法和度量指标去对学习器的性能进行评估比较了" class="headerlink" title="2.4 有了实验评估方法和性能度量，就要研究如何应用方法和度量指标去对学习器的性能进行评估比较了"></a><strong>2.4 有了实验评估方法和性能度量，就要研究如何应用方法和度量指标去对学习器的性能进行评估比较了</strong></h3><p>研究怎么来做“比较”是很有必要的，因为第一，我们要的是<strong>泛化性能</strong>，但是能用的只是测试性能；第二，测试性能和测试集的选择对测试结果有很大影响；第三，有的机器学习算法本身也有随机性，对同一测试集的多次测试结果也可能会不同。</p>
<p>为了解决这些问题，统计假设检验（hypothesis test）为我们提供了重要的依据。</p>
<h4 id="2-4-1-假设检验"><a href="#2-4-1-假设检验" class="headerlink" title="2.4.1 假设检验"></a>2.4.1 假设检验</h4><blockquote>
<p>西瓜书介绍的是假设检验方法，个人认为更好的方式应该是求泛化性能的置信区间，而不是进行假设检验。置信区间不仅可以得到泛化性能的一个区间，同时它也可以进行假设检验。所以，置信区间完全可以替换掉假设检验。</p>
<p>泛化性能的估计值 u=k/n，它是泛化性能p的一个无偏估计，E(u)=p，u的方差为 u*(1-u)/n，基于中心极限定理知道 u 渐进符合正态分布 N[p,u*(1-u)/n]。知道了u的抽样分布，u的置信区间就可以计算出来。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/259232881">如何计算置信区间</a></p>
</blockquote>
<p>假设检验中的“假设”是对学习器泛化错误率分布的某种猜想或判断，现实任务中学习器的泛化错误率不可知，只能获知其测试错误率，尽管二者未必相同，但肯定相似，因此， 可根据测试错误率估推出泛化错误率的分布。</p>
<p>然后通过假设的验证结果来对不同的学习器或模型的性能进行判断。比如假设“学习器A和B性能相同”，当该假设被拒绝时，说明学习器A和B具有显著差异，这时候错误率较低的学习器性能较优。</p>
<p>假设检验的具体逻辑和使用方法是这样的：</p>
<p>［1］设定一个假设，比如“一个机器学习真正的泛化错误率不大于0.3”</p>
<p>［2］设定一个置信概率“显著度a”，a的一般取值为0.05、0.1；a代表的意思是当我们的假设成立的概率在（1-a，1］的范围内时，我们认为是成立的。</p>
<p>［3］计算使假设在置信范围内成立的最大值是多少，比如根据上边［1］中的假设，要使泛化错误率不大于0.3成立，即泛化错误率小于0.3的概率大于（1-a）。要计算这个，我们要算出要使错误率大于0.3的概率之和小于a时的最大泛化错误率是多少。</p>
<p>［4］比较计算出的满足假设的最大值和我们实际计算出的值，如果我们实际计算出来的错误率已经大于最大可能的错误率了，说明假设不成立。</p>
<p>［5］在这里的假设中，假设不成立说明我们的学习器错误率要大于0.3啊，这是个很烂的学习器，我们还需要继续调优。</p>
<p>在实际实验时，我们会多次使用留出法或交叉验证法进行多次训练/测试，那么我们实际上会得到多个测试错误率（这里假设为$k$个）。我们可以通过求这些错误率的平均和方差来将假设检验转换为自由度为$k-1$的$ t $分布。通过查询 $t$ 检验常用临界表可以很方便的计算出假设是否成立。</p>
<p>书中提到的交叉验证 $t $检验、Friedman检验与Nemenyi后续检验都是基于一样的假设检验流程的稍微变化。其中交叉验证 $t$ 检验是针对两种学习器之间性能的比较，Friedman检验与Nemenyi后续检验是针对多个学习器之间性能的比较。在这里就不一一介绍了。</p>
<h3 id="2-5-对学习算法除了通过实验估计其泛化性能，我们还需要理解“为什么”具有这样的性能，“偏差与方差分解”（bias-variance-decomposition）是解释学习算法泛化性能的一种重要工具"><a href="#2-5-对学习算法除了通过实验估计其泛化性能，我们还需要理解“为什么”具有这样的性能，“偏差与方差分解”（bias-variance-decomposition）是解释学习算法泛化性能的一种重要工具" class="headerlink" title="2.5 对学习算法除了通过实验估计其泛化性能，我们还需要理解“为什么”具有这样的性能，“偏差与方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具"></a><strong>2.5 对学习算法除了通过实验估计其泛化性能，我们还需要理解“为什么”具有这样的性能，“偏差与方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具</strong></h3><p>省略具体的算法和公式推导过程，偏差与方差分解是对学习算法的期望泛化错误率的分解，分解结果是下边这个重要的公式</p>
<p>$E(f;D)=bias^2(x)+var(x)+\varepsilon^2$</p>
<p>也就是说，泛化误差可分解为偏差、方差与噪声之和。</p>
<p>其中，偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法的拟合能力；方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所带来的影响；噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<p>偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p>
<p>一般来说，偏差与方差是有冲突的。要使偏差小则需要算法对数据充分拟合，这就有可能会导致过拟合，这样对新样本的适应性差，就会导致方差变高。反之亦然，拟合过低，偏差较大，但是方差会相对较低。</p>
<blockquote>
<p>很多学习算法都可控制训练程度，例如决策树可控制层数，神经网络可控制训练轮数，集成学习方法可控制基学习器个数。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/moyudexiaosong/picGo-use//image-20220619224405067.png" srcset="/img/loading.gif" lazyload alt="image-20220619224405067"></p>
<h3 id="2-6-总结"><a href="#2-6-总结" class="headerlink" title="2.6 总结"></a>2.6 总结</h3><p>泛化误差无法获得，经验误差因为过拟合的存在而不适合作为标准，导致我们需要专门的模型评估方法来测量学习器的效果。</p>
<p>专门的模型评估方法是通过从数据集中选取一部分数据作为测试集来对训练出的模型进行验证，以测试误差来近似泛化误差实现的。</p>
<p>测试误差体现在具体的性能度量指标上，我们要根据具体情况选择对应的指标。</p>
<p>假设检验是我们对学习器性能进行比较的有效方法。</p>
<p>泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p>
<p>通常来讲，更多的数据胜过更好的算法：对一批数据使用高明的算法，比不上用普通算法但是引入一部分外部数据源的效果要好。</p>
<p><a target="_blank" rel="noopener" href="http://anand.typepad.com/datawocky/2008/03/more-data-usual.html">额外阅读</a></p>
<h3 id="2-7-习题"><a href="#2-7-习题" class="headerlink" title="2.7 习题"></a>2.7 习题</h3><h4 id="2-7-1"><a href="#2-7-1" class="headerlink" title="2.7.1"></a>2.7.1</h4><p><em>数据集包含 1000 个样本，其中 500 个正例、 500 个反例，将其划分为包含 70% 样本的训练集和 30% 样本的测试集用于留出法评估，试估算共有多少种划分方式。</em></p>
<p>500个正例和500个反例，根据分层抽样的原则，30%的测试样本共300个，其中必须包含150个正例和150个反例。若不考虑样本其他的分布情况，则选取方式为：从500个正例中随机抽取150个，再从500个反例中随机抽取150个，两个过程相互独立，则共有$(C_{500}^{150})^2$种方式。</p>
<h4 id="2-7-2"><a href="#2-7-2" class="headerlink" title="2.7.2"></a>2.7.2</h4><p><em>数据集包含 100 个样本，其中正、反例各一半，假定学习算法所产生的模型是将新样本预测为训练样本数较多的类别(训练样本数相同时进行随机猜测)，试给出用 10 折交叉验证法和留一法分别对错误率进行评估所得的结果。</em></p>
<p>10 折交叉验证法：将样本集划分为10个同分布不相交的子集，将其中9个作为训练集，1个作为测试集，每个划分可得到10次不同的训练和验证。对于题目所述的模型，总是将新样本预测为训练样本较多的类别，但每一次验证时，训练集的正例和反例一样多，将会进行随机猜测。每次都进行随即猜测，其错误率的期望是50%。</p>
<p>留一法：$k$折交叉验证中$k$等于样本个数的特例。在题目所述的情况下，即将100个样本每次取出1个样本用于测试，99个用于训练。当1个测试样本为正例时，99个训练样本为50个反例和49个正例，新样本将被预测为出现较多的反例，而测试样本的ground truth是正例，必然会预测错误。当测试样本为反例时同理必然会预测错误，此时错误率的期望为100%。</p>
<h4 id="2-7-3"><a href="#2-7-3" class="headerlink" title="2.7.3"></a>2.7.3</h4><p><em>若学习器 A 的 F1 值比学习器 B 高，试析 A 的 BEP 值是否也比 B 高。</em></p>
<p>F1：查准率P和查全率R的调和平均；</p>
<p>BEP：Beak-Even Point，P-R曲线上P = R时二者的取值。</p>
<p>F1和BEP有概念上的巨大差异，二者没有必然联系。P-R曲线的定义是：学习器将所有样本按“可能是正例”的概率从前向后排序，然后依次将前若干个样本按正例进行预测，所得出的预测结论。注意此时<u>BEP曲线只是衡量了学习器进行“排序”的性能，并不包含最终预测的结果。</u>也就是说，给定了P-R曲线的情况下，根据不同的预测策略，会产生不同的P和R。<u>而F1是一个确定的概念，是在P和R都确定的情况下计算出的二者的调和平均。</u>因此在同一P-R曲线上，F1在不同的位置有不同的取值。</p>
<p>因此对于题目所述的假设，我们很容易给出反例：对于R-P曲线完全相同的两个学习器，二者的P-R曲线上存在两个不同位置，使得对应的F1值不同。不妨设F1值较大的位置所对应的预测策略为学习器A，另一个为B，此时学习器A的F1值比学习器B高，但二者P-R曲线完全相同，也有相同的BEP值。</p>
<h4 id="2-7-4"><a href="#2-7-4" class="headerlink" title="2.7.4"></a>2.7.4</h4><p><em>试述真正例率(TPR) 、假正例率 (FPR)与查准率(P) 、查全率(R)之间的联系。</em></p>
<p>查全率: 真实正例被预测为正例的比例。<br>真正例率: 真实正例被预测为正例的比例。<br>显然查全率与真正例率是相等的。</p>
<p>查准率:预测为正例的实例中真实正例的比例。<br>假正例率: 真实反例被预测为正例的比例。<br>两者并没有直接的数值关系。</p>
<h4 id="2-7-5"><a href="#2-7-5" class="headerlink" title="*2.7.5"></a>*2.7.5</h4><p><em>试证明式(2.22).</em></p>
<p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/pumpkin-book/#/chapter2/chapter2?id=_221">南瓜书中有证明，但同时，根据南瓜书的建议</a></p>
<blockquote>
<p>对于初学机器学习的小白，西瓜书第1章和第2章的公式<strong>强烈不建议深究</strong>，简单过一下即可，等你学得有点飘的时候再回来啃都来得及。</p>
</blockquote>
<h4 id="2-7-6"><a href="#2-7-6" class="headerlink" title="2.7.6"></a>2.7.6</h4><p><em>试述错误率与 ROC 曲线的联系。</em></p>
<p>ROC曲线本质上只反映学习器的“排序能力”，而具体的预测策略则取决于在ROC曲线上的哪一点作截断。当确定了一种预测策略时，才会对应一个确定的错误率。因此可以说，ROC曲线上的每一点，对应了学习器一种情况下的错误率。</p>
<h4 id="2-7-7"><a href="#2-7-7" class="headerlink" title="2.7.7"></a>2.7.7</h4><p><em>试证明任意一条 ROC 曲线都有一条代价曲线与之对应，反之亦然.</em></p>
<p>代价曲线、ROC曲线、P-R曲线都是为了描述某一学习器的“排序能力”而引入的概念。ROC曲线下方的面积仅能在“错误代价均等”的条件下反应学习器的排序质量，而在错误代价并不均等的情况下，引入代价矩阵后，应当使用代价曲线来反应考虑代价的排序质量。但不论使用哪一种曲线，衡量哪一种面积，一旦学习器给定，其排序质量是一定的，则三种曲线都是确定的。从这一角度来看，任意一条ROC曲线都对应了一个确定的学习器，而该学习器有唯一确定的代价曲线，反之亦然。</p>
<p>若要严格证明该结论，西瓜书给出了ROC曲线和代价曲线的转换方法：ROC曲线上每一点对应了代价平面上的一条线段，设ROC曲线上点的坐标为(FPR, TPR)，则可计算相应的FNR，然后再代价平面上绘制一条从(0, FPR)到(1, FNR)的线段，如此求出ROC曲线上所有点对应的线段，其下界围成的曲线即代价曲线。同理，在代价曲线上寻找一个连续的分段，将其线段计算出相应的FPR与FNR，再计算出TPR，即得到ROC曲线上的一个点，连接所有如此的到的点即得ROC曲线。</p>
<h4 id="2-7-8"><a href="#2-7-8" class="headerlink" title="2.7.8"></a>2.7.8</h4><p><em>Min-Max规范化与z-score规范化如下所示。试析二者的优缺点</em></p>
<p>Min−max规范化方法简单，而且保证规范化后所有元素都是正的，每当有新的元素进来，只有在该元素大于最大值或者小于最小值时才要重新计算全部元素。但是若存在一个极大(小)的元素，会导致其他元素变的非常小(大)。</p>
<p>z−score标准化对个别极端元素不敏感，且把所有元素分布在0的周围，一般情况下元素越多，0周围区间会分布大部分的元素，每当有新的元素进来，都要重新计算方差与均值。</p>
<h4 id="2-7-9"><a href="#2-7-9" class="headerlink" title="2.7.9"></a>2.7.9</h4><p><em>试述 χ2 检验过程.</em></p>
<p><a target="_blank" rel="noopener" href="http://guoze.me/2015/09/07/chi-square/">参考链接</a></p>
<h4 id="2-7-10"><a href="#2-7-10" class="headerlink" title="2.7.10*"></a>2.7.10*</h4><p><em>试述在Friedman 检验中使用式 (2.34) 与 (2.35) 的区别.</em></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/daigz1224/p/7163342.html">参考链接</a></p>
<h1 id="第-3-章-线性模型"><a href="#第-3-章-线性模型" class="headerlink" title="第 3 章 线性模型"></a>第 3 章 线性模型</h1><h3 id="章节主要内容-1"><a href="#章节主要内容-1" class="headerlink" title="章节主要内容"></a>章节主要内容</h3><ul>
<li><strong>线性判别分析(LDA)<strong>是一种经典的</strong>监督线性降维方法</strong>:设法将训练样例投影到一条直线上,使同类样例的投影点尽可能接近,异类样例的投影点尽可能远离.对新样本分类时根据投影点的位置来确定类别.</li>
<li><strong>多分类学习的分类器</strong>一般有以下三种策略:</li>
</ul>
<ol>
<li>一对一(OvO),N个类别产生N * (N - 1) / 2种分类器</li>
<li>一对多(OvR或称OvA),N个类别产生N - 1种分类器</li>
<li>多对多(MvM),如纠错输出码技术</li>
</ol>
<ul>
<li>解决<strong>类别不平衡问题</strong>的三种方法:</li>
</ul>
<ol>
<li><strong>过采样法</strong>,增加正例使正负例数目接近,如<strong>SMOTE</strong>:思想是合成新的少数类样本,合成的策略是对每个少数类样本a,从它的最近邻中随机选一个样本b,然后在a、b之间的连线上随机选一点作为新合成的少数类样本.</li>
<li><strong>欠采样法</strong>,减少负例使正负例数目接近,如<strong>EasyEnsemble</strong>:每次从大多数类中抽取和少数类数目差不多的重新组合,总共构成n个新的训练集,基于每个训练集训练出一个AdaBoost分类器（带阈值）,最后结合之前训练分类器结果加权求和减去阈值确定最终分类类别.</li>
<li>再缩放法</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/04786709258b">思维导图</a></p>
<p>3.1 基本形式</p>
<p>线性模型是什么，简单来说和我们学过的线性函数是一样的，我们学过的线性函数形式一般为：$y = ax + b$，在这里$a，b$代表系数，也就是我们模型要学习的东西，代表的是属性，也就是我们的特征。</p>
<p>给定由 $d$ 个属性描述的示例$x=(x_1;x_2;……;x_d)$ ， 其中$x_i$是 $x$ 在第 $i$ 个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即$f(x)=w_1x_1+w_2x_2+……+w_dx_d+b$ ，一般用向量形式写成$f(x)=w^Tx+b$ ，其中$w=(w_1;w_2;…;w_d)$ ，$w$ 和 $b$ 学得之后，模型就得以确定。</p>
<p>举一个例子，在西瓜样例中，<br>$$<br>f_{好瓜}(x)=0.2\times x_{色泽}+0.5\times x_{根蒂}+0.3\times x_{敲声}+1<br>$$<br>其中0.2,0.5,0.3还有1 都是属于线性模型通过训练数据学到的系数，而其中的色泽，根蒂，敲声属于一个样本的各个特征，我们在本章中先从回归讲起，然后讨论二分类再讨论多分类问题。 </p>
<p>3.2 线性回归</p>
<p>首先我们考虑最简单的问题，也就是只有一个输入属性的情况。</p>
<p>对离散属性，若属性值间存在”序” (order)关系，可通过连续化将其转化为连续值，例如二值属性”身高”的取值——“高” “矮”可转化为 {1.0,0.0}，三值属性”高度” 的取值”高” “中” “低”可转化为 {1.0, 0.5, 0.0}；若属性值间不存在序关 系，假定有 $k$ 个属性值，则通常转化为 $k$ 维向量，例如属性”瓜类”的取值”西瓜”、”南瓜”、”黄瓜”可转化为(0,0,1),(0,1,0),(1,0,0)。</p>
<p>线性回归试图学得$f(x_i)=wx_i+b$ ，使得$f(x_i)\approx y_i$ ，</p>
<p><u><em>如何确定 $ω$ 和 $b$ 呢？显然，关键在于如何衡量$ f(x) $与 $y$ 之间的差别。</em></u></p>
<p>这时候需要用到均方误差了，也就是我们常说的”欧式距离“，我们可以通过让均方误差最小化来求解需要的$w,b$。即<br>$$<br>(w^*,b^*)=arg\min_{(w,b)}\sum^m_{i=1}(f(x_i)-y_i)^2=arg\min_{(w,b)}\sum^m_{i=1}(y_i-wx_i-b)^2<br>$$<br>求解$w$和$b$使所有样本到一条直线上的欧氏距离之和最小，称为线性回归模型的最小二乘”参数估计” (parameter estimation).。我们可将上式对 $ω $和 $b$ 分别求导，得到<br>$$<br>\frac{\partial{E_{w,b}}}{\partial w}=2(w\sum^m_{i=1}x_i^2-\sum^m_{i=1}x_i(y_i-b))<br>$$</p>
<p>$$<br>\frac{\partial{E_{w,b}}}{\partial b}=2(mb-\sum^m_{i=1}(y_i-wx_i))<br>$$</p>
<p>令导数等于0可得到$w$和$b$最优解的闭式解：<br>$$<br>w=\frac{\sum^m_{i=1}y_i(x_i-\overline{x})}{\sum^m_{i=1}x_i^2-\frac{1}{m}(\sum^m_{i=1}x_i)^2}<br>$$</p>
<p>$$<br>b=\frac{1}{m}\sum^m_{i=1}(y_i-wx_i)<br>$$</p>
<p>其中$\overline{x}=\frac{1}{m}\sum^m_{i=1}x_i$为 $x$ 的均值。</p>
<p>当我们的问题中存在的不止一个特征，我们称之为多元线性回归，形式与上述过程类似。<br>把$w,b$吸入向量模式，表示形式为$\hat{w}=(w;b)$，然后把数据集$D$表示为一个$m*(d+1)$的大小矩阵，前$d$行对应$d$个属性，最后一行元素置为$1$，即<br>$$<br>X=\left|<br>    \begin{matrix}<br>    x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} &amp; 1\<br>    x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} &amp; 1\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots\<br>    x_{m1} &amp; x_{m2} &amp; \cdots &amp; x_{md} &amp; 1 \<br>    \end{matrix}<br>    \right|=\left|<br>    \begin{matrix}<br>    x_1^T &amp;1\<br>    x_2^T &amp;1\<br>    \vdots &amp; \vdots\<br>    x_m^T &amp;1\<br>    \end{matrix}<br>    \right|</p>
<p>$$<br>再把标记也写成向量形式$y=(y_1;y_2;…;y_m)$，则类似于单变量线性回归模型，有<br>$$<br>\hat{w}^*=argmin_{\hat{w}}(y-X\hat{w})^T{}(y-X\hat{w})<br>$$<br>令$E_\hat{w}=(y-X\hat{w})^T{}(y-X\hat{w})$，对$\hat{w}$求导得到：<br>$$<br>\frac{\partial E_{\hat{w}}}{ \partial\hat w}=2X^T(X\hat w-y)<br>$$<br>令上式为零可得 $\hat w$ 最优解的闭式解，但由于涉及矩阵逆的计算，比单变量情形要复杂一些，</p>
<p>下面说一下线性模型的变种，有时候我们的$y$和$x$之间不是线性变化，比如说y是跟随$x$呈现指数变化，这就导致了一个问题，$y=w<em>x+b$不能再表示他们之间的关系，那么这时候应该通过一个“<strong>联系函数</strong>”，如上面我们举出来的例子，如果$y$和$wx+b$之间不再是线性而是指数变换，这是我们可以对$y$进行取对数操作<br>$$<br>ln y=w^Tx+b<br>$$<br>这个取对的操作就相当于在原先的等式之间又加上了一个函数，这个函数我们就叫作联系函数，而我们把上面的式子叫做对数线性回归。<br> 我们再回味一下为什么这么做呢？因为y和x之间不再具有某种线性关系，取而代之的是一种指数关系，那我们怎么将这种指数关系表示出来呢？将y进行取对操作，这样lny又一次和w</em>x+b呈现一种线性关系，这已经实际上是一种空间映射。</p>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/">#机器学习基础理论</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>week01</div>
      <div>http://example.com/2022/06/16/机器学习week01/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>June 16, 2022</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>Licensed under</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/06/17/Canopen%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/" title="CANopen网络协议">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CANopen网络协议</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/06/16/Labiew/" title="Labview">
                        <span class="hidden-mobile">Labview</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>






  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
