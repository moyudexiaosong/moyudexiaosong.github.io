

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/icon.jpg">
  <link rel="icon" href="/img/icon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="FSL综述 小样本学习：在样本很少的情况下，不足以训练一个神经网络，只能提供一些参考信息。 举个例子，下面这张图，人能根据左边这个很小的数据集总结出犰狳和穿山甲的区别，正确地对新的样本进行分类，但是机器不能。 FSL和传统机器学习的区别：FSL的目标不是让机器能够识别训练集里的图片，并泛化到测试集，而是让机器自己学会学习。  FSL的测试样本是以前从未见过的东西，而传统神经网络已经见了几百上千次">
<meta property="og:type" content="article">
<meta property="og:title" content="小样本学习综述">
<meta property="og:url" content="http://example.com/2022/08/31/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/index.html">
<meta property="og:site_name" content="摸鱼之家">
<meta property="og:description" content="FSL综述 小样本学习：在样本很少的情况下，不足以训练一个神经网络，只能提供一些参考信息。 举个例子，下面这张图，人能根据左边这个很小的数据集总结出犰狳和穿山甲的区别，正确地对新的样本进行分类，但是机器不能。 FSL和传统机器学习的区别：FSL的目标不是让机器能够识别训练集里的图片，并泛化到测试集，而是让机器自己学会学习。  FSL的测试样本是以前从未见过的东西，而传统神经网络已经见了几百上千次">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/photo14.jpeg">
<meta property="article:published_time" content="2022-08-31T14:41:07.000Z">
<meta property="article:modified_time" content="2022-10-21T06:55:34.467Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="book">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/photo14.jpeg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>小样本学习综述 - 摸鱼之家</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":false},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"AwHBUAjSP1GvDVpiBgxfS2Pg-gzGzoHsz","app_key":"kMsGLN3hzkQJuLrmqQBgquFF","server_url":"https://awhbuajs.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>快乐老家</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                档案馆
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                目录
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/photo14.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="小样本学习综述"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-08-31 22:41" pubdate>
          August 31, 2022 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          12k words
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">小样本学习综述</h1>
            
              <p class="note note-info">
                
                  
                    Last updated on 11 days ago
                  
                
              </p>
            
            <div class="markdown-body">
              
              <hr>
<p><a class="btn" target="_blank" rel="noopener" href="https://www.cnblogs.com/jiangxinyang/p/12163215.html#:~:text=Task-invariant%E6%98%AF%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%A4%A7%E7%9A%84%E4%B8%94%E5%92%8C%E4%BB%BB%E5%8A%A1%E7%9B%B8%E4%BC%BC%E7%9A%84source,%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%EF%BC%8C%E7%84%B6%E5%90%8E%E7%9B%B4%E6%8E%A5%E7%94%A8%E4%BA%8E%E5%BD%93%E5%89%8D%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E5%B5%8C%E5%85%A5%E3%80%82" title="title">FSL综述</a></p>
<h3 id="小样本学习："><a href="#小样本学习：" class="headerlink" title="小样本学习："></a>小样本学习：</h3><p>在样本很少的情况下，不足以训练一个神经网络，只能提供一些参考信息。</p>
<p>举个例子，下面这张图，人能根据左边这个很小的数据集总结出犰狳和穿山甲的区别，正确地对新的样本进行分类，但是机器不能。<img src="/../img/image-20220925163936847.png" srcset="/img/loading.gif" lazyload alt="image-20220925163936847"></p>
<h3 id="FSL和传统机器学习的区别："><a href="#FSL和传统机器学习的区别：" class="headerlink" title="FSL和传统机器学习的区别："></a>FSL和传统机器学习的区别：</h3><p>FSL的目标不是让机器能够识别训练集里的图片，并泛化到测试集，而是让机器自己学会学习。</p>
<ul>
<li>FSL的测试样本是以前从未见过的东西，而传统神经网络已经见了几百上千次了</li>
<li>FSL的训练集里没有query sample的类别</li>
</ul>
<p><img src="/../img/image-20220925164330392.png" srcset="/img/loading.gif" lazyload alt="image-20220925164330392"></p>
<p>例如上面这个数据集，FSL的目标并不是让机器学习这些动物图片，并能够识别没见过的哈士奇或者鹦鹉。而是<strong>理解模型的异同，区分不同的事物。</strong>在训练完成后，我们问的问题是：下面这两张图片，是同一种东西吗？这时模型机已经学会了分辨异同，知道这两张图片都是同一种东西，但是如果没有告诉他这是松鼠，他并不知道，也不用知道他们其实是松鼠。</p>
<p><img src="/../img/image-20220925164750331.png" srcset="/img/loading.gif" lazyload alt="image-20220925164750331"></p>
<p>Support Set和训练集的区别：训练集是一个很大的，用来训练神经网络的数据集，但是Support Set只能训练提供一些额外信息。</p>
<p>例如下图，FSL并不知道query是什么，但是在给出Support Set后，FSL开始把query和Support Set里的动物类型进行比对，发现query和Otter最相似，所以把query分类为Otter。</p>
<p><img src="/../img/image-20220925165147799.png" srcset="/img/loading.gif" lazyload alt="image-20220925165147799"></p>
<h3 id="元学习Meta-Learning"><a href="#元学习Meta-Learning" class="headerlink" title="元学习Meta Learning"></a>元学习Meta Learning</h3><p>笼统地说，FSL就是元学习。元学习和传统的监督学习不一样，传统学习要求模型去识别训练数据，并能泛化到测试数据。而元学习的目标是让模型学会怎么自己去学习。</p>
<p><img src="/../img/image-20220925174038715.png" srcset="/img/loading.gif" lazyload alt="image-20220925174038715"></p>
<p>如上图，小朋友的学习资料只有这堆卡片，如果只靠一张图片就能识别是不是Otter，就叫One-Shot-Learning。</p>
<h3 id="FSL术语："><a href="#FSL术语：" class="headerlink" title="FSL术语："></a>FSL术语：</h3><p><img src="/../img/image-20220926012333714.png" srcset="/img/loading.gif" lazyload alt="image-20220926012333714"></p>
<ul>
<li>K-way：Support Set里有多少个类别，本例中有6个类别</li>
<li>N-shot：每个类里有多少个样本，本例中有每个类里有1个样本</li>
</ul>
<p>因此，这是一个6-way 1-shot的Support Set。</p>
<p><img src="/../img/image-20220926013140024.png" srcset="/img/loading.gif" lazyload alt="image-20220926013140024"></p>
<p>如图所示，随着Support Set里的类别增加，FSL分类的准确性会降低，因为在给出一个样本，然后和Support Set里的每一个类进行比较的过程中，1/3的正确率明显要大于1/10。</p>
<p><img src="/../img/image-20220926013730483.png" srcset="/img/loading.gif" lazyload alt="image-20220926013730483"></p>
<p>随着每个类的样本数增加，做预测越容易，准确率越高。</p>
<h3 id="FSL的中心思想："><a href="#FSL的中心思想：" class="headerlink" title="FSL的中心思想："></a>FSL的中心思想：</h3><p>学习一个函数，然后判断Similaritu相似度。把函数记为<script type="math/tex">sim(x,x')</script>，可以比较两张图片$x$和$x’$的相似度，两个图片越相似，输出值越高。</p>
<p><img src="/../img/image-20220926014110093.png" srcset="/img/loading.gif" lazyload alt="image-20220926014110093"></p>
<p>这里有三张图片，分别是斗牛犬、斗牛犬和狐狸，最理想的情况是把$x_1 , x_2$作为输入，sim函数输出1，意思是这两张图片是相同的动物，而把$x_1 ,x_3$或者$x_2,x_3$作为输入时，函数输出0，意思是这是两种完全不一样的动物。</p>
<p>具体实现：从一个很大的数据集上学习一个相似度函数，可以判断两张图的相似度有多高。然后把query和Support Set里的图片逐一计算相似度，返回相似度最高的class为结果。</p>
<p><img src="/../img/image-20220926014743390.png" srcset="/img/loading.gif" lazyload alt="image-20220926014743390"></p>
<p>用这种方式，可以做到One-Shot-Learning。</p>
<h3 id="常用数据集："><a href="#常用数据集：" class="headerlink" title="常用数据集："></a>常用数据集：</h3><ul>
<li>Omniglot手写字体数据集，50个字母表，每个字母表24个字符，每个字符由20个人手写。</li>
</ul>
<p><img src="/../img/image-20220926014932600.png" srcset="/img/loading.gif" lazyload alt="image-20220926014932600"></p>
<ul>
<li><p>Mini-ImageNet</p>
<p><img src="/../img/image-20220926015120240.png" srcset="/img/loading.gif" lazyload alt="image-20220926015120240"></p>
</li>
</ul>
<h3 id="孪生-连体网络Siamese-Network"><a href="#孪生-连体网络Siamese-Network" class="headerlink" title="孪生/连体网络Siamese Network"></a>孪生/连体网络Siamese Network</h3><p>这个方法对输入的结构进行限制并自动发现可以从新样本上泛化的特征。通过一个有监督的基于孪生网络的度量学习来训练，然后重用那个网络所提取的特征进行one/few-shot学习。</p>
<p>两种训练方法：</p>
<h4 id="第一种训练方法："><a href="#第一种训练方法：" class="headerlink" title="第一种训练方法："></a>第一种训练方法：</h4><p>每次取两个样本，分别计算它们的相似度。</p>
<p><img src="/../img/image-20220926015331293.png" srcset="/img/loading.gif" lazyload alt="image-20220926015331293"></p>
<p>这是一个很大的数据集，我们需要用训练集来构造正样本和负样本，正样本告诉神经网络什么是同一类，负样本告诉神经网络事物之间的区别。</p>
<p>Positive Samples：每次从训练集中随机抽取一张图片，然后从和这张照片的同一类里抽取另一张图片，并把标签设置为1，意思为相似度满分。 </p>
<p>Negative Samples：每次从训练集中随机抽取一张图片，然后从和这张照片不同的类里抽取另一张图片，并把标签设置为0，意思是完全不相似。 </p>
<p><img src="/../img/image-20220926015839134.png" srcset="/img/loading.gif" lazyload alt="image-20220926015839134"></p>
<p>搭一个神经网络来提取特征，这个神经网络有很多卷积层，和一个平面层，输入是一张图片，输出是提取的特征向量。</p>
<p><img src="/../img/image-20220926020017283.png" srcset="/img/loading.gif" lazyload alt="image-20220926020017283"></p>
<p>现在开始训练一个神经网络，刚才已经准备好了训练数据，把两张图片作为输入，输进刚刚搭建好的卷积神经网络f，卷积神经网络输出刚刚提取的特征向量$h_1$，$h_2$。</p>
<p>因为这两个输入共享了特征提取的部分，所以叫孪生/连体网络。</p>
<p>然后拿$h_1$减去$h_2$得到一个向量，再对这个这个向量的所有元素求绝对，表示这两个向量的区别，即$z=|h_1-h_2|$，再用一些权连接层处理这个向量$z$，输出一个标量，然后用$Sigmoid$激活函数，得到的输出是一个介于0-1之间的实数，这个输出就可以用来衡量两个图片之间的相似度。</p>
<p><img src="/../img/image-20220926173317759.png" srcset="/img/loading.gif" lazyload alt="image-20220926173317759"></p>
<p>在输入两张图片的时候，我们已经准备好了标签，因为这是两张同类的图片，所以标签为1，而我们经过训练得到的函数输出可能不是1，将标签与预测值相减，得到的就是损失函数Loss。</p>
<p>有了损失函数，就可以用反向传播计算梯度，然后用梯度下降来更新参数。</p>
<p>模型主要有两个部分：</p>
<ul>
<li>一个是CNN卷积神经网络f，用来从图片汲取特征。</li>
<li>另一部分是权连接层，用来预测相似度。</li>
</ul>
<p>训练的过程就是更新这两部分的参数。</p>
<p><img src="/../img/image-20220926174827528.png" srcset="/img/loading.gif" lazyload alt="image-20220926174827528"></p>
<p>作反向传播，梯度从Loss函数反向传播到梯度z，就可以更新权连接层的参数来，然后进一步传播到卷积层f，就可以进而更新卷积层的参数，这样就完成了一轮训练。</p>
<p>做训练的时候，要准备同样数量的正样本和负样本，标签分别设为1和0。</p>
<p>训练好模型后，就可以用这个模型来做One-Shot-Prediction，注意的是，这里Support Set里的类别都不在训练集里，然后给出Query，让模型在Support Set里进行多选一，这就是FSL的困难之处。</p>
<p><img src="/../img/image-20220926175455066.png" srcset="/img/loading.gif" lazyload alt="image-20220926175455066"></p>
<p>如上图，模型选择了小松鼠。</p>
<h4 id="第二种训练方法："><a href="#第二种训练方法：" class="headerlink" title="第二种训练方法："></a>第二种训练方法：</h4><p>想要使用Triplet Loss，要这样准备训练数据：</p>
<p><img src="/../img/image-20220926175943492.png" srcset="/img/loading.gif" lazyload alt="image-20220926175943492"></p>
<p>在给定的数据集里，先随机选择一张图片作为锚点anchor，然后再从这张图片的同一类里随机选择另一种图片作正样本positive，再从别的随机一类里抽一张图片作负样本negative。</p>
<p>把这三张图片一起输入同一个神经网络f（孪生网络的中心思想就是共用同一个卷积神经网络），分别提取这三个特征向量，然后计算正负样本和锚点在特征空间上的距离，相减后计算其二范数的平方，得到距离。</p>
<p><img src="/../img/image-20220926180744654.png" srcset="/img/loading.gif" lazyload alt="image-20220926180744654"></p>
<p>我们希望得到这样一个特征，相同类别的特征向量都聚在一起，不同类别的特征向量都分得很开，因此结果应该符合这样的特征：$d^+$很小，$d^-$很大。</p>
<p>举个例子，卷积神经网络得出的特征向量映射出的特征图片如图所示。</p>
<p><img src="/../img/image-20220926181021129.png" srcset="/img/loading.gif" lazyload alt="image-20220926181021129"></p>
<p>基于我们的期望，我们这样定义损失函数：鼓励正样本接近锚点，$d^+$很小，鼓励负样本远离锚点，$d^-$很大。</p>
<p>我们自己指定一个margin，记作$\alpha$，这是一个超参数，需要我们自己来调。</p>
<p>如果$d^-$比$d^+$大了$\alpha$，我们就认为这一组样本分类是正确的，Loss等于0，如果不满足，就认为这个模型分不开正负样本，那么就会有Loss，把Loss定义为$d^+ +\alpha -d^-$。我们希望Loss越小越好，因此定义完整的Loss损失函数为：</p>
<script type="math/tex; mode=display">
Loss(x^a,x^+,x^-)=\max(0,d^+ +\alpha -d^-)</script><p>即使一下，意思是$x^a,x^+,x^-$为输入，定义损失函数为：如果$d^-&gt;d^+ +\alpha $，说明模型可以把正负样本分开，损失函数记为0，如果$d^-&lt;d^+ +\alpha $，说明模型是个废物，差异这么小，根本分不开，损失函数就记为$d^+ +\alpha -d^-$，直到损失函数变为0，能分开二者为止。</p>
<p><img src="/../img/image-20220926183220869.png" srcset="/img/loading.gif" lazyload alt="image-20220926183220869"></p>
<p>有了损失函数，就可以求损失函数关于CNN神经网络参数的梯度，然后做梯度下降来更新模型参数。训练好神经网络后，就可以进行OSL。</p>
<p>如下图，在用做好的CNN提取特征向量后，把Support Set和Query的图片都变成特征向量，然后比较特征向量之间的距离，计算可得，和小松鼠的距离最小，因此这是一只小松鼠。</p>
<p><img src="/../img/image-20220926183631963.png" srcset="/img/loading.gif" lazyload alt="image-20220926183631963"></p>
<p>注意：孪生网络虽然很简单，但并不是准确率最高的做法，这几年发表的论文里，基本上都是inflecting，把图片映射成神经网络这种做法，思路和孪生网络还是很像的。</p>
<h3 id="Pratraining-and-Fine-Tuning"><a href="#Pratraining-and-Fine-Tuning" class="headerlink" title="Pratraining and Fine Tuning"></a>Pratraining and Fine Tuning</h3><h4 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h4><p>这是一种很简单的方法，基本思想是在一个规模很大的数据集上先预训练模型，然后在小规模的Support Set上做fine-tuning，方法虽然简单但是准确率还是挺高的。</p>
<h5 id="余弦相似度-——-Cosine-Similarity"><a href="#余弦相似度-——-Cosine-Similarity" class="headerlink" title="余弦相似度 —— Cosine Similarity"></a>余弦相似度 —— Cosine Similarity</h5><p>用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上。</p>
<p>对于长度不等1的向量，用下面这个公式来计算Cosine Similarity：</p>
<p><img src="/../img/image-20220927001733597.png" srcset="/img/loading.gif" lazyload alt="image-20220927001733597" style="zoom: 50%;"></p>
<p><img src="/../img/image-20220927003427883.png" srcset="/img/loading.gif" lazyload alt="image-20220927003427883"></p>
<p>如上图中，因为x和w的长度都为1，他们的二范数都为1，所以他们的余弦相似度就是他们的内积。可以这么理解向量相似度，把向量x投影到w这个方向上，这段投影的长度就是Cosine Similarity，投影的长度在-1到+1之间。</p>
<h5 id="Softmax函数"><a href="#Softmax函数" class="headerlink" title="Softmax函数"></a>Softmax函数</h5><p>二分类问题必须用到的就是逻辑回归算法，它负责将线性模型输出的实数域映射到[0, 1]这个表示概率分布的有效实数空间。</p>
<p>例如使用逻辑回归算法预测患者是否有恶性肿瘤的二分类问题中，输出层可以只设置一个节点，表示良性肿瘤发生的概率为 $P(A | x)$ ，其中x为患者的一些特征指标，作为输入。而双节点输出的二分类就相当于多了一个$P(\overline{A}|x)$表示的恶性肿瘤发生的概率，并满足约束各个输出节点的输出值的和为1。</p>
<p>有没有将各个输出节点的输出值范围映射到[0, 1]，并且约束各个输出节点的输出值的和为1的函数呢？这个函数就是Softmax函数。</p>
<p>给出Softmax函数的定义（以第i个节点输出为例）：</p>
<script type="math/tex; mode=display">
Softmax(z_i)=\frac{e^{z_i}}{∑_{c=1}^{C}e^{z_c}}</script><p>zi 为第i个节点的输出值，C为输出节点的个数，即分类的类别个数。通过Softmax函数就可以将多分类的输出值转换为范围在[0, 1]内的和为1的概率分布。</p>
<p><img src="/../img/image-20220927005430747.png" srcset="/img/loading.gif" lazyload alt="image-20220927005430747"></p>
<p>那么它是怎么把一个向量映射成一个概率分布的呢？</p>
<p>Softmax的输入是$\phi$，它是任意的k维向量，每一个方向都是输入在这个类上的相似度，把$\phi$的每一个元素做指数变换，得到k个大于0的数，然后对结果做上面公式所示的归一化，让得到的k个数相加等于1，把得到的k个数记做向量p，这个向量p就是softmax函数的输出，因此，它们相加是肯定等于1的，所以，p也是一个概率分布，。</p>
<p>softmax函数常用于分类器的输出层，如果有k个类别，那么softmax的输出就是k个概率值，每个概率值表示对一个类别的confidence，这里举个例子：</p>
<p><img src="/../img/image-20220927011127183.png" srcset="/img/loading.gif" lazyload alt="image-20220927011127183"></p>
<p>左边是输入，右边是输出。不同于max函数把最大值变1，其余值变0的操作，softmax()的作用是让最大值变大，其余值变小，但是最大值也没有大到1，这是指数化的作用。</p>
<p><img src="/../img/image-20220927011517529.png" srcset="/img/loading.gif" lazyload alt="image-20220927011517529"></p>
<p>softmax分类器是由一个权连接层加一个softmax函数组成的，分类器输入是向量x，输出是向量p，假如类别数量等于k，那么向量p就是k维的。</p>
<p>矩阵W和向量b是这一层的参数，可以从训练数据中学习，所以W的每一行对应一个类别，每一列对应一个特征，输入x显示的是这个图片的不同特征，经过$Wx+b$变换后得到一个k维向量，对其使用Softmax激活函数后，得到的就是一个k维向量p。</p>
<h5 id="cross-Entropy交叉熵"><a href="#cross-Entropy交叉熵" class="headerlink" title="cross Entropy交叉熵"></a>cross Entropy交叉熵</h5><p>有时，我们可能希望预测的概率分布接近我们观察到的数据的分布，也就是说，我们希望一种分布（可以是概率向量）与另一种分布接近， 而交叉熵为我们提供了一种自然的方法测量两个分布之间的差距，这个差距就可以被当作损失函数。</p>
<p>香农提出的<strong>熵的定义</strong>：无损编码事件信息的最小平均编码长度。</p>
<p><img src="/../img/v2-8de58ebed3434892762f5809c1320462_1440w.jpg" srcset="/img/loading.gif" lazyload alt="img" style="zoom:50%;"></p>
<p>举个例子，下图传消息时，明显方式3编码长度最小，且是平均意义上的最小。方式3胜出的原因在于：对高可能性事件(Fine,Cloudy)用短编码，对低可能性事件(Rainy,Snow)用长编码。<img src="/../img/v2-73be23174f9ab59fe8ea5b2aa3e38f00_1440w.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<h6 id="如何直接计算熵？"><a href="#如何直接计算熵？" class="headerlink" title="如何直接计算熵？"></a>如何直接计算熵？</h6><p>再举个例子，假设一个信息事件有8种可能的状态，且各状态等可能性，即每一种可能性都是12.5%=1/8。我们需要多少位来编码8个值呢？</p>
<p>1位可以编码2个值(0或1)，2位可以编码2×2=4个值(00,01,10,11)，则8个值需要3位，2×2×2=8(000,001,010,011,100,101,110,111)。</p>
<p>归纳来看，对于具有N种等可能性状态的信息，每种状态的可能性P = 1/N，编码该信息所需的最小编码长度为：</p>
<script type="math/tex; mode=display">
log_2 N=-log_2 P</script><p>那么计算平均最小长度，也就是熵的公式为：</p>
<script type="math/tex; mode=display">
Entropy=-\sum_i P(i)log_2 P(i)</script><p>其中P(i)是第i个信息状态的可能性。</p>
<p>同理，对于连续变量 x 的概率分布P(x)，熵的公式可以表示为：</p>
<script type="math/tex; mode=display">
Entropy=-\int P(i)log_2 P(i)dx</script><p>因此，只要我们知道了任何事件的概率分布，我们就可以计算它的熵。但如果在不知道的情况下，我们需要对它做一个估计，这就引出了交叉熵。</p>
<h6 id="熵的估计"><a href="#熵的估计" class="headerlink" title="熵的估计"></a>熵的估计</h6><h4 id="FSL思想："><a href="#FSL思想：" class="headerlink" title="FSL思想："></a>FSL思想：</h4><p>大多数FSL学习都基于类似的想法，先用一个大数据集来预训练一个神经网络，用来从图片中提取特征，然后用这个神经网络把query和Support Set中的图片都映射成特征向量，再比较特征空间上的相似度，比如可以计算两两之间的consine similarity，最后选择相似度最高的，作为对Query分类的结果。</p>
<p>预训练有很多种方法，包括传统的监督学习，训练好之后把权连接层都去掉，也可以用孪生网络，都可以。但这个神经网络的结构和训练方法都会对最终结果产生影响。</p>
<h4 id="FSL常用分类方法："><a href="#FSL常用分类方法：" class="headerlink" title="FSL常用分类方法："></a>FSL常用分类方法：</h4><p><img src="/../img/image-20220927013600678.png" srcset="/img/loading.gif" lazyload alt="image-20220927013600678"></p>
<p>这是一个共三类，每类两个的Support set，对这六张图片分别进行特征提取。然后对相同类提取出的特征向量取均值，就作为小松鼠或者小狗狗这一总类的对照向量。然后对这个向量进行归一化（方法各异，可以采用不同的激活函数，怎么都可以），分别得到$\mu_1,\mu_2,\mu_3$，他们的二范数都等于1，这就是对这三个类别的表征。做分类的时候，就拿query的特征向量跟这三个向量分别作对比（可以采用cosine similarity，也是怎么都可以）。</p>
<p><img src="/../img/image-20220927014332395.png" srcset="/img/loading.gif" lazyload alt="image-20220927014332395"></p>
<p>把query特征提取再归一化后，得到一个向量q，然后再对Support set里的三个类做相同操作，把得到的三个$\mu$向量堆叠起来，作为矩阵M的三个行向量。把q乘到矩阵M上，然后再做softmax变换，得到一个概率分布的向量p，每个元素表示对该类别的confidence，这时候做内积就等于在求cosine similarity。</p>
<p><img src="/../img/image-20220927014926040.png" srcset="/img/loading.gif" lazyload alt="image-20220927014926040"></p>
<p>很明显是$\mu_1$，也就是模型认为结果是第一类——小松鼠。</p>
<h4 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine-Tuning"></a>Fine-Tuning</h4><p>一般训练完神经网络后就要直接开始预测了，这时候我们在这两部分之间插入fine-tuning，，用support set进一步做训练，可以更好的提高准确率。</p>
<p>这种方法已被广泛地应用。获得一定量的标注数据，然后基于一个基础网络进行微调。这个基础网络是通过含有丰富标签的大规模数据集获得的，比如imagenet，我们的淘宝电商数据，称为通用数据域。然后在特定数据域上进行训练。训练时，会固定基础网络部分的参数，对领域特定的网络参数进行训练（这里有很多训练的trick，包括如何设置固定层和学习率等）。这个方法相对较快，依赖数据量也不必太多，效果还行。</p>
<p>刚刚我们用的是神经网络在训练集上预训练好的W和b，在比较Support set和query时直接固定这些参数，但其实我们可以在support set上学习W和b，这就叫做Fine tuning。</p>
<p><img src="/../img/image-20220928014751753.png" srcset="/img/loading.gif" lazyload alt="image-20220928014751753"></p>
<p>学习过程：用交叉熵衡量真实标签(one-hot向量形式)与预测标签的差别有多大，得到一个损失函数，Support Set里有几个或者几十个这样的样本，每一个样本都对应一个交叉熵损失函数，把这些函数都加起来作为目标函数，对目标损失函数做最小化，让预测标签尽量接近真实标签。</p>
<p>这个最小化是相对于分类器参数W和b求的，希望学习W和b。当然也可以让梯度反向传播会卷积神经网络，更新神经网络参数，让提取的特征向量更有效。</p>
<p>但是由于Support Set通常很小，所以最好加一个regularization来防止过拟合。有多种regularization可供选择，其中entropy regularization较为合理。</p>
<h5 id="技巧一：初始化参数："><a href="#技巧一：初始化参数：" class="headerlink" title="技巧一：初始化参数："></a>技巧一：初始化参数：</h5><p>做Fine-Tuning的时候，我们想要从Support Set中学习这样一个Softmax分类器：矩阵W和向量b是分类器的参数。但由于Support Set中的样本数量太少了，如果随机初始化参数，最终结果并不理想。</p>
<p>因此，可以把W初始化为前面得出的矩阵M，把b初始化为全零向量。</p>
<p><img src="/../img/image-20220928015328051.png" srcset="/img/loading.gif" lazyload alt="image-20220928015328051"></p>
<p>在矩阵M中，有几个类就有几行，每一行代表的是该类的均值向量，之前我们用的就是固定M，并把b设为0向量进行softmax的方法，这样做的情况下，哪怕不做训练，用这样固定的设置就已经有了很好的效果。</p>
<p>所以这是一个很合理的初始化方法。</p>
<h5 id="技巧二：防止过拟合"><a href="#技巧二：防止过拟合" class="headerlink" title="技巧二：防止过拟合"></a>技巧二：防止过拟合</h5><p><img src="/../img/image-20220928022725476.png" srcset="/img/loading.gif" lazyload alt="image-20220928022725476"></p>
<p>把query看作输入x，经过特征提取后得到f(x)，把f(x)输入softmax分类器，得到预测p向量，p是个概率分布，每一个元素都是一个概率值，可以用Entropy来衡量概率分布p的信息量，如第三行公式所示。这是用一个样本x求出的Entropy，通常会有多个query图片，对于每个query，求出一个Entropy，然后对其取平均，所有Entropy的均值就是Entropy regularization。</p>
<p>我们希望Entropy regularization越小越好。</p>
<p><img src="/../img/image-20220928023403969.png" srcset="/img/loading.gif" lazyload alt="image-20220928023403969"></p>
<p>假设分类问题有三个类别，分类器输出每个类别的概率值，左图所示的情况三个概率值差不多，说明分类器判别不出query图片属于哪一类，我们不喜欢这种结果。右图分类器则认为query属于第二类，而且非常有信心，这就是我们想要的结果。</p>
<h5 id="技巧三：结合consine-Similarity和softmax分类器"><a href="#技巧三：结合consine-Similarity和softmax分类器" class="headerlink" title="技巧三：结合consine Similarity和softmax分类器"></a>技巧三：结合consine Similarity和softmax分类器</h5><p>根据最新论文表明，这种方法可以显著提高分类准确率。</p>
<p><img src="/../img/image-20220928024230677.png" srcset="/img/loading.gif" lazyload alt="image-20220928024230677"></p>
<p>本来是直接向量相乘就softmax的，现在先把$w^Tq$作归一化处理，然后再和b向量相加。</p>
<p>根据相关论文，这个很小的改动就可以大幅度提高准确率。</p>
<h3 id="小样本学习综述"><a href="#小样本学习综述" class="headerlink" title="小样本学习综述"></a>小样本学习综述</h3><p>本文根据机器学习中的误差分解理论，认为FSL任务中最小化经验风险是不可信的，这也是FSL难以训练的原因。</p>
<h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><h6 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h6><p>通常而言，一个N-way K-shot的分类任务，假定任务的真实分布为$𝑝(𝑥,𝑦)$，而这个真实分布有一个最优假设$ℎ̂$可以描述它。通常的做法是给定一个假设空间𝐻，然后从里面找一个接近$ℎ̂$的假设$ℎ$，在这里𝐻是由你选择的模型和参数的初始化分布决定的，用一些优化方法（通常为梯度下降）来逼近这个最优假设。</p>
<h6 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h6><p>在经典机器学习中，给定一个任务T，任务的性能P，给定一些额外的条件E，比如标注的训练数据，可以提升任务T的性能P，FSL任务本质也是这样。</p>
<h6 id="Relevant-Learning-Problems"><a href="#Relevant-Learning-Problems" class="headerlink" title="Relevant Learning Problems"></a>Relevant Learning Problems</h6><p>FSL可以是各种形式的学习，监督，半监督，强化学习，迁移学习等等，弱监督学习是强调在不完整、不准确、有噪声、数据少的数据上学习，半监督学习是强调在少量标注数据和大量非标注数据上学习，迁移学习是把充足数据上学习的知识迁移到数据匮乏的任务上。本质上的定义取决于可用的数据。</p>
<p>当然，大多数时候用的都是meta learning，直接把它看作meta learning就行。</p>
<h5 id="Core-Issue"><a href="#Core-Issue" class="headerlink" title="Core Issue"></a>Core Issue</h5><p>在机器学习中寻找最适合的模型时，通常都是通过找到一组最优的参数来确定这个模型，并通过给定的训练集，最小化损失函数这一目标来指示最优参数的搜索，最小化损失函数如下所示：</p>
<p>　　　　<img src="/../img/1335117-20200107180341483-79584449.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>h就是我们企图逼近最优模型$ℎ̂$的模型，y是真实标签，l是损失函数，对每一个训练样本的损失函数进行求和，找到这个和的最小值。</p>
<p>在训练模型中，我们是通过训练集来拟合真实分布，我们训练出来的分布和真实分布往往不一样，这中间的差值称为期望风险（期望损失），表达式如下：</p>
<p>　　　　<img src="/../img/1335117-20200107181052551-1263293547.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>p为真实分布，要求对损失函数求期望，需要将它放到以真实分布为坐标轴的维度上，它与坐标轴围成的面积就是期望损失。</p>
<p>理论上说，让期望风险最小化才能逼近真实分布，但因为真实分布只有神知道，因此最小化期望风险是无法实现的，而在机器学习中通常用经验风险来替换期望风险，经验风险就是在训练集上预测的结果和真实结果的差异，也是我们常说的损失函数，表达式如下：</p>
<p><img src="/../img/image-20221009224149062.png" srcset="/img/loading.gif" lazyload alt="image-20221009224149062" style="zoom:50%;"></p>
<p>给出符号描述：</p>
<p><img src="/../img/image-20221009224256524.png" srcset="/img/loading.gif" lazyload alt="image-20221009224256524"></p>
<p>$ℎ̂ $是真实分布的模型，$ℎ∗$是假设空间$𝐻$中最接近$ℎ̂ $的模型，而$h_I$是通过最小化经验损失得到的模型。根据机器学习中的误差分解可得：</p>
<p><img src="/../img/1335117-20200107181555284-1137027787.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>等式右边第一项只能靠玄学，我们能做到的只有选个合适的模型，有时候模型选择的简单了，给再多的数据也训练不好，欠拟合。</p>
<p>第二项就是我们训练得到的模型和𝐻中最优模型的误差，有时候训练的太好会陷入局部最优，或者提供的训练数据分布有偏差，导致无法到全局最优。</p>
<p>但理论上对于第二项，当样本数量𝐼足够大时，有：</p>
<p><img src="/../img/1335117-20200107182014950-124597622.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>即只要样本够多，没有做不出来的模型。</p>
<p>传统的机器学习都是建立在大规模的训练数据上的，因此𝜀𝑒𝑠𝑡(𝐻,𝐼)是很小的，但是在FSL任务上，训练数据很小，因此𝜀𝑒𝑠𝑡(𝐻,𝐼)是很大的，所以此时采用传统的训练模式，如softmax+交叉熵，是极容易陷入过拟合的，这个应该很好理解。</p>
<p>针对上面的问题再去拓展寻求解决方案，在机器学习中正则化是一项，正则化可以约束你的假设空间𝐻，但是在FSL中不行，它的约束是没有指示性的，而FSL中的约束是需要有指示性的，即能指示你更好的接近真实假设。引入霍夫丁不等式：</p>
<p><img src="/../img/1335117-20200107183222190-1115277030.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>给定样本复杂度为S，保证上述不等式能在ϵ很小且δ很小时成立时，需要给定的样本数I大于S，给定<a target="_blank" rel="noopener" href="https://blog.csdn.net/shenxiaoming77/article/details/51881321">VC维理论</a>：</p>
<p><img src="/../img/image-20221010001459061.png" srcset="/img/loading.gif" lazyload alt="image-20221010001459061" style="zoom:50%;"></p>
<p>知道就行了，算是对降低模型复杂度的理论支撑。</p>
<h4 id="Taxonomy"><a href="#Taxonomy" class="headerlink" title="Taxonomy"></a><strong>Taxonomy</strong></h4><p>如果把小样本学习比作一个黑盒子，给这个黑盒子喂少量的数据，凭什么能让它表现得好呢？显然我们需要外力来帮助，这个外力就是“先验知识”。</p>
<p>小样本学习的先验知识来自三方面：<strong>数据、模型、算法</strong>，小样本学习的研究也都是从这三方面着手。因此，小样本学习方法大致可分为基于<strong>数据增强</strong>的方法、基于<strong>模型改进</strong>的方法、基于<strong>算法优化</strong>的方法。</p>
<p>在这里作者将解决这个问题的方法分为了三类：Data，Model，Algorithm。具体的图如下：</p>
<p><img src="/../img/1335117-20200107184200179-1606317169.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><strong>一、基于数据增强的方法</strong></p>
<p>​    主要思路就是数据增强，通俗地讲就是扩充样本。想到数据增强，我们通常会想到平移、裁剪、翻转、加噪声等操作，但是这些操作可能在特定数据集表现很好，不具有普适性。而且设计这些操作需要对所处理的领域具有足够的了解。小样本学习所使用的数据增强方法主要有三个思路：</p>
<ol>
<li>只有小样本数据集：可以训练一个transformer学习样本之间的变化，然后使用该transformer对小样本数据集进行扩充；</li>
<li>有小样本数据集+弱标注数据集：可以训练transformer从弱标注数据集中“挑选”样本来扩充小样本数据集；</li>
<li>有小样本数据集+相似的数据集：可以训练一个GAN网络，通过学习给小样本数据集加上扰动来生成新样本。    </li>
</ol>
<p><img src="/../img/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQ1NTEzNQ==,size_16,color_FFFFFF,t_70.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>基于数据的方法比较容易理解，但是存在的问题是：很多工作都不具备普适性，难以迁移到别的数据集。</p>
<p><strong>二、基于模型改进的方法</strong></p>
<p>每个模型经过迭代都会得到近似解，而当样本有限时，在假设空间搜索解就变得困难。这类方法为了缩小假设空间，主要有四种方法：</p>
<ol>
<li><p>多任务学习（Multitask Learning）：这种模型可以处理多个任务，因此也就兼备了模型的普适性和一般性。在处理多个任务时，模型的参数可以是共享的，也可以是相关联的；</p>
</li>
<li><p><strong>嵌入学习</strong>（Embedding Learning）：将样本映射到一个低维度空间，从而达到了缩小假设空间的效果，然后就可以通过少量的样本求出模型在该假设空间下的近似解。根据映射到低维空间的方法又分为三类：任务特定型（结合任务的具体特点进行映射）、通用型、结合型（结合任务和通用）；</p>
</li>
<li><p><strong>基于外部记忆的学习</strong>（Learning with External Memory）：通过对小样本数据集学习得到知识，然后存储到外部，对于新样本，都使用存储在外部的知识进行表示，并根据表示来完成匹配。这种方法大大降低假设空间；</p>
</li>
<li><p><strong>生成模型</strong>（Generative Modeling）：生成模型学习小样本数据集的数据分布，并可将其用于各种任务。</p>
</li>
</ol>
<p><strong>三、基于算法优化的方法</strong></p>
<p>这类方法的核心是通过改进优化算法来更快地搜索到合适解。主要方法有三种：</p>
<ol>
<li><p>改善已有参数：这种方法从<strong>参数初始化</strong>的角度着手，主要思路是借助已训练好的模型参数来调整小样本模型的参数，例如：在大数据集训练好模型来初始化小样本模型；聚合其他已训练好的模型到一个模型；给已训练好的模型加一些特别用于小样本任务的参数；等等。</p>
</li>
<li><p>改善元学习参数。元学习（meta-learning）是当下很火的一个研究方向，它的思想是学习如何学习。它的结构一般是由一个底层模型和一个顶层模型组成，底层模型是model的主体，顶层模型是meta-learner。更新参数时，它除了要更新底层model，还要更新meta参数。改善策略大致有三类：1）结合不同特定任务模型参数来对新任务的参数进行初始化；2）对模型不确定性建模，以备后续提升；3）改进参数调整流程。</p>
</li>
<li><strong>学习优化器。</strong>如下图所示，optimizer每次都迭代会更新上一次的模型参数，现在通过学习小样本数据集中每个迭代的更新值，从而应用在新的测试数据上。</li>
</ol>
<p><img src="/../img/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQ1NTEzNQ==,size_16,color_FFFFFF,t_70-20221021144046567.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>接下来的工作都是围绕这几个方向展开来求解FSL问题。</p>
<p><img src="/../img/1335117-20200107185138248-285067125.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h5 id="DATA"><a href="#DATA" class="headerlink" title="DATA"></a>DATA</h5><p>　　数据增强的方式有很多种，平时也被使用的比较多，在这里作者将数据增强的方法概括成4类：　<img src="/../img/1335117-20200107195137257-1424668420.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>　　总之，数据增强没有什么神秘感，也是大家比较熟悉的，无论是手动在数据上修改，比如图片的旋转，句子中的同义词替换等，以及复杂的生成模型生成和真实数据相近的数据。数据增强的方式有很多种，大量的合适的增强一定程度上可以缓解FSL问题，但其能力还是有限的。</p>
<h5 id="MODEL"><a href="#MODEL" class="headerlink" title="MODEL"></a>MODEL</h5><p>　　为了完美收集样本的所有特征，我们一开始给一个假设空间𝐻很大的模型，然后通过一些先验知识将这个空间中无效的hypothesis去掉，缩小假设空间𝐻，这样做感觉很绕，但实际上和<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8e1209d3127a">模型剪枝</a>中的理念类似，你一开始给一个小的模型，这个模型空间离真实假设太远了，而你给一个大的模型空间，它离真实假设近的概率比较大，然后通过先验知识去掉哪些离真实假设远的假设。</p>
<p>　　作者根据使用不同的先验知识将MODEL的方法分成4类：　　　　<img src="/../img/1335117-20200107200328079-2038936314.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​        其中，<strong>多任务学习</strong>是比较常见的，对于多个共享信息的任务，可以是数据相同任务不同，也可以是数据和任务都不同，但是数据具有领域性等等，都可以用多任务学习来训练，多任务分为硬参数共享和软参数共享两种模式：<img src="/../img/1335117-20200107201451814-1465095916.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>　　硬参数共享认为任务之间的假设空间是有部分重叠的，体现在模型上就是有部分参数是共享的，而共享的参数可以是模型的前面一些层，表征任务的低阶信息。也可以是在嵌入层之后，不同的嵌入层将不同任务嵌入到同一不变任务空间，然后共享模型参数等等。</p>
<p>　　软参数共享不再显式的共享模型参数，而是让不同任务的参数相似，这就可以通过不同任务的参数正则，或者通过损失来影响参数的相似，以此让不同任务的假设空间类似。</p>
<p>　　多任务学习通过多个任务来限制模型的假设空间，对于硬参数共享，多个任务会有一个共享的假设空间，然后每个任务还有自己特定的假设空间；对于软参数共享也类似，软参数更灵活，但也需要精心设计。</p>
<p>​        <strong>嵌入学习</strong>很好理解，将训练集中所有的样本通过一个函数𝑓(.)嵌入到一个低维可分的空间𝑍，然后将测试集中的样本通过一个函数𝑔(.)嵌入到这个低维空间𝑍，然后计算测试样本和所有训练样本的相似度，选择相似度最高的样本的标签作为测试样本的标签，根据task-specific和task-invariant，以及两者的结合可以分为三种，嵌入学习如下：</p>
<p>　　　　<img src="/../img/1335117-20200107203731133-1752571664.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>　　Task-specific是在任务自身的训练集上训练的，通过构造“同类样本相同，不同类样本不同”的<strong>样本对</strong>作为数据集，这样数据集会有一个爆炸式的扩充，可以提高样本的复杂度，然后可以用如siamese network孪生网络等来训练，前面有讲。</p>
<p>　　Task-invariant是在一个大的且和任务相似的source数据集上训练一个嵌入模型，然后直接用于当前任务的训练集和测试集嵌入，前面也有讲。</p>
<p>　　但实际上现在用的比较多的还是两者的结合，既可以利用大的通用数据集学习通用特征，又可以在特定任务上学习特定的特征，而现在常用的训练模式是meta learning中的metric-based的方式，此类常见的模型有match network，prototypical network ，relation network等，详细可以见<a target="_blank" rel="noopener" href="https://www.cnblogs.com/jiangxinyang/p/11346764.html">小样本学习（few-shot learning）在文本分类中的应用</a>。</p>
<p>​    <u>用具有外部存储机制的网络和生成式模型来学习不是很熟，学了迁移学习再看看。</u></p>
<h5 id="ALGORITHM"><a href="#ALGORITHM" class="headerlink" title="ALGORITHM"></a><strong>ALGORITHM</strong></h5><p>在FSL任务中，样本数量很少，许多梯度下降的优化方法都会失效。因此我们不再限制假设空间，根据使用不同的先验知识，可以将ALGORITHM分为下面3类：</p>
<h6 id="Refine-Existing-Parameters-theta-0"><a href="#Refine-Existing-Parameters-theta-0" class="headerlink" title="Refine Existing Parameters ${\theta} ^ {0}$"></a><img src="/../img/1335117-20200107211620794-1625958996.png" srcset="/img/loading.gif" lazyload alt="img">Refine Existing Parameters ${\theta} ^ {0}$</h6><p>　　本质上就是我们常用的pretrained + fine-tuning的模式，最常见的就是直接在pretrianed的模型上直接fine-tuning参数，其他的还有可以在一个新的网络上使用pretrained的部分参数来初始化等等。</p>
<h6 id="Refine-Meta-learned-𝜃"><a href="#Refine-Meta-learned-𝜃" class="headerlink" title="Refine Meta-learned 𝜃"></a><strong>Refine Meta-learned 𝜃</strong></h6><p>基于meta learning的解决方法，利用元学习器<u>学习一个好的初始化参数</u>，之后在新的任务上，只要对这个初始化参数少量迭代更新就能很好的适应新的任务。</p>
<p>元学习区别于机器学习的是，机器学习通常是在拟合一个数据的分布，而元学习是在拟合一系列相似任务的分布，因此元学习的训练样本其实是一系列任务。</p>
<p>但这样的方式也有一个问题，就是新的任务的特性必须要和元训练中的任务相近，这样𝜃值才能作为一个较好的初始化值。否则效果会很差。因此也就有不少研究在根据新任务的数据集来动态的生成一个适合它的初始化参数。</p>
<h6 id="Learn-Search-Steps"><a href="#Learn-Search-Steps" class="headerlink" title="Learn Search Steps"></a><strong>Learn Search Steps</strong></h6><p>还没看RNN，不是很懂。</p>
<h4 id="FUTURE-WORKS"><a href="#FUTURE-WORKS" class="headerlink" title="FUTURE WORKS"></a><strong>FUTURE WORKS</strong></h4><p>未来的方向可以从：</p>
<ul>
<li>先验数据：例如利用更多的先验知识，多模态的数据等。</li>
<li>模型方法：用一些新的网络结构去替换以前的，比如用transformer替换RNN会不会有更好的结果</li>
<li>使用的场景：现在FSL也只是在字符识别，图像识别等取得不错的效果，在CV其他方向，如目标检测，目标跟踪，NLP中的各项任务上又是什么样的表现，该怎样改进；理论分析等。</li>
</ul>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/book/" class="category-chain-item">book</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/book/">#book</a>
      
    </div>
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/09/01/Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="要看的书">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">要看的书</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/25/vue3-x-%E7%BB%84%E4%BB%B6%E7%AF%87/" title="vue3.x 组件篇">
                        <span class="hidden-mobile">vue3.x 组件篇</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="vcomment" class="comment"></div> 
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
  <script>
    var notify = '' == true ? true : false;
    var verify = '' == true ? true : false;
      window.onload = function() {
          new Valine({
              el: '#vcomment',
              app_id: "AwHBUAjSP1GvDVpiBgxfS2Pg-gzGzoHsz",
              app_key: "kMsGLN3hzkQJuLrmqQBgquFF",
              placeholder: "说点什么",
              avatar:"retro",
              visitor: true       

          });
      }
  </script>

 
  <noscript>Please enable JavaScript to view the comments</noscript>



  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  




  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  
    
  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>

  <script defer src="/js/leancloud.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/yinghua.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/xiantiao.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/xiaoxingxing.js"></script>
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/caidai.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
